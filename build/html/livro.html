<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-br" xml:lang="pt-br">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Escola de Dados" />
  <title>Fluxo de trabalho com dados - Do zero à prática</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  
  
  
</head>
<body>
<header id="title-block-header">
<h1 class="title">Fluxo de trabalho com dados - Do zero à prática</h1>
<p class="author">Escola de Dados</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#créditos">Créditos</a></li>
<li><a href="#apresentação">Apresentação</a></li>
<li><a href="#introdução">Introdução</a>
<ul>
<li><a href="#nada-dado-nos-dados">Nada dado nos dados</a></li>
<li><a href="#trabalhando-com-dados">Trabalhando com dados</a></li>
<li><a href="#iniciação-à-programação">Iniciação à programação</a></li>
</ul></li>
<li><a href="#defina">Defina</a>
<ul>
<li><a href="#criando-boas-perguntas">Criando boas perguntas</a></li>
<li><a href="#reconhecendo-um-bom-escopo">Reconhecendo um bom escopo</a></li>
<li><a href="#dados-para-além-de-tabelas">Dados para além de tabelas</a></li>
</ul></li>
<li><a href="#obtenha">Obtenha</a>
<ul>
<li><a href="#lei-de-acesso-à-informação-e-dados-abertos">Lei de Acesso à Informação e dados abertos</a></li>
<li><a href="#problemas-comuns-com-tabelas">Problemas comuns com tabelas</a></li>
<li><a href="#lidando-com-pdfs">Lidando com PDFs</a></li>
<li><a href="#raspagem-de-dados-e-apis">Raspagem de dados e APIs</a></li>
</ul></li>
<li><a href="#cheque">Cheque</a>
<ul>
<li><a href="#biografando-dados">Biografando dados</a></li>
<li><a href="#tópicos-de-atenção">Tópicos de atenção</a></li>
</ul></li>
<li><a href="#limpe">Limpe</a>
<ul>
<li><a href="#ferramentas-e-técnicas-de-limpeza">Ferramentas e técnicas de limpeza</a></li>
<li><a href="#tópicos-de-atenção-1">Tópicos de atenção</a></li>
</ul></li>
<li><a href="#analise">Analise</a>
<ul>
<li><a href="#vieses-e-limitações">Vieses e limitações</a></li>
<li><a href="#operações-matemáticas-básicas">Operações matemáticas básicas</a></li>
<li><a href="#estatística-para-leigos">Estatística para leigos</a></li>
<li><a href="#operações-de-análise-de-dados">Operações de análise de dados</a></li>
</ul></li>
<li><a href="#visualize">Visualize</a>
<ul>
<li><a href="#breve-histórico-da-visualização-de-dados">Breve histórico da visualização de dados</a></li>
<li><a href="#princípios-práticos">Princípios práticos</a></li>
<li><a href="#clareza-vs-emoção">Clareza vs emoção</a></li>
<li><a href="#tarefas-perceptivas-e-gráficos">Tarefas perceptivas e gráficos</a></li>
<li><a href="#ferramentas-para-visualização-de-dados">Ferramentas para visualização de dados</a></li>
</ul></li>
<li><a href="#conclusão">Conclusão</a></li>
<li><a href="#referências">Referências</a></li>
<li><a href="#apoiadores">Apoiadores</a></li>
</ul>
</nav>
<h1 id="créditos">Créditos</h1>
<p>Esta é a primeira edição do guia <strong>Fluxo de trabalho com dados - do zero à prática</strong>, publicada em agosto de 2020. O ebook foi produzido graças aos recursos obtidos com o primeiro financiamento coletivo da Escola de Dados, que alcançou sua meta e contou com o apoio de 282 pessoas. A listagem completa dos nomes encontra-se no final do livro.</p>
<hr />
<p><strong>Organização</strong></p>
<p>Adriano Belisário</p>
<p><strong>Revisão e edição de texto</strong></p>
<p>Adriano Belisário</p>
<p>Marília Gehrke</p>
<p><strong>Editoração</strong></p>
<p>Adriano Belisário</p>
<p><strong>Capa</strong></p>
<p>Isis Reis</p>
<p><strong>Autoria dos capítulos</strong></p>
<p>Os capítulos do livro possuem a seguinte autoria:</p>
<p>Introdução: Adriano Belisário, Rodrigo Menegat e Marília Gehrke</p>
<p>Defina: Adriano Belisário</p>
<p>Obtenha: Adriano Belisário</p>
<p>Cheque: Marina Gama Cubas e Rodrigo Menegat</p>
<p>Limpe: Marina Gama Cubas e Adriano Belisário</p>
<p>Analise: Rodrigo Menegat</p>
<p>Visualize: Rodrigo Menegat</p>
<p><strong>Equipe</strong></p>
<p><em>Adriano Belisário</em></p>
<p>Coordenador da Escola de Dados e jornalista com mais de 10 anos de experiência com projetos na área de comunicação e tecnologias livres. É autor e organizador de diversas publicações, tutoriais e textos sobre o assunto, como o livro ‘Copyfight - Pirataria &amp; Cultura Livre’ (2012) e dezenas de conteúdos publicados regularmente no site da Escola de Dados. Atualmente, também é pesquisador associado ao Medialab da Universidade Federal do Rio de Janeiro, onde desenvolve investigações baseadas em dados e técnicas de Open Source Intelligence (OSINT). Tem mestrado em Comunicação na mesma universidade e foi colaborador de veículos de jornalismo investigativo, como a Agência Pública, e organizações internacionais, como a UNESCO e Witness.</p>
<p><em>Marília Gehrke</em></p>
<p>Doutoranda em Comunicação e Informação pela Universidade Federal do Rio Grande do Sul (UFRGS), onde também fez mestrado. É jornalista graduada pela Universidade de Santa Cruz do Sul (Unisc), e na mesma instituição realizou aperfeiçoamento em Assessoria em Comunicação Política. Trabalhou como repórter multimídia no interior do RS e pesquisa temas como jornalismo guiado por dados, transparência e desinformação. Integra o Núcleo de Pesquisa em Jornalismo (Nupejor/UFRGS) e o Laboratório de Popularização da Ciência (Popcicom). Auxilia na gestão de cursos da Escola de Dados e integra a rede de pessoas embaixadoras da Open Knowledge. É uma das organizadoras do Open Data Day de Porto Alegre.</p>
<p><em>Marina Gama Cubas</em></p>
<p>Marina Gama Cubas é jornalista de dados. Colabora com investigações e análises de dados em projetos especiais do Aos Fatos. Trabalhou no DeltaFolha, editoria de dados do jornal Folha de S. Paulo, e no Estadão. No exterior, passou pelas seções de dados dos jornais El Mundo, na Espanha, e La Nacion, na Argentina. Possui master em jornalismo investigativo e de dados pela Universidade Rey Juan Carlos, de Madri, e graduações em Comunicação Social e Letras.</p>
<p><em>Rodrigo Menegat</em></p>
<p>Rodrigo Menegat trabalha como jornalista na editoria de infografia digital do Estadão, onde produz reportagens e visualizações feitas a partir da exploração de bases de dados. Antes disso, trabalhou como redator e repórter na Folha de S.Paulo e teve conteúdo publicado em veículos como The Intercept e Agência Pública. É formado em jornalismo pela Universidade Estadual de Ponta Grossa, no Paraná, e fez uma especialização em jornalismo de dados na Universidade de Columbia, em Nova York.</p>
<h1 id="apresentação">Apresentação</h1>
<p>A <a href="https://escoladedados.org">Escola de Dados</a> é o programa da <a href="http://ok.org.br/">Open Knowledge Brasil</a> que tem o objetivo de ajudar pessoas e organizações a transformarem dados em histórias, evidências e mudanças sociais, compartilhando conhecimento, encontros, plataformas e materiais didáticos gratuitos. De 2013 até 2020, já envolvemos mais de 18 mil pessoas em nossas atividades, em todas as regiões do Brasil, e realizamos quatro edições do <a href="https://coda.escoladedados.org">Coda.Br</a>, a maior conferência de jornalismo de dados e métodos digitais da América Latina. Reunindo esta experiência e aproveitando o acúmulo de diversas colaborações com profissionais externos, preparamos esta publicação, que foi viabilizada com o apoio de mais de 280 pessoas em nossa primeira campanha de financiamento coletivo.</p>
<p>Esta publicação é um guia prático destinado a profissionais e estudantes interessados em trabalhar com dados no campo da comunicação, em especial no jornalismo. <strong>O guia é baseado no fluxo de trabalho com dados (<em>data pipeline</em>), uma metodologia desenvolvida pela rede da Escola de Dados internacionalmente, que aborda todas etapas do trabalho</strong>.</p>
<figure>
<img src="images/apresentacao/codabr.jpg" alt="Foto com parte das pessoas participantes da quarta edição do Coda.Br, em 2019" /><figcaption aria-hidden="true">Foto com parte das pessoas participantes da quarta edição do Coda.Br, em 2019</figcaption>
</figure>
<p>O fluxo tem como ponto de partida a definição de uma pergunta ou hipótese, seguida da busca, localização e obtenção dos dados. O passo subsequente envolve a verificação e a limpeza das informações nas bases de dados, de modo que fiquem preparadas para a etapa de análise e, finalmente, para a visualização do conteúdo. Neste material, todas essas etapas serão detalhadas. Por isso, se você é iniciante na área, não se preocupe - este livro foi pensado para você.</p>
<p>Apesar de o apresentarmos de forma linear, tenha em mente que na prática estas etapas em geral costumam ser mais intercaladas. Às vezes, você chegará na etapa de visualização e perceberá que existe um erro nos dados e precisará refazer esta etapa. Como veremos, de fato, a checagem é uma etapa que deve ser transversal a todo o trabalho com dados. Do mesmo modo, um insight obtido com uma visualização pode gerar uma nova questão, que por sua vez irá demandar uma nova coleta e análise. Ainda assim, <strong>a representação do trabalho com dados como um fluxo (pipeline) é útil, especialmente para quem está começando</strong>.</p>
<p>Assim, inicialmente, apresentamos uma breve retrospectiva da comunicação baseada em dados. Falaremos sobre o jornalismo de dados e seus precursores, cujas raízes estão assentadas sobre o método científico, ou seja, o princípio da replicabilidade e a transparência na comunicação das informações. Apresentamos, ainda, as principais tecnologias utilizadas nessas práticas atualmente e uma introdução às linguagens de programação mais relevantes da área.</p>
<p>No capítulo sobre <strong>definição</strong>, vamos discutir como formular uma boa pergunta, refletir sobre temas de interesse público e conhecer os princípios para identificar um bom escopo de investigação. Também veremos que os dados vão muito além do formato de tabelas e indicam não só a quantificação de fenômenos.</p>
<p>Em seguida, falaremos sobre a <strong>obtenção dos dados</strong>. Veremos as diferentes técnicas utilizadas, ferramentas úteis e problemas recorrentes. Nesta etapa, também aprenderemos como usar a Lei de Acesso à Informação para obter dados inéditos e conheceremos os principais formatos de dados abertos.</p>
<p>Posteriormente, trataremos da <strong>checagem e limpeza dos dados</strong>. Veremos que dados podem ser imperfeitos, assim como nós, e aprenderemos como podemos biografar os dados para, assim, identificar suas limitações e possíveis vieses. Na etapa de limpeza, revisaremos ferramentas importantes para deixar os dados prontos para serem analisados e destacaremos alguns pontos que merecem atenção especial. Essas etapas podem parecer menos empolgantes que as demais, mas acredite: elas são essenciais e você provavelmente irá passar bastante tempo nelas ao realizar seus trabalhos.</p>
<p>Depois, no capítulo de <strong>análise de dados</strong>, falaremos sobre operações matemáticas e estatísticas básicas, que são frequentemente empregadas. Também conheceremos operações de análise de dados fundamentais, que são utilizadas em todas as ferramentas e tecnologias, tais como filtragem, ordenação e agrupamento de registros.</p>
<p>No capítulo de <strong>visualização de dados</strong>, veremos as atenções que você deve ter na hora de apresentar o resultado do seu trabalho usando gráficos. Ao mesmo tempo em que esta técnica pode ampliar ampliar nossas capacidades cognitivas, se mal conduzida, pode ser fonte de erros e enganos. Por isso, você irá aprender alguns princípios práticos para elaborar gráficos e conhecerá ferramentas úteis para colocar a mão na massa.</p>
<p>Por fim, na conclusão, você encontra dicas de como seguir sua aprendizagem. Este livro funciona como um guia, e, por meio de inúmeros exemplos, poderá ser consultado inclusive durante a prática jornalística. Ao final desta publicação, separamos referências e dicas de comunidades e plataformas para você se conectar e continuar aprendendo.</p>
<figure>
<img src="images/apresentacao/datapipeline.png" style="width:60.0%" alt="Data pipeline ou o fluxo de trabalho com dados" /><figcaption aria-hidden="true">Data pipeline ou o fluxo de trabalho com dados</figcaption>
</figure>
<h1 id="introdução">Introdução</h1>
<p>Durante a pandemia da Covid-19, gráficos representando o aumento do número de casos ao longo do tempo, por meio de curvas de distribuição, ganharam as notícias e o debate público. <strong>A visualização de dados se tornou <em>mainstream</em>, com o apelo de salvar vidas</strong>. Gráficos são debatidos por especialistas e leigos nas redes sociais, e a interpretação das estatísticas oficiais se revela uma habilidade crucial para a compreensão da pandemia.</p>
<p>A escala do coronavírus e suas implicações não têm precedentes, mas a visualização de dados sobre mortalidade tem um histórico que se confunde com os próprios primórdios da prática de entender e comunicar dados por meio de gráficos. Dois dos trabalhos mais icônicos da história da comunicação baseada em dados estão intimamente ligados à área de saúde e também buscavam, em última instância, salvar vidas. Revisitaremos estas duas visualizações de dados clássicas para em seguida tentar extrair daí algumas lições para o trabalho com dados nos dias de hoje.</p>
<p>Um deles é o gráfico de <strong>Florence Nightingale</strong> sobre as mortes durante a Guerra da Crimeia. Hoje considerada mãe da enfermagem moderna, ela esteve à frente dos cuidados aos soldados ingleses durante as batalhas e também compilou estatísticas sobre a causa de mortalidade dos combatentes.</p>
<figure>
<img src="images/introducao/coxcombchart.jpg" alt="No gráfico, cada fatia representa um mês e a área coberta pelas cores indica as causas de mortalidade: em laranja, mortes em batalha; em azul, por doenças; em verde, outras causas. Fonte: University of Houston." /><figcaption aria-hidden="true">No gráfico, cada fatia representa um mês e a área coberta pelas cores indica as causas de mortalidade: em laranja, mortes em batalha; em azul, por doenças; em verde, outras causas. Fonte: <em>University of Houston.</em></figcaption>
</figure>
<p>Por meio de um gráfico elaborado em 1858, hoje considerado um clássico, ela mostrou que as mortes em combate eram minoritárias, se comparadas àquelas causadas por doenças preveníveis, como aquelas provocadas por má condições de higienes no hospital. Esta forma de representar os dados é conhecida como <strong>diagrama de área polar</strong> (ou <em>coxcomb,</em> em inglês) e é utilizada até os dias atuais. Na imagem, é possível ver como a proporção de mortes por causas evitáveis era constantemente maior ao longo dos meses.</p>
<p>Além de diversas guerras e batalhas, o século XIX teve também seis epidemias de cólera, que mataram milhões de pessoas em diversos continentes. E foi na mesma Inglaterra dos anos 1850 que o médico <strong>John Snow</strong> decidiu levantar dados “geolocalizados” sobre a doença, mapeando os casos e óbitos. Assim, ele elaborou o chamado <strong>mapa da cólera</strong>, que representou os casos da doença como pontos no mapa. A partir da análise dos padrões espaciais e uma intensiva investigação por meio de entrevistas, descobriu uma bomba d’água como vetor de disseminação da cólera no bairro de Soho. À época, Londres experimentava uma expansão urbana somada ao crescimento populacional em condições precárias de moradia e saneamento.</p>
<p>Com isso, John Snow reforçou sua teoria de que a água poderia ser um dos vetores de contaminação, na contramão da chamada teoria miasmática, que era predominante à época e supunha a transmissão por meio do ar. A história mostrou que ele estava certo. Hoje, Snow é considerado um dos nomes fundadores da epidemiologia.</p>
<figure>
<img src="images/introducao/snow.jpg" alt="Mapa da cólera de John Snow na Inglaterra (1854) - Fonte: Wikimedia Commons" /><figcaption aria-hidden="true">Mapa da cólera de John Snow na Inglaterra (1854) - Fonte: Wikimedia Commons</figcaption>
</figure>
<p>Retomamos os exemplos de Snow e Nightingale por uma dupla razão: primeiro, para desfazer um aura de novidade (“hype”), ainda que este tema fique mais evidente em épocas de crise em tópicos de interesse público, como a saúde. Lidar com dados não é exatamente algo recente na experiência humana, tampouco teve início com os computadores digitais. Na verdade, no fundo, <strong>a utilização de dados é praticamente indissociável da experiência humana tal como a conhecemos</strong>.</p>
<figure>
<img src="images/introducao/mapcovid.png" alt="Mapa do novo coronavírus em São Paulo (2020) - Fonte: Labcidade" /><figcaption aria-hidden="true">Mapa do novo coronavírus em São Paulo (2020) - Fonte: Labcidade</figcaption>
</figure>
<p>Os exemplos podem ser diversos. Podem ser até pré-históricos, como quando as contagens eram feitas em artefatos rudimentares, como o osso de Ishango, objeto datado do paleolítico que foi encontrado na África Central e hoje é considerado uma das primeiras formas de armazenamento de dados. Ou ainda o ábaco, inventado durante a Antiguidade no Oriente Médio para facilitar cálculos, e a máquina de Anticítera, um computador analógico para fazer previsões sobre eclipses e as posições dos astros, que foi inventado pelos gregos. Sem dúvida, as tecnologias digitais de armazenamento de dados atuais abrem horizontes novos e bastante amplos, mas é importante lembrar que lidamos com a quantificação da realidade cotidianamente e desde sempre.</p>
<p>Quanto tempo irei levar para chegar ao meu compromisso? Quantas xícaras de farinha preciso colocar no bolo? Qual a diferença de preço entre este e aquele produto? Quantos quilos eu ganhei depois do Natal? Como podemos dividir uma conta igualmente entre as pessoas? São perguntas banais, mas ilustram como sempre lidamos com dados no cotidiano em algum nível, mesmo sem refletir muito sobre isso.</p>
<p>Assim, por um lado, isso deixa claro que qualquer pessoa pode vir a trabalhar com dados. Esta prática não é e não precisa ser restrita a especialistas ou pessoas ligadas às chamadas “áreas de exatas” (matemática, estatística, desenvolvimento de software, etc). Por outro, a segunda razão para retomarmos o exemplo de Nightingale e Snow é para ressaltar um cuidado importante relacionado à comunicação baseada em dados: <strong>qualquer pessoa poder trabalhar com dados, mas isso não significa que eles devam ser tratados de qualquer forma</strong>.</p>
<p>Há alguns ensinamentos que podemos extrair das experiências do século XIX que foram mencionadas, particularmente no que diz respeito ao método científico. Esse tipo de procedimento nos ajuda a ter uma <strong>leitura crítica dos dados para utilizá-los como uma ferramenta de conhecimento - e não como artifício retórico para reforçar crenças e opiniões pré-existentes</strong>.</p>
<p>A ciência pressupõe o acúmulo de conhecimento. Cada cientista estuda uma pequena parte de um tema, ocupando-se de um problema muito específico. A partir de muita leitura - a revisão bibliográfica serve para conhecer o estado da arte de determinada área, ou seja, aquilo que outros pesquisadores já descreveram - e observação da realidade, o cientista está apto a formular e testar sua hipótese.</p>
<p>A descrição detalhada do método é fundamental para que a comunidade científica seja capaz de validar os resultados de uma pesquisa e eventualmente replicá-la integral ou parcialmente. Na academia, os artigos são submetidos à revisão cega por pares - em outras palavras, significa dizer que outros cientistas leram e avaliaram a consistência teórica e metodológica de um trabalho. Em projetos mais complexos e longos, como teses e dissertações, o mesmo ocorre a partir de uma banca avaliadora.</p>
<p>No imaginário social, o estereótipo do cientista geralmente é formado por uma pessoa de jaleco branco que trabalha em um laboratório conduzindo experimentos químicos. A realidade, no entanto, sugere uma fotografia mais ampla: cientistas também usam roupas normais e trabalham apenas no computador em salas convencionais nas universidades ou mesmo de casa. Assim também se faz ciência, e com métodos igualmente rigorosos.</p>
<p>Neste guia, não iremos abordar a área de ciência de dados em si, ainda que muitos dos conceitos e técnicas que iremos abordar aqui sejam emprestados desta área. Nosso enfoque será a comunicação baseada em dados, especialmente na área do jornalismo. <strong>Da ciência, iremos tomar emprestada principalmente a inspiração no método, para que possamos conduzir trabalhos mais sólidos e robustos</strong>.</p>
<p>Embora o jornalismo não seja uma ciência propriamente dita, visto que trabalha com a ideia de pauta e de um conhecimento menos formal e sistemático, pode aproximar-se do rigor metodológico à medida que abre suas fontes, seus dados e o passo a passo empreendido para obter um resultado. É neste contexto que a ideia de replicabilidade entra em cena e pode ser apropriada tanto pelos leitores quanto por outros jornalistas. Ao longo deste guia, veremos como podemos nos inspirar no método científico para produzir conteúdos baseados em dados com mais rigor e qualidade.</p>
<p>Em tempos de debates acalorados na internet, é comum que as pessoas busquem os dados apenas quando querem legitimar seus argumentos. Há quem fale até em “torturar os dados” para que confessem o que o analista deseja. Aqui, porém, trabalharemos a perspectiva oposta.</p>
<p>É importante que você <strong>seja cético em relação aos seus dados</strong>. A respeito deste tema, vale conferir o artigo <a href="https://escoladedados.org/2019/08/sou-uma-cientista-de-dados-cetica-quanto-aos-dados/"><em>Sou uma cientista de dados cética quanto aos dados</em></a> de Andrea Jones-Rooy, professora de Ciência de Dados na New York University. Ao trabalhar com investigações baseadas em dados, seu objetivo não é encontrar números que confirmem sua hipótese ou aquilo que você (acha que) sabe. Ao contrário, você deve olhar os dados sob uma perspectiva crítica, ao invés de adotá-los como uma representação objetiva da realidade.</p>
<p>Em especial se você não é um especialista no tema que está abordando, provavelmente, sua autocrítica talvez não seja capaz de avaliar todas as possíveis nuances dos dados ou erros de uma análise. Por isso, <strong>para fazer sentido de tabelas ou dados, é importante também conhecer como eles foram produzidos e, se possível, entrevistar ou conversar com diferentes pessoas que entendam mais que você sobre o tema em questão</strong>, seja o novo coronavírus, a performance de um clube em um campeonato esportivo ou mesmo dados sobre o mercado de trabalho.</p>
<p>No fim das contas, como na ciência, a <strong>transparência também é fundamental na comunicação</strong>. Então, sempre que possível, disponibilize os dados utilizados ou a referência de onde eles se encontram. Dessa forma, as pessoas poderão refazer o passo a passo da sua análise - remetendo ao princípio da replicabilidade científica - se assim desejar. Aprender a programar também ajuda, pois assim você consegue documentar e compartilhar todas as etapas de processamento, análise e até visualização dos dados. Além de tornar seu trabalho mais confiável, a publicação de scripts e programas com código-aberto permite que outras pessoas possam revisar o trabalho feito, identificar possíveis erros (sim, isso é ótimo!), entender como ele foi feito e aprender com a sua experiência.</p>
<p>Visto que o jornalismo envolve a produção de conhecimento a partir da observação da realidade, semelhante ao que ocorre na ciência, desenvolveram-se diversas teorias e práticas para aproximar estes dois campos ao longo do século XX. O primeiro grande esforço sistemático neste sentido foi feito por Philip Meyer, criador do chamado <strong>“jornalismo de precisão”</strong>.</p>
<p>Meyer se destacou por aplicar métodos das ciências sociais no jornalismo. No ano de 1967, em meio à luta do movimento negro por direitos civis nos EUA, durante a cobertura de protestos em Detroit, ele decidiu aplicar técnicas de pesquisas amostrais (survey) para entender a opinião pública e as causas das manifestações a partir da perspectiva da população local. Algo com intuito parecido ao que um repórter ou uma organização faz ao coletar depoimentos de pessoas sobre determinado tema, mas com o objetivo de refletir a opinião coletiva de um grupo social em vez de opiniões individuais.</p>
<p>Ainda nos anos 1960, Philip Meyer e sua equipe criaram uma amostra das residências em regiões de manifestações, entrevistaram 437 pessoas e utilizaram um computador para testar hipóteses e processar os resultados, <a href="https://s3.amazonaws.com/s3.documentcloud.org/documents/2070181/detroit1967.pdf">culminando nesta apresentação</a>. Na contramão de discursos que circulavam à època, inclusive na própria imprensa, a pesquisa mostrou que os manifestantes não eram pessoas de baixa educação e que apoiavam atos violentos. Formação ou renda não eram fatores distintivos entre aqueles que participavam dos atos, mas o desemprego, sim. Além disso, os participantes da pesquisa apontaram possíveis causas para os atos violentos, que até então não recebiam a devida atenção, como violência policial ou condições de habitação precárias.</p>
<figure>
<img src="images/introducao/detroit.jpg" alt="Prisioneiros dos protestos de Detroit em 1967 - Fonte: Wystan/Flickr" /><figcaption aria-hidden="true">Prisioneiros dos protestos de Detroit em 1967 - Fonte: <a href="https://www.flickr.com/photos/70251312@N00/6176169705">Wystan/Flickr</a></figcaption>
</figure>
<p>Ao defender uma guinada do jornalismo em direção à ciência, Meyer acreditava na ampliação do papel do repórter e na menor dependência de fontes oficiais. Dessa forma, como no caso de Detroit, acreditava que os próprios jornalistas deveriam fazer a coleta de dados para responder às questões levantadas no dia a dia da profissão. A cobertura do colapso social do final da década de 1960 rendeu a Meyer e sua equipe o primeiro lugar na categoria de jornalismo local no Prêmio Pulitzer.</p>
<p>Posteriormente, o jornalismo de precisão inspirou práticas como a Reportagem Assistida por Computador (RAC) - ou Computer-Assisted Reporting (CAR), em inglês -, desenvolvida especialmente nos anos de 1980 nos Estados Unidos. Com a disseminação do uso de computadores no ambiente de trabalho dos jornalistas, surgiram novidades nos procedimentos de apuração. Nos primórdios da RAC, o uso de softwares simples para resolver problemas e obter informações já era motivo para comemorar.</p>
<p>No final dos anos de 1990, Meyer sugeriu que se pensasse em outro nome para substituir a RAC. Ele admitiu que o termo ficou datado por apresentar a palavra “computador” em sua composição, destacando uma ferramenta utilizada para a apuração jornalística. Tampouco o “jornalismo de precisão” obteve sucesso como conceito amplamente difundido.</p>
<p>Atualmente, porém, parte das premissas do jornalismo de precisão e da RAC são levadas a cabo por práticas do chamado jornalismo de dados. Dados são abundantes e habilidades básicas de análise são exigidas atualmente em diversos campos da comunicação. <strong>O jornalismo de dados - também conhecido como jornalismo guiado por dados (data-driven journalism) - pode envolver todas as etapas do trabalho, desde a coleta até a visualização das informações</strong>.</p>
<p>Quando publicou o artigo <a href="http://www.holovaty.com/writing/fundamental-change/"><em>A fundamental way newspaper sites need to change</em></a>, em 2006, o programador Adrian Holovaty defendia que os jornalistas se preocupassem com o uso de informações estruturadas. Isto é, que os repórteres não coletassem apenas informações para uma pauta específica, mas que refletissem sobre sua organização sistemática, facilitando a recuperação e o reuso do que já foi apurado. Em vez de somente divulgar informações sobre um incêndio específico, por exemplo, os jornalistas deveriam coletar aspectos que todos os incêndios têm em comum (localização, número de vítimas, tempo de atendimento, prejuízo etc.) para, com a formatação de um banco de dados, identificar padrões e obter informações mais abrangentes e contextuais.</p>
<p>Embora estes recursos ainda sejam utilizados hoje e as reflexões de Holovaty sigam atuais, planilhas e consultas online em portais da transparência remetem à primeira metade dos anos 2000, em que havia menos conhecimento técnico e disponibilidade de matéria-prima aberta e acessível aos jornalistas de dados. O professor Paul Bradshaw classifica a segunda década (2010-2020) do jornalismo de dados como uma “<a href="https://medium.com/@paulbradshaw/the-next-wave-of-data-journalism-7e2e10087bb3">segunda onda</a>”, permeada por um movimento global pela abertura de dados, acesso às APIs e a inserção de algoritmos neste cenário, incluindo inteligência artificial e a internet das coisas.</p>
<p>Bradshaw defende que os jornalistas de dados abram seus códigos e submetam suas fontes e métodos ao escrutínio público, pois assim os cidadãos ganham conhecimento sobre sua própria realidade. <strong>Ao obter informações sobre a sociedade onde vivem, as pessoas passam a ter condições de cobrar o poder público com mais veemência sobre suas demandas, por exemplo. Outro ponto destacado é o potencial que o jornalismo de dados tem em dar voz às minorias ao divulgar informações quantificáveis e que tendem a circular pouco</strong>. Assim, é possível perceber que não só a tecnologia importa ao jornalismo de dados - as demais premissas da prática jornalística, relacionadas à produção de informação qualificada e à fiscalização do poder público, são mantidas e intensificadas.</p>
<p>Como mencionamos, uma das características do jornalismo de dados desta “segunda onda” é o uso de algoritmos de inteligência artificial (IA). Em um texto sobre o assunto, o artigo <a href="https://qz.ai/how-youre-feeling-when-machine-learning-might-help/"><em>How you’re feeling when machine learning might help</em></a>, Jeremy B. Merril elenca algumas características úteis deste tipo de tecnologia para jornalistas. Ele desta a possibilidade dessas técnicas processarem um volume enorme de documentos, que seriam impossíveis de ser lido por humanos, em busca de padrões.</p>
<p>Ele cita o exemplo do Atlanta Journal-Constitution, que usou o aprendizado de máquina para identificar relatórios de sanções contra médicos relacionados a abuso sexual. A equipe de dados do jornal desenvolveu cerca de 50 raspadores para diferentes sites, que permitiram a coleta de mais de <a href="http://doctors.ajc.com/about_this_investigation/">100 mil documentos de agências reguladoras</a>. Como era impossível ler e categorizar manualmente todos os relatórios, eles selecionaram uma amostra relevante e fizeram esta categorização manual, escolhendo palavras-chave que identificavam relatos de abuso sexual dos demais casos.</p>
<p>Então, treinaram uma solução de aprendizado de máquina que baseado nessas palavras assinalava quais relatórios eram provavelmente mais interessantes para a investigação. Claro que a solução não nasce pronta. Foi necessário encontrar as melhores palavras-chaves por meio de tentativa e erro, observando os resultados das escolhas utilizadas. Porém, é um exemplo interessante do potencial da inteligência artificial para lidar com uma documentação muito vasta.</p>
<p>Neste sentido, uma solução simples, de código-aberto e interessante tanto para jornalistas quanto para organizações é o <a href="https://www.documentcloud.org/">DocumentCloud</a>, uma ferramenta que consegue “ler” dados em documentos, tabelas e PDFs para então realizar a extração de entidades automaticamente, identificando menções a pessoas, locais ou datas em cada documento.</p>
<p>Outros casos de uso mencionados por Merril incluem a chamada computação visual e a identificação de dados que possuam um certo padrão. As aplicações são várias e vale ler o artigo completo, caso você tenha interesse no tema. Por ora, o importante é saber que a <strong>inteligência artificial e o aprendizado de máquina permitem converter uma quantidade incontrolável de informações em algo gerenciável, gerando taxonomias e classificações a partir dos dados fornecidos</strong>.</p>
<p>Por ser introdutório, este guia não irá cobrir temas como o uso de algoritmos de IA na comunicação, uma área que começa a despontar agora. Por ora, o importante é saber que, mesmo com IA e independente da tecnologia utilizada, as conclusões de investigações baseadas em dados não devem ser encaradas como uma tradução objetiva da realidade.</p>
<h2 id="nada-dado-nos-dados">Nada dado nos dados</h2>
<p>O que são dados, afinal? Essa é uma pergunta importante. Existem várias definições possíveis. De modo geral, podemos dizer que a produção de dados é baseada na quantificação ou estruturação do mundo. Mencionamos “produção” não por acaso: <strong>dados não dão em árvore, ou seja, não são entidades que não existem por si só na natureza</strong>.</p>
<p>Dados são construções humanas para tentar abstrair (ou tentar “representar”, com muitas aspas) fenômenos complexos da realidade através de elementos quantificáveis, que por sua vez são passíveis de serem analisados. Um dado sempre implica um determinado escopo, um recorte. Eles são construídos baseados em conceitos e, por vezes, em preconceitos. Os dados não são neutros ou puramente objetivos, eles traduzem visões de mundo.</p>
<p>Em suma, não há nada dado nos dados. Dados são sempre construídos e, por serem construções humanas, assim como nós, estão sujeitos a erros de diferentes tipos. Devemos ter sempre ter isso em mente ao analisá-los.</p>
<p>Os dados podem ser encarados como uma fonte como outra qualquer, embora sejam “entrevistados” de forma diferente. Assim como você não considera automaticamente verdade tudo que uma pessoa diz, você também não deve “comprar pelo valor de face” tudo que os dados apontam.</p>
<p>Imagine esta cena: um repórter recebe a ligação de uma fonte, ou seja, uma pessoa que tem coisas interessantes para contar e que quer que essas coisas sejam publicadas no jornal. Essa tal fonte pode ser um assessor de imprensa, um político, um dissidente com documentos para vazar, um juiz, um promotor, um pesquisador. De todo modo, ela tem interesses pessoais – que podem ser completamente nobres – embutidos nas informações que divulga.</p>
<p>Do mesmo modo, como identificado pela pesquisadora Marília Gehrke em sua <a href="https://lume.ufrgs.br/bitstream/handle/10183/172614/001060430.pdf?sequence=1">dissertação de mestrado</a>, também podem ser fontes bancos de dados, estudos científicos, pesquisas das mais diversas naturezas, documentos públicos, legislações, sites de redes sociais e outros. A diferença é que essas fontes não podem ser acessadas a partir de pergunta e resposta diretas; elas pressupõem outro tipo de consulta, que não alteram sua natureza documental.</p>
<p>Ainda que apresentem caráter oficial, bancos de dados e outras fontes documentais podem servir para a obtenção de pautas exclusivas, visto que não estão estruturadas em formato de release nem são disparadas para a imprensa de modo geral. Exigem, sim, o esforço do repórter na elaboração de uma hipótese ou pergunta que dará início à investigação e, depois, na coleta e no tratamento das informações. Para valorizar ainda mais o caráter exclusivo, algumas redações optam por construir os seus próprios bancos de dados, realizando análises inéditas.</p>
<p>Em sua <a href="http://tede2.pucrs.br/tede2/bitstream/tede/4590/1/461784.pdf">tese de doutorado</a>, o pesquisador Marcelo Träsel entrevistou diversos jornalistas brasileiros que usam dados em suas tarefas cotidianas na redação.</p>
<p>Por meio dos procedimentos de apuração - que costumam ter etapas mais bem delineadas na execução do jornalismo de dados em comparação às práticas tradicionais -, esses profissionais acreditam estar mais próximos da noção de objetividade no método jornalístico, cuja concretização leva em conta a correspondência do relato jornalístico à realidade dos fatos.</p>
<p>O poder de mergulhar em números permite ao repórter contestar as narrativas mais óbvias oferecidas por fontes institucionais. Além disso, na contramão de simplesmente reproduzir declarações ou noticiar informações de bastidores, jornalistas de dados se utilizam de recursos (números e planilhas) que podem ser facilmente disponibilizados e verificados por terceiros (leitores e colegas da imprensa, por exemplo).</p>
<p>Como já dissemos, os bancos de dados entram no cardápio de fontes, e devem ser consideradas como tal - vistas de forma crítica, portanto. Para caracterizar seu trabalho como jornalista de dados, Kátia Brembatti, do jornal Gazeta do Povo, fez uma alusão a “entrevistar planilhas” enquanto participante da pesquisa, expressão que se tornaria o título da tese de Träsel.</p>
<p>Brembatti assinou uma série de reportagens conhecida como “Diários Secretos”, que expôs um esquema de nomeação de funcionários fantasmas na Assembleia Legislativa do Paraná. Seu trabalho consistiu em organizar uma série de informações em arquivos de Excel para descobrir fatos de interesse público.</p>
<p>O esquema envolvia esconder alguns dos Diários Oficiais que continham referências às nomeações irregulares - e o trabalho de reportagem foi reunir documentos que expunham toda a trama. À medida que os dados eram sistematizados, a equipe envolvida na investigação conseguia respostas para suas perguntas, quase como se estivesse ganhando a confiança de um informante particularmente ruim de lidar.</p>
<p>Pensar nos dados como um entrevistado faz bastante sentido – principalmente porque desmistifica a ideia de que um dado é um fato encerrado, definitivo. Como qualquer entrevistado, um banco de dados tem sua história, seus vieses e um bom motivo para apresentar as informações da forma que está apresentando.</p>
<p>Por esses e outros motivos, há críticas quanto ao termo “dados brutos”, já que em sua origem essas informações foram coletadas, selecionadas e disponibilizadas por pessoas. Dados nunca são “brutos”, são sempre moldados por uma forma de abstrair uma realidade complexa em termos quantificáveis.</p>
<p>Por isso, é comum que, ao longo de um trabalho, os dados se tornem cada vez menos autoevidentes. Ao aprofundar suficientemente um determinado tema, os dados trazem consigo, muitas vezes, um emaranhado de questões sobre a forma como foram criados. Assim, vale consultar com atenção as notas metodológicas e os dicionários de variáveis que geralmente acompanham as bases de dados. A leitura da documentação é essencial para compreender o escopo e as limitações de determinado conjunto de informações, evitando problemas nas análises.</p>
<h2 id="trabalhando-com-dados">Trabalhando com dados</h2>
<p>Saber lidar com dados abre caminhos para quem deseja ter mais autonomia e ser menos dependente de informes oficiais ou trabalhos de terceiros para analisar informações e obter suas próprias conclusões. O percurso de aprendizagem não é óbvio e muitas vezes não está disponível na grade curricular das universidades. Dessa forma, os profissionais costumam buscar por conta própria conhecimentos relacionados ao “letramento em dados” (data literacy) e outros tópicos.</p>
<p>Se este é o seu primeiro contato com o universo dos dados, não se preocupe. Muitas pessoas não se interessam em trilhar esses caminhos por se sentirem inaptas a trabalhar com números ou programação. No entanto, isso pode ser enganoso. <strong>A facilidade em trabalhar com estatísticas ou escrever códigos no computador não precisa ser um ponto de partida, mas pode ser algo que você adquire durante o aprendizado</strong>. Se você sente essa dificuldade, tudo que você precisa é ter cuidado na hora de comunicar os resultados das suas análises e pedir ajuda de pessoas com mais conhecimentos, quando necessário.</p>
<p>Além disso, atualmente, é possível realizar análises e visualizações bastante interessantes, fazendo tudo por meio de interfaces gráficas. De fato, em muitos trabalhos, especialmente aqueles que requerem pouca customização, importa menos a solução tecnológica utilizada e mais o conteúdo e o impacto da ação em si.</p>
<p>Existem diversos serviços e programas gratuitos que permitem a criação de trabalhos sofisticados sem a necessidade de escrever uma linha de código, como o <a href="https://workbenchdata.com/">Workbench</a>, <a href="https://www.tableau.com/pt-br">Tableau</a> ou mesmo o <a href="https://orange.biolab.si/">Orange</a>, que trabalha até com algoritmos de inteligência artificial. Neste guia, iremos citar alguns deles e dar algumas dicas de ferramentas, mas nosso foco será te passar uma base que te permitirá lidar com diferentes plataformas e tecnologias.</p>
<figure>
<img src="images/apresentacao/orange.png" alt="O Orange é um exemplo de programa com interface gráfica para trabalhar com dados, por meio de fluxos visuais. Fonte: Wikimedia Commons" /><figcaption aria-hidden="true">O Orange é um exemplo de programa com interface gráfica para trabalhar com dados, por meio de fluxos visuais. Fonte: Wikimedia Commons</figcaption>
</figure>
<p>De fato, as possibilidades são muitas, mas, se você está começando, vá com calma. Um passo de cada vez. Antes de se aventurar com visualizações interativas ou modelos estatísticos elaborados, é importante dominar o básico, como o uso de editores de planilha e a criação de gráficos simples.</p>
<p>Muito se ouve falar em <em>big data</em>, mas saiba que <a href="https://www.youtube.com/watch?v=2oFGpDFUnMc">boas histórias também podem ser extraídas de planilhas</a> de menor porte. A dica para começar a trabalhar com dados é encontrar algum tema que te motive por alguma razão, seja porque você tem paixão pelo assunto, seja porque é uma demanda do seu trabalho ou simplesmente algo que você gostaria aprender mais a fundo.</p>
<p>Uma possível definição é que a expressão big data indica um volume de dados tão grande que um computador só não consegue processar. Fique tranquilo: você provavelmente não precisará disso em suas análises. Para bases muito grandes, você pode importar os dados em um banco de dados SQL, seja no seu próprio computador ou utilizando serviços online como o BigQuery da Google.</p>
<p>A ideia aqui é aprender a trabalhar com dados a partir de um “mini-projeto”; real que te motive de alguma forma, buscando soluções para os problemas reais que enfrentar, em vez de tentar dar conta de todas as possibilidades de aprendizado na área de antemão. Na próxima seção, falaremos sobre uma outra dúvida comum para quem está começando na área: é preciso aprender a programar para trabalhar com dados?</p>
<h2 id="iniciação-à-programação">Iniciação à programação</h2>
<p>Ainda que não seja mais um obstáculo para começar a trabalhar com dados, saber programar de fato abre muitas possibilidades nessa área. Lidar com a obtenção, processamento, análise ou visualização de dados por meio de códigos te dá liberdade quase total para trabalhar. Você pode realizar as operações diretamente, sem as restrições de programas de terceiros, além de automatizar tarefas, documentar e compartilhar todas etapas de manipulação dos dados.</p>
<p>De modo geral, existem vantagens tanto nas soluções via interface gráfica quanto nas baseadas em linguagens de programação.</p>
<hr />
<p><strong>Vantagens de usar interfaces gráficas</strong></p>
<ul>
<li>Curva de aprendizado baixa: para leigos, é mais fácil aprender a usar programas com interfaces gráficas;</li>
<li>Poupa tempo: especialmente se você não é fluente em alguma linguagem de programação, muitas vezes, poderá conseguir executar tarefas de forma mais rápida com interface gráfica.</li>
</ul>
<p><strong>Vantagens de programar</strong></p>
<ul>
<li>Alta customização: o software será totalmente adaptável às suas necessidades;</li>
<li>Automação: é muito fácil automatizar tarefas com programação, mas nem todos programas gráficos suportam isso;</li>
<li>Escalabilidade: do mesmo modo, é fácil aumentar a escala de um software próprio para que ele lide com um volume maior de dados, por exemplo.</li>
</ul>
<hr />
<p>É comum, por exemplo, a criação de “notebooks” (blocos de notas), que trazem não só os dados, mas também os códigos que foram utilizados em determinado trabalho, além de comentários adicionais. Esta prática permite um excelente grau de transparência e detalhamento da conclusão e do método utilizado em trabalhos baseados em dados.</p>
<figure>
<img src="images/introducao/notebook.png" alt="Um notebook sobre análise de texto em ação, mostrando textos, códigos e o resultado dos códigos" /><figcaption aria-hidden="true">Um notebook sobre análise de texto em ação, mostrando textos, códigos e o resultado dos códigos</figcaption>
</figure>
<p>É possível trabalhar com dados em qualquer linguagem de programação. Porém, iremos falar aqui especificamente sobre quatro linguagens que se destacam pela sua ampla utilização em projetos baseados em dados atualmente.</p>
<p>A primeira delas é o <strong>SQL</strong>, uma abreviação para linguagem de consulta estruturada (Structured Query Language, em inglês). O SQL é um excelente ponto de partida para quem ter um primeiro contato com códigos para qualquer tipo de profissional, devido ao uso de palavras comuns em inglês para as operações (“select”,“from”, “group by”, etc). Esta linguagem incrivelmente simples permite consultar tabelas enormes, que “travariam” qualquer editor de planilha.</p>
<p>O SQL pode ser uma porta de entrada para o mundo da programação, visto que demanda o uso de lógica computacional. Para começar a usar SQL, você pode experimentar softwares como o <strong>DB Browser for SQLite</strong> e <strong>Dbeaver</strong>. Você pode também utilizar o SQL em conjunto com linguagens como Python e R, que falaremos a seguir, ao lidar com um volume grande de dados. Por ser uma tecnologia voltada especificamente para o armazenamento e processamento de bases de dados, o SQL tem uma performance superior às soluções nativas daquelas linguagens para lidar com muitos registros.</p>
<p>Outra opção é o <strong>JavaScript</strong>, uma linguagem especialmente interessante para designers ou pessoas interessadas em se aprofundar para valer com visualização de dados na web. Ao lado do HTML e do CSS, o JavaScript é uma das linguagens que dão as bases para as páginas web tal como a conhecemos. Mais especificamente, ela é responsável por permitir interatividade e dinamicidade entre os elementos de uma página, como quando você clica no botão de fechar de uma propaganda e ele some de sua tela.</p>
<p>O JavaScript não costuma ser tão utilizado em projetos de raspagem ou visualização de analisar dados, mas é especialmente interessante para visualização. A biblioteca D3.JS destaca-se como uma das principais referências para trabalhos do tipo.</p>
<p>Porém, se você está interessado em linguagens mais flexíveis, com as quais seja possível realizar com facilidade operações das diversas etapas do trabalho com dados, então, precisa conhecer as duas estrelas dessa área: <strong>Python</strong> e <strong>R</strong>.</p>
<p>Ambas são consideradas o “estado da arte” para projetos de ciência de dados e são amplamente utilizadas não só por cientistas, estatísticos ou desenvolvedores, mas também por jornalistas, pesquisadores das ciências humanas e organizações da sociedade civil.</p>
<p>Cada uma delas conta com milhares de bibliotecas ou pacotes, que nada mais são que softwares escritos nas respectivas linguagens que expandem suas funcionalidades nativas para melhor performar tarefas específicas. A quantidade de pacotes e bibliotecas disponíveis é surpreendente. Suas funcionalidades são muitas: podem servir para estruturar dados a partir de páginas na web, criar visualizações de dados, modelos estatísticos, rotinas de automação e etc.</p>
<p>Para quem está começando, os comandos básicos de ambas são igualmente simples, mas a real complexidade de cada linguagem vai depender do seu objetivo, dos softwares já disponíveis para facilitar esta tarefa e do tempo/conhecimento disponível por você ou sua equipe.</p>
<p>Você pode escolher uma ou aprender ambas, o que te dará bastante flexibilidade. Mas vamos aqui destacar algumas características gerais sobre estas linguagens para você se situar.</p>
<p>De acordo com a <a href="https://spectrum.ieee.org/static/interactive-the-top-programming-languages-2020">revista do Institute of Electrical and Electronics Engineers</a>, Python foi considerada a linguagem mais popular do mundo. Flexível e moderna, permite a utilização em aplicações diversas ao mesmo tempo em que mantém uma curva de aprendizado suave, com códigos simples e legíveis. Python é uma linguagem robusta, que pode ser utilizada não só para trabalhar com dados, como também para distintas aplicações (Web, administração de redes entre outras). O índice de pacotes em Python conta quase 250 mil projetos disponíveis.</p>
<p>Já o R costuma ser preferido por estatísticos e acadêmicos de diversas áreas. A linguagem leva a fama de ter bibliotecas que produzem gráficos e visualizações mais caprichadas e também conta com um rico universo de bibliotecas de softwares para trabalhar com dados. Atualmente, no <a href="https://cran.r-project.org/web/packages/available_packages_by_name.html">CRAN</a>, o principal repositório da linguagem, estão listadas mais de 16 mil bibliotecas - isso sem contar outras bibliotecas disponíveis em outra fontes.</p>
<h1 id="defina">Defina</h1>
<p>Na prática, tudo começa com os dados ou um tema. Ou seja, em geral, no início de um projeto ou investigação baseada em dados, você irá se encontrar em uma destas duas situações: 1) você tem diante de si dados dos quais precisa extrair respostas ou 2) possui um tema, questão ou hipótese a ser estudada.</p>
<p>Na primeira situação, você já obteve os dados, mas precisa explorá-los para gerar novos conhecimentos ou responder a uma questão definida a priori. Ou seja, seu escopo inicial de certa forma já está definido. O recomendável aqui é compreender pelo menos o básico sobre análise exploratória e análise de dados para conseguir interpretar melhor os resultados - iremos falar sobre isso nos capítulos seguintes.</p>
<p>Já se você estiver abordando um tema bem específico, pode ser necessário também que você estruture sua própria base de dados. Organizar bases de dados inéditas pode ser um diferencial importante na sua proposta. Projetos premiados e reconhecidos no Brasil, como o <a href="https://g1.globo.com/monitor-da-violencia/noticia/monitor-da-violencia-do-g1-vence-o-data-journalism-awards-na-categoria-escolha-do-publico.ghtml">Monitor da Violência</a> e o <a href="http://produtos.ne10.uol.com.br/umaporuma/index.php">Uma Por Uma</a>, seguiram esta linha. Neste guia, não iremos cobrir o processo de publicação de dados inéditos, porém, de todo modo, as demais etapas do fluxo de trabalho com dados (para além da obtenção) seguem sendo úteis.</p>
<p>Mas nem sempre você terá os dados de antemão ou poderá criá-los. Especialmente se você está começando, talvez você tenha apenas uma questão ou um tema que gostaria de pesquisar. Aqui, vale ressaltar que qualquer assunto pode ser investigado a partir de dados. Para te inspirar, vamos listar aqui alguns temas e trabalhos inspiradores, que vão além dos assuntos mais óbvios (indicadores oficiais do governo, estatísticas de esportes, dados de mercado, etc):</p>
<ul>
<li><p><strong>Nutrição</strong>: se você se preocupa com sua alimentação, você pode compilar e fazer análises sobre os dados da composição nutricional dos alimentos de sua dieta ou que estão na sua geladeira, por exemplo;</p></li>
<li><p><strong>Cultura</strong>: a produção musical e cinematográfica estão entre as áreas da cultura com bases de dados mais bem estruturadas (vide o Spotify ou <a href="http://www.omdbapi.com/">O</a><a href="http://www.omdbapi.com/">MDB</a>) e você pode tirar proveito disso para investigar seu tipo de música ou filme favorito, por exemplo;</p></li>
<li><p><strong>Moda</strong>: neste excelente trabalho do <a href="https://pudding.cool/2018/08/pockets/">The Pudding</a>, eles investigaram como a indústria da moda lida com as questões de gênero ao desenhar o tamanho dos bolsos nas roupas, a partir de dados;</p></li>
</ul>
<figure>
<img src="images/defina/pudding.png" alt="Para investigar o tema, os jornalistas pegaram o tamanho do bolso da frente de 80 calças de ambos os sexos para então calcular o tamanho médio. Fonte: The Pudding" /><figcaption aria-hidden="true">Para investigar o tema, os jornalistas pegaram o tamanho do bolso da frente de 80 calças de ambos os sexos para então calcular o tamanho médio. Fonte: The Pudding</figcaption>
</figure>
<ul>
<li><strong>Transporte por bicicletas</strong>: no projeto <a href="https://interaktiv.tagesspiegel.de/radmesser/">Radmesser</a>, o jornal alemão Der Tagesspiegel investigou a segurança no trânsito para os ciclistas em Berlim, criando um dispositivo que media a distância entre os carros e as bicicletas e distribuindo entre seus leitores, que coletaram dados e compartilharam com o jornal. O trabalho recebeu o prêmio de inovação do Data Journalism Awards em 2019.</li>
</ul>
<p>Enfim, você consegue usar dados para abordar qualquer assunto. Depois de encontrar um tema de seu interesse, você precisa gerar algumas perguntas iniciais que possam ser investigadas e respondidas com auxílio de dados. A definição desta “pauta” inicial é bastante importante para o desenrolar da pesquisa. Vejamos, então, como criar boas questões ao iniciar um trabalho com dados.</p>
<h2 id="criando-boas-perguntas">Criando boas perguntas</h2>
<p>O exercício de começar a investigação com uma pergunta é exatamente o oposto de já ter uma certeza e ir atrás dos dados que a confirmam. Reflita inicialmente sobre qual é a sua questão motivadora, esmiuçando-a o máximo possível. Por que essa é uma questão relevante? Quando/como/onde ela ocorre? Quem são as pessoas ou atores envolvidos? Qual é a definição exata de cada termo implicado na sua pergunta?</p>
<p>Vejamos tudo isso aplicado a um exemplo prático. Digamos que você queira investigar o transporte público rodoviário em sua cidade. Uma primeira pergunta poderia ser: quais são as empresas que atuam neste mercado?</p>
<p>Esta pergunta, que parece simples e objetiva, pode ser ainda melhor detalhada.</p>
<p>Primeiro, o que entendemos como empresas atuante no mercado rodoviário da cidade? São aquelas que possuem concessões públicas com a Prefeitura no presente momento? Ou com concessões vencidas também? Os ônibus intermunicipais serão levados em conta? E se a firma dona da concessão for controlada por outra empresa, esta segunda empresa deve entrar em nossa listagem? O interesse é apenas saber o nome das empresas ou gostaríamos de obter outras informações, tais como o nome dos donos ou data de criação das mesmas?</p>
<p>Enquanto você formula e detalha sua pergunta, faça uma pesquisa intensa sobre o assunto do seu interesse. Quais outras publicações já abordaram o tema? Quais foram as fontes de dados utilizados? Quais foram as análises, seus pontos fortes e fracos?</p>
<p><strong>Atenção:</strong> tenha um cuidado especial ao formular questões que envolvam causalidade. Estabelecer a causalidade entre dois fenômenos é algo bastante complexo. Falaremos mais sobre isso no capítulo sobre análise de dados.</p>
<p>A pergunta mencionada sobre o transporte rodoviário foi a questão seminal da investigação realizada por Adriano Belisário (coautor e organizador do ebook) e a equipe da Agência Pública, que resultou em uma série de reportagens publicadas no <a href="https://apublica.org/especial/especial-catraca/">Especial Catraca</a>. A partir de levantamentos de dados para responder àquela simples pergunta inicial, a investigação revelou relações inéditas entre deputados e empresários do ramo, por exemplo.</p>
<figure>
<img src="images/defina/redes.png" alt="Visualização interativa da rede de empresas e empresários de ônibus no município do Rio de Janeiro" /><figcaption aria-hidden="true">Visualização interativa da rede de empresas e empresários de ônibus no município do Rio de Janeiro</figcaption>
</figure>
<p>Obviamente, esboçar uma questão sempre requer algum grau de conhecimento sobre o tema e, quanto mais você se aprofundar, melhores perguntas conseguirá fazer. Ao longo de sua pesquisa, é comum que você detalhe, aprofunde ou mesmo mude completamente a questão que irá te guiar. Não se preocupe em fazer a pergunta perfeita ou definitiva, mas esforce-se para que ela seja detalhada e o mais objetiva possível.</p>
<p>Com este processo, além de questões robustas, você provavelmente terá uma ou mais hipóteses, ou seja, possíveis respostas ou explicações para suas perguntas iniciais.</p>
<p>Depois de identificar e obter os dados, certifique-se que se você sabe suficientemente sobre o contexto no qual ele foi produzido. Quem produziu os dados? Quais são os interesses dessa organização ou instituição? Qual foi a metodologia de registro das informações? Ter respostas a essas perguntas é fundamental para você realizar uma leitura crítica dos dados.</p>
<p>Posteriormente, talvez seja preciso adaptar sua pergunta principal para questões que possam ser respondidas utilizando os dados obtidos. Neste momento, é possível não só testar suas hipóteses, como também explorar os dados para experimentar novas análises, que não estavam no foco da questão inicial, mas podem ser descobertas. Manter esta abertura te permite extrair novos insights na sua pesquisa. Fique atento a valores ou padrões inesperados e tente compreendê-los. Muitas vezes, isto o fará inclusive redefinir a sua pergunta inicial.</p>
<h2 id="reconhecendo-um-bom-escopo">Reconhecendo um bom escopo</h2>
<p>Para te ajudar neste processo, vamos elencar aqui algumas características de um escopo bem definido, no caso de pesquisas baseadas em dados. O objetivo aqui não é limitar sua abordagem, mas destacar aspectos importantes a serem levados em conta.</p>
<p><strong>É objetivo</strong></p>
<p>Busque definir seu escopo objetivamente e de forma concisa. Isto implica abordar um único problema ou tópico central por vez, mesmo que você tenha várias questões relacionadas a ele. Um escopo bem definido descreve a definição de cada termo ou conceito envolvido nas questões centrais, bem como explicita recortes temporais ou territoriais que serão aplicados. E também não depende de juízos subjetivos. Então, no geral, evite noções como “melhor” ou “pior” em perguntas tais como “isto é melhor que aquilo?”.</p>
<p><strong>Pode ser abordado com dados</strong></p>
<p>Pode ser redundante, mas não custa afirmar que suas questões precisam ser resolvidas com dados. Caso não seja possível obter ou coletar dados para tratar da pergunta que você abordou, talvez você precise refazê-la. É o caso, por exemplo, de um escopo sobre gastos governamentais que envolvam despesas sob sigilo.</p>
<p><strong>É complexo</strong></p>
<p>Ser objetivo não quer dizer que seu escopo deva ser simplista. Ao contrário, um bom escopo é complexo e não pode ser respondido simplesmente com um “sim” ou “não”.</p>
<p><strong>É viável de ser realizado</strong></p>
<p>Outro desafio é definir um escopo que seja viável de ser realizado - de nada adianta um escopo perfeito e completo, porém inalcançável. Ou seja, um bom escopo é complexo, porém factível de ser abordado. Isso vai depender muito de seus conhecimentos, tempo, equipe, entre outros fatores. Se sua pergunta depende de dados que são pagos e pelos quais você não pode pagar ou que exige um tipo de análise mais complexa do as que você consegue fazer, simplifique o escopo.</p>
<p><strong>É original</strong></p>
<p>Se o seu intuito é publicar o resultado de uma investigação, é recomendável que você busque abordar um tema com alguma originalidade, nem que seja atualizar uma análise já feita para trazer números mais recentes, por exemplo. Caso você deseje apenas exercitar seus conhecimentos, não há problemas em refazer trabalhos alheios. Pelo contrário, é até recomendável tentar reproduzir análises - assim, você pode aprimorar seu conhecimento e compreender melhor abordagens feitas por outras pessoas.</p>
<p><strong>É relevante</strong></p>
<p>Este é outro caso que vale especialmente para quem deseja compartilhar o resultado do seu trabalho. Se você quer publicá-lo, tente definir temas e um escopo de investigação que seja relevante para as pessoas. Ao pensar sobre o recorte de sua pesquisa, pergunte-se: qual tipo de público terá acesso ao trabalho? Por que ele deveria se importar com isso?</p>
<h2 id="dados-para-além-de-tabelas">Dados para além de tabelas</h2>
<p>Para compreender as diferentes possibilidades de trabalhar com dados e pensar um escopo para sua pesquisa, também é interessante reconhecer as diferentes formas que os dados podem assumir. Geralmente, quando pensamos em dados, logo imaginamos números em tabelas. Porém, o formato de dado tabular é apenas um entre vários. Nosso guia tem foco justamente neles, os dados tabulares, mas nesta seção vamos te apresentar outros tipos de dados para que você conheça suas vantagens e tenha um panorama de seus principais formatos e tecnologias. Assim, você conseguirá pensar recortes para sua pesquisa de forma mais ampla, para além das tabelas.</p>
<p><strong>Dados tabulares</strong></p>
<p>Como dito, esta é a forma mais “tradicional” de estruturar dados. Ela consiste em organizar os registros em tabelas, com linhas e colunas. As extensões de arquivos mais comuns para <strong>dados tabulares</strong> são CSV, XLS, XLSX e ODS. Você pode usar editores de planilha para lê-los ou importá-los em bases de dados com SQL, por exemplo. Também pode acontecer de você encontrar tabelas em formato PDF, o que exigirá um trabalho adicional. Falaremos mais sobre isso no capítulo seguinte.</p>
<p><strong>Dados espaciais</strong></p>
<p>É possível incluir coordenadas <strong>geográficas em planilhas</strong>, como informações de <strong>latitude e longitude</strong>, de modo que você consiga visualizar seus dados em um mapa. Porém, é justo considerar os dados geográficos ou espaciais como uma “família” ou tipo por si só. Isto porque há conceitos e técnicas de análise dos dados espaciais que são únicas e não se aplicam a outros tipos de dados tabulares. Há todo um universo próprio de dados geoespaciais no chamado <strong>GIS</strong> (Sistemas de Informação Geográficas ou Geographic Information System, em inglês).</p>
<p>Além disso, visualizar a distribuição territorial dos dados em um mapa nos permite revelar padrões espaciais, que são invisíveis em uma tabela. Vale a máxima do geógrafo Waldo Tobler, considerada a primeira lei da geografia: “todas as coisas estão relacionadas com todas as outras, mas coisas próximas estão mais relacionadas do que coisas distantes”.</p>
<p>Os dados espaciais possuem uma variedade de formatos/extensões de arquivos bem particulares, por exemplo, KML, GeoJSON, SHP, entre outros. Há também ferramentas e programas específicos para lidar com eles e, neste caso, o destaque fica por conta do <strong>QGIS</strong>, que é o principal programa de código-aberto para lidar com dados geográficos e produzir mapas.</p>
<p><strong>Redes</strong></p>
<p>Outra forma de representar dados é em forma de <strong>redes ou grafos</strong>. Na prática, muitas vezes, você consegue “traduzir” dados tabulares em redes e vice-versa. Por exemplo, considere a tabela abaixo, com informações fictícias sobre os proprietários de algumas empresas de ônibus.</p>
<table>
<thead>
<tr class="header">
<th><strong>Empresa</strong></th>
<th><strong>Proprietário</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Viação 1</td>
<td>Joaquim</td>
</tr>
<tr class="even">
<td>Viação 1</td>
<td>Manoel</td>
</tr>
<tr class="odd">
<td>Viação 1</td>
<td>Luiza</td>
</tr>
<tr class="even">
<td>Viação 2</td>
<td>Joaquim</td>
</tr>
</tbody>
</table>
<p>Estes mesmos dados poderiam ser “traduzidos” para uma representação em redes com o grafo abaixo.</p>
<figure>
<img src="images/defina/grafo.png" alt="O grafo mostra uma forma de representação da rede" /><figcaption aria-hidden="true">O grafo mostra uma forma de representação da rede</figcaption>
</figure>
<p>Ao invés de organizar a informação em uma matriz ou uma tabela, os dados são estruturados a partir de nós (os pontos nas imagens acima) e arestas (os traços que conectam os pontos). Essa estrutura é especialmente útil quando seu interesse são relações entre entidades. Não é à toa que os grafos se tornaram bastante populares para entender a disseminação da informação e relações entre pessoas na análise de redes sociais. Assim como os dados geográficos, as redes possuem conceitos, metodologias e técnicas de análises próprias, que seriam impossíveis ou muito difíceis de serem realizadas utilizando tabelas.</p>
<p>Para lidar com redes, vale a pena conhecer o <strong>Gephi</strong>, que é a principal solução em código-aberto para visualizar e analisar grafos. Com ele, você consegue carregar tabelas e formatos nativos de grafos (como GEXF ou GML) ou até mesmo conectar-se diretamente a serviços como o Twitter, para extrair dados em tempo real.</p>
<p><strong>Textos</strong></p>
<p>Textos também podem ser estruturados como dados. Neste caso, as planilhas podem ser utilizadas em algum momento, mas há também uma série de conceitos, metodologias e técnicas de análise de texto próprias, que são bem específicas e não se confundem com as abordagens baseadas somente em dados tabulares. As <strong>nuvens de palavras</strong> talvez sejam o exemplo mais popular desta perspectiva de texto como dado. Nela, o tamanho das palavras-chaves é proporcional à frequência em determinado conjunto de textos.</p>
<p>Para lidar com análise de texto, você precisará aprender coisas como remoção de palavras frequentes (stopwords) para otimizar suas análises e padronização de palavras semelhantes (lematização ou stemização). Neste caso, a área do conhecimento que você deve se aprofundar é a de <strong>Processamento de Linguagem Natural</strong> (ou Natural Language Processing - NLP, na sigla em inglês). Com ela, você pode ir muito além das nuvens de palavras e realizar tarefas mais avançadas, como detectar automaticamente entidades (nomes de pessoas, empresas ou lugares) em um conjunto de texto. Estas técnicas são utilizadas em um volume muito grande texto, como no caso dos jornalistas que tiveram lidar com o <a href="https://www.icij.org/investigations/panama-papers/">Panamá Papers</a>.</p>
<p>Não existem muitas opções de softwares de código-aberto com interface gráfica que facilitem a análise de textos, mas vale a menção ao Voyant Tools, que conta com uma versão web e permite análise rápidas, e o DocumentCloud, uma plataforma que facilite a organização de documentos e permite detecção de entidades até em PDFs.</p>
<p>Para entender as possibilidades de trabalhar com texto como dados, vale conferir trabalhos <a href="https://pudding.cool/projects/vocabulary/index.html">como este do The Pudding</a> sobre o vocabulário de cantores de rap ou <a href="https://www.nexojornal.com.br/grafico/2018/10/05/30-anos-o-quanto-a-Constitui%C3%A7%C3%A3o-preserva-de-seu-texto-original">este do Nexo</a>, que foi ganhador do primeiro Prêmio Cláudio Weber Abramo de Jornalismo de Dados no Brasil. Na reportagem premiada, os jornalistas analisaram as mudanças no texto da Constituição ao longo das três décadas desde sua promulgação.</p>
<p><strong>Imagens</strong></p>
<p>Este é um terreno mais difícil de ser trabalhado, se você está começando. De todo modo, é bom que você saiba que ele existe. Imagens e vídeos também podem ser trabalhados como dados, ainda que isto seja algo avançado e demande alguma familiaridade com programação. Neste caso, a chave é compreender as tecnologias de visão computacional. A principal ferramenta em código-aberto para isso é o <strong>OpenCV</strong> e você encontra implementações tanto em Python como em R.</p>
<p>A tecnologia de visão computacional permite que o computador consiga “ler” imagens para reconhecer entidades (animais, pessoas ou objetos, por exemplo) ou até mesmo expressões faciais. Um ótimo exemplo no jornalismo de dados deste tipo de abordagem é <a href="https://www.estadao.com.br/infograficos/politica,o-que-revela-uma-analise-das-emocoes-dos-candidatos-durante-o-debate,923037">este trabalho</a> realizado por Rodrigo Menegat (coautor deste ebook) no Estadão. Na reportagem, softwares de visão computacional foram utilizados para identificar e analisar os sentimentos dos candidatos à presidência durante um debate televisivo a partir de suas expressões faciais.</p>
<h1 id="obtenha">Obtenha</h1>
<p>Agora que vimos alguns pontos importantes para definir o escopo de nossa pesquisa e a diversidade de formatos que os dados podem assumir, vamos voltar aos <strong>dados tabulares</strong> para entender como podemos obtê-los. Basicamente, existem três formas de se obter dados.</p>
<p>A primeira é coletá-los você mesmo. Apesar de comum em setores como o poder público e algumas organizações da sociedade civil, no campo da comunicação, em geral, você irá lidar com dados já coletados por alguém. Por isto, como dito no capítulo anterior, não iremos abordar a coleta de dados primários neste guia.</p>
<p>O segundo modo é obter dados inéditos. Neste livro, iremos focar no principal mecanismo legal para isso no Brasil. Quando você já esgotou suas possibilidades de busca, no caso do poder público, há uma alternativa bastante promissora para você obter os dados que precisa: a <strong>Lei de Acesso à Informação</strong>. Neste capítulo, veremos como utilizá-la a seu favor para conseguir novas bases de dados pelo Serviço de Informação ao Cidadão previsto pela lei.</p>
<p>Por último, o terceiro modo de se obter dados é simplesmente os encontrando. Muitas vezes, as informações que você precisa já estarão disponível na internet.</p>
<p>Porém, nem sempre é fácil encontrar a informação que você precisa, principalmente se você está lidando com um tema que não domina. Nestes casos, antes de ir atrás dos dados propriamente ditos, é preciso fazer uma pesquisa ou buscar ajuda com especialistas para entender melhor o campo que você desejar estudar e compreender quais bases de dados estão disponíveis.</p>
<p>Neste capítulo, veremos quais técnicas são utilizadas para lidar com situações como essa. Iremos revisar diversos conceitos e técnicas relativas à obtenção de dados, das mais simples às mais complexas.</p>
<p>Primeiramente, vamos abordar a busca avançada na web. Esta etapa é fundamental, pois antes de tudo você precisa definir quais termos ou palavras-chaves serão utilizadas na pesquisa. Por isso, veremos agora algumas técnicas importantes para fazer pesquisas precisas e obter os dados que você precisa.</p>
<h3 id="busca-avançada-na-web">Busca avançada na web</h3>
<p>Não raro, os dados encontram-se “escondidos” ou são de difícil acesso. Por isso, é importante conhecer alguns operadores de busca avançada na web. Basicamente, esses operadores funcionam como uma espécie de filtro, que permite garimpar na vastidão da internet exatamente o que você precisa.</p>
<p>Talvez você já conheça alguns operadores de busca mais básicos. Por exemplo, se você apenas joga as palavras ou termos no buscador, ele irá vasculhar páginas que contenham os termos inseridos em qualquer lugar da página, mesmo que não estejam em sequência. Porém, se você colocar os termos entre aspas, a busca retornará apenas as expressões exatas, ou seja, quando os termos retornam exatamente na ordem em que foram inseridos. Para ver isso na prática, considere a palavra-chave “obtenção de dados” e primeiro faça uma busca no Google com elas entre aspas e depois sem aspas.</p>
<p>Este é apenas um entre vários operadores de busca disponíveis. Conhecer estas opções irá ampliar em muito a forma como você busca informações na internet. É possível fazer filtros por data, extensões de arquivo ou sites específicos da internet, entre várias outras opções. Além disso, você consegue combinar os operadores para fazer buscas realmente precisas. Vejamos o exemplo abaixo.</p>
<pre><code>            coronavirus filetype:xls site:gov.br</code></pre>
<p>Se você digitar isso no Google, o buscador irá retornar todas as planilhas em Excel com extensão XLS que estão hospedados em endereços do governo brasileiro e possuem a palavra <em>coronavírus</em>.</p>
<p>Para conhecer os operadores de busca disponíveis e aperfeiçoar suas habilidades de busca na web, recomendamos a leitura deste <a href="https://escoladedados.org/tutoriais/busca-avancada-na-internet/">tutorial introdutório</a> e especialmente deste <a href="https://escoladedados.org/tutoriais/operadores-de-busca-avancada/">texto que publicamos sobre busca avançada</a>. O texto é uma tradução de um artigo de Daniel M. Russell, pesquisador sênior do Google, que documentou todos operadores de busca da ferramenta.</p>
<p>Se você quiser ir fundo no tema, vale a pena pesquisar por técnicas de inteligência com fontes abertas (open source intelligence - OSINT). Os operadores de busca avançados são uma das técnicas utilizadas em OSINT. No entanto, o campo compreende várias outras abordagens, que inclusive vão além do trabalho com dados, como a geolocalização de imagens a partir de características visuais.</p>
<p>De todo modo, as metodologias e as abordagens de OSINT são bastante interessantes para melhorar suas habilidades de investigação na internet e com dados. Um dos grupos de mais destaque nesta área é o <a href="https://www.bellingcat.com/">Bellingcat</a>. Vale a pena conferir suas investigações e os tutoriais que disponibilizam. Além disso, o grupo tem o guia “<a href="https://docs.google.com/document/d/1BfLPJpRtyq4RFtHJoNpvWQjmGnyVkfE2HYoICKOGguA/edit#">Bellingcat’s Online Investigation Toolkit</a>”, uma compilação fantástica de fontes e recursos para obtenção de dados online.</p>
<h2 id="lei-de-acesso-à-informação-e-dados-abertos">Lei de Acesso à Informação e dados abertos</h2>
<p>Outro importante mecanismo de obtenção de dados são as requisições oficiais feitas a governos e entidades públicas. Este mecanismo existe em diversos países. Nos Estados Unidos, chama-se <em>Freedom Of Information Act</em> (FOIA), por exemplo, mas no Brasil é conhecida como <strong>Lei de Acesso à Informação</strong> (LAI - Lei 12.527/2011).</p>
<p>Esta legislação que entrou em vigor em 2012 regulamentou o direito à informação garantido pela Constituição Federal brasileira em seu artigo quinto, reforçando o entendimento da publicidade como regra e o sigilo como exceção. Ela obriga órgãos públicos de diferentes esferas e poderes a fornecer ativamente e abertamente, na web, informações de interesse da sociedade. Assim, o caminho inicial para quem quer obter dados governamentais é verificar se eles já estão disponíveis no site do órgão sobre o qual se busca a informação.</p>
<p>Além de regulamentar esta transparência ativa, quando o próprio órgão disponibiliza a informação proativamente, a LAI também criou o Serviço de Informação ao Cidadão, que implementa na prática a chamada transparência passiva. É o SIC - ou eSIC, nos casos de atendimento online - que garante acesso do público aos dados que são de interesse coletivo, mas por algum motivo não estão disponíveis para consulta.</p>
<p>Mas a LAI vale para todos? Vejamos a quem se aplica esta legislação. <strong>Tanto a União quanto os estados, o Distrito Federal e os municípios estão sujeitos à LAI. Isso vale no âmbito dos três poderes: legislativo, executivo e judiciário. Além deles, também devem obedecer a LAI as autarquias, fundações ou empresas públicas, sociedades de economia mista e entidades controladas direta ou indiretamente por entes da federação. Entidades privadas que recebam recursos públicos igualmente devem fornecer as informações relacionadas ao uso dessas verbas</strong>.</p>
<p>Antes de recorrer à LAI, porém, é importante que você faça o dever de casa: busque os portais de transparência já existentes e verifique se o dado desejado não está disponível. Faça essa checagem antes de realizar o seu pedido para evitar sobrecarregar o serviço público com demandas que já foram resolvidas.</p>
<p>Além de buscar nos portais de transparência e nas fontes oficiais sobre o dado que você deseja, vale também consultar solicitações e respostas já prévias, no caso de pedidos submetidos ao governo federal. Pode ser que alguém já tenha solicitado o dado que você busca e, se for este o caso, você pode encontrar no site da <a href="http://www.consultaesic.cgu.gov.br/busca/SitePages/principal.aspx">Controladoria Geral da União</a> tanto a solicitação quanto a resposta do órgão.</p>
<p>O prazo de resposta é de 20 dias, mas o órgão pode prorrogá-lo por mais 10. Em caso de pedidos negados, você tem direito de ter acesso à justificativa completa para esta decisão e pode questioná-la em até 10 dias. Depois disso, a autoridade hierarquicamente superior àquela que negou o acesso deve se manifestar em até 5 dias. O recurso pode ser usado tanto nos casos em que o acesso à informação não sigilosa for negado, ou procedimentos (como prazos) forem desrespeitados, quanto para pedir a revisão da classificação da informação sigilosa.</p>
<p>Para fazer bons recursos, vale buscar embasamento na legislação. Artigos de leis e decretos, de todas as esferas, podem ser aliados nesse processo. Também vá atrás de precedentes, não necessariamente do mesmo órgão. Pode ser de outras pastas com o mesmo tema. Nesse caso, o site <a href="http://buscaprecedentes.cgu.gov.br/busca/SitePages/principal.aspx">Busca Precedentes</a>, da CGU, pode ser um aliado. Em último caso, muitas vezes, a própria recusa em liberar a informação ou a declaração do sigilo já podem ser informações suficientemente fortes para valer uma publicação.</p>
<p>Você não precisa dar nenhuma justificativa para realizar um pedido de acesso à informação. Ao solicitar dados, lembre-se também que a Lei de Acesso à Informação, especificamente no artigo 8º, explicita a importância de disponibilizar as informações em formatos abertos, estruturados e legíveis por máquina e de forma acessível para todos os cidadãos brasileiros. Para tentar minimizar os riscos de receber dados em formatos inadequados em seus pedidos, você pode inserir uma solicitação explícita para que sejam encaminhados como dados abertos, juntamente com um dicionário de dados (documento que traz informações sobre as “regras de negócios” por trás dados) ou alguma documentação básica que os explique.</p>
<p>Um exemplo de texto que você pode usar é o seguinte texto:</p>
<blockquote>
<p>“Solicito que os dados sejam fornecidos preferencialmente em formato aberto (planilha em .csv,.ods, etc) de acordo com o determinado no art. 8º, §3º da Lei Federal 12.527/11, o item V do art. 24 da Lei Federal 12.695/14 e a normatiza expressa no item 6.2 da <a href="http://dados.gov.br/pagina/cartilha-publicacao-dados-abertos">Cartilha Técnica para Publicação de Dados Abertos no Brasil</a>, elaborada pelo Governo Federal. Solicito ainda que seja encaminhado também o dicionário de dados, documento ou explicação equivalente que descreva o significado de cada variável/coluna”.</p>
</blockquote>
<p>Na sequência, entenderemos melhor o que significa na prática a noção de <em>dados abertos</em>. Mas antes vamos fazer uma revisão de um checklist para você conferir antes de fazer seus pedidos de LAI.</p>
<hr />
<p><strong>Dicas para consultas via Lei de Acesso à Informação</strong></p>
<ul>
<li><p><strong>Faça o dever de casa</strong>: é importante saber quem detém a informação solicitada para fazer o pedido ao órgão responsável;</p></li>
<li><p><strong>Cada um no seu quadrado</strong>: faça um pedido/protocolo para cada dado desejado, principalmente se forem informações diferentes;</p></li>
<li><p><strong>Tenha foco</strong>: pedidos muito genéricos costumam ser recusados, por isso é importante fazer recortes precisos de período, local e itens específicos. É importantes ser claro. Você pode fazer o pedido usando listas, explicar qual o recorte temporal que deseja ou mesmo quais os campos ou variáveis você gostaria de ter acesso, caso solicite dados;</p></li>
<li><p><strong>Use artigos/precedentes</strong>: para embasar o pedido é possível recorrer a artigos da lei ou outros precedentes, como decisões em outros estados, por exemplo;</p></li>
<li><p><strong>Antecipe sigilos</strong>: se os dados podem ter informações sigilosas, você já pode se antecipar e solicitar que eles sejam tarjados ou removidos para evitar possíveis negativas com essa justificativa.</p></li>
</ul>
<hr />
<h3 id="dados-abertos">Dados abertos</h3>
<p>De acordo com a <a href="http://opendatahandbook.org/guide/en/what-is-open-data/">Open Knowledge</a>, <strong>dados abertos</strong> são aqueles que qualquer um pode livre e gratuitamente acessar, usar, modificar e compartilhar para qualquer propósito, inclusive para uso de comercial. Eles estão sujeitos, no máximo, à exigência de menção da autoria e abertura de trabalhos derivados.</p>
<p>Isto diz respeito ao licenciamento dos dados, mas também é importante que o formato do arquivo no qual os dados estão disponibilizados seja um formato aberto. O formato dos arquivos são indicados pela sua extensão. Você deve saber que XLS ou XLSX é a extensão utilizada pelo Excel para planilhas, mas este é um formato de arquivo fechado, que é propriedade privada da Microsoft. Portanto, não é um formato aberto. Para saber mais sobre os diferentes níveis de abertura de dados, vale conferir o ranking da iniciativa <a href="https://5stardata.info/en/">5-star Open Data</a>, uma classificação criada por Tim Berners-Lee, inventor da web e defensor de dados interconectados (<em>linked data</em>).</p>
<p>Os <strong>formatos mais comuns para dados abertos são o CSV, no caso de arquivos com planilhas já disponíveis para download, e o JSON ou o XML no caso de obtenção de dados por meio de APIs</strong>. Enquanto o primeiro representa dados tabulares, com linhas e colunas, o XML e o JSON possuem uma estrutura hierárquica, onde os valores estão uns dentro dos outros, mais ou menos como as pastas de seu computador são organizadas.</p>
<p>No geral, dados abertos não tão comuns de encontrar. Você provavelmente encontrará alguns empecilhos antes de sequer começar a analisar ou visualizar a sua base. Os dados podem estar espalhados em várias planilhas diferentes, despadronizados, desatualizados e sem documentação suficiente para que se compreenda o que as informações significam. A lista de problemas é longa.</p>
<p>Um dos primeiros problemas nesta fase de obtenção é não encontrar os dados que você precisa como dados abertos. Eles podem estar disponibilizados por meio de páginas na web, que foram feitas para serem visualizadas por humanos, mas são inúteis se queremos fazer análises ou visualizações. Ou pior: podem ser fotos ou tabelas digitalizadas.</p>
<p>A seguir, veremos alguns problemas comuns na hora de obter dados em tabelas - e como você pode contorná-los.</p>
<h2 id="problemas-comuns-com-tabelas">Problemas comuns com tabelas</h2>
<p>Mesmo quando você encontra uma tabela já estruturada em formatos abertos, é possível que você enfrente alguns problemas na hora de abrir os arquivos. Nesta seção, iremos ver três problemas muito comuns, especialmente entre iniciantes, que identificamos na Escola de Dados ao longo destes anos de treinamentos.</p>
<p>A solução deles é bastante simples, porém, se você nunca passou por isso antes, pode ser que encontre dificuldades. Todos os problemas são especialmente comuns ao lidar com tabelas, seja em editores de planilhas ou utilizando linguagens como Python ou R.</p>
<p>Para quem está começando, apesar de serem de fácil resolução, estes problemas podem causar bastante confusão, pois a função padrão de <em>Abrir Arquivo</em> dos editores de planilha costumam passar por cima desses “detalhes” importantíssimos. Por isso, de modo geral, é recomendável utilizar a função de importar dados para abrir os CSV, pois assim você poderá fazer ajustes em configurações importantes, como as que veremos abaixo.</p>
<p>Além disso, no fim desta seção, também veremos como lidar com dados que estão em formato PDF ou como imagens/fotos.</p>
<h3 id="separador-de-campos">Separador de campos</h3>
<p>A sigla CSV significa <em>Comma Separated Values</em> ou, em bom português, valores separados por vírgulas. Isto porque um arquivo CSV nada mais é que um arquivo de texto onde um certo caractere é utilizado como separador das colunas. Ou seja, se você abrir seu bloco de notas e salvar um arquivo com extensão CSV contendo o texto abaixo poderá abrí-lo depois no editor de planilhas e ele será visualizado como uma tabela.</p>
<pre><code>            nome,aula,nota

            rosa,matemática,10

            walter,português,8

            maria,português,5</code></pre>
<figure>
<img src="images/obtenha/exemplocsv-2.png" alt="Texto estruturado em CSV, que será exibido como uma tabela, se aberto em um editor de planilha com o separador de campo adequado" /><figcaption aria-hidden="true">Texto estruturado em CSV, que será exibido como uma tabela, se aberto em um editor de planilha com o separador de campo adequado</figcaption>
</figure>
<p>No caso apresentado, os campos ou colunas são separados com vírgula. Essa é a base fundamental por trás de um CSV, mas existem particularidades. Podemos, por exemplo, utilizar aspas para delimitar o resultado de uma célula, além das vírgulas. Não iremos entrar nestes detalhes aqui. Para quem está começando, o importante não é compreender todas especificações de um CSV, mas simplesmente conseguir abrir adequadamente os dados quando necessário.</p>
<p>Como a sigla da extensão CSV indica, a vírgula é o separador de caractere padrão. Porém, é comum que você encontre tabelas que utilizem o ponto-e-vírgula como separador dos campos. É o caso, por exemplo, de algumas tabelas disponibilizadas pelo Tribunal Superior Eleitoral no Brasil (TSE).</p>
<p>Ao tentar abrir estes arquivos com um editor de planilha, sem especificar qual o separador de caractere utilizado, é possível que os campos e colunas apareçam desconfigurados. Por desconhecer o separador de campos adequado, o programa não conseguirá exibir os valores nas suas células adequadas.</p>
<p>No exemplo a seguir, você vê uma tabela em CSV do TSE aberta usando a função <em>Abrir</em>, sem a especificação do campo de separador de caractere. Repare que os valores das colunas são mostrados de forma inadequada.</p>
<figure>
<img src="images/obtenha/separador-csv.png" alt="Exemplo de tabela com problema no separador de caractere." /><figcaption aria-hidden="true">Exemplo de tabela com problema no separador de caractere.</figcaption>
</figure>
<p>Agora, veja a mesma tabela após ser aberta utilizando a função de <em>Importar</em>, que permite a especificação do separador de caractere correto. Neste caso, todos os valores aparecem nas colunas adequadas.</p>
<figure>
<img src="images/obtenha/separador-csv2.png" alt="A mesma tabela com o problema no separador de caractere corrigido." /><figcaption aria-hidden="true">A mesma tabela com o problema no separador de caractere corrigido.</figcaption>
</figure>
<p>Na prática, é possível utilizar qualquer caractere como separador em um CSV. Porém, <strong>a vírgula e o ponto-e-vírgula são de longe os mais comuns</strong>. Portanto, saiba que, se você abriu uma tabela em CSV e as colunas aparecem desformatadas, muito provavelmente você não selecionou o separador de campos adequado. Provavelmente, você precisará utilizar a função <em>Importar</em> e então especificar manualmente o ponto-e-vírgula como o separador de campos.</p>
<h3 id="codificação-de-caracteres">Codificação de caracteres</h3>
<p>Outro problema bastante comum, não só com planilhas, mas com qualquer documento digital, são os erros de <em>encoding</em> ou codificação de caracteres. Você já tentou abrir algum arquivo e alguns caracteres especiais apareciam de forma estranha, mais ou menos como neste exemplo?</p>
<figure>
<img src="images/obtenha/encoding.png" alt="Exemplo de tabela com problema de codificação de caracteres" /><figcaption aria-hidden="true">Exemplo de tabela com problema de codificação de caracteres</figcaption>
</figure>
<p>Repare como as letras com acentos na tabela não aparecem adequadamente. As codificações de caracteres que “traduzem” os caracteres que nos conhecemos em padrões que os computadores conseguem entender. Novamente, você não precisa se preocupar com os detalhes técnicos sobre isso para abrir suas tabelas. Basta saber que, se alguns caracteres da sua tabela aparecem de forma estranha, tal como na imagem acima, então, provavelmente, a codificação de caracteres selecionada não está correta.</p>
<p>Existem alguns programas que podem te ajudar a identificar a codificação de caractere utilizada em um arquivo, mas você pode consultar a documentação dos dados que obteve em busca de alguma especificação do tipo ou simplesmente tentar os dois tipos de <em>encoding</em> mais comuns.</p>
<p>O UTF-8 (Unicode) é de longe a codificação de caracteres mais comum da web. Quando você apenas lê algo, sem se preocupar com coisas como esta, provavelmente seu computador está usando UTF-8. Porém, se você encontrar problemas, vale a pena tentar abrir seus dados com o <em>encoding</em> ISO-8859-1 (Latin 1), uma codificação de caracteres latinos, que você pode encontrar em alguns documentos brasileiros, por exemplo. O caminho para corrigir a codificação varia conforme o software utilizado para manusear os dados, mas você conseguirá encontrar facilmente tutoriais e orientações na internet sobre o assunto.</p>
<h3 id="tipo-de-dados-na-coluna">Tipo de dados na coluna</h3>
<p>Imagine que você se depare com uma planilha do Instituto Brasileiro de Geografia e Estatística (IBGE). No conteúdo organizado pelo IBGE, cada município possui um código único, viabilizado por meio de números. No entanto, você não os usará para fazer cálculos matemáticos. Não faz sentido, por exemplo, multiplicar o código de identificação de Fortaleza com o de Porto Alegre. Este número na realidade é um código, um conjunto de símbolos que tem um significado específico. Por isso, é importante que colunas que contenham códigos numéricos sejam convertidas para o formato texto.</p>
<p>Os números em formato de código podem ter diferentes significados dependendo da sua base: categorizações, identificadores (IDs), resposta afirmativa, positiva ou ausente. Isso pode ser esclarecido no dicionário de dados, caso sua base venha acompanhada dele.</p>
<p>Em geral, usuários iniciantes ignoram essa configuração do tipo de dados de cada coluna e acabam tendo dificuldades para realizar operações simples, como o ordenamento das linhas a partir de um valor específico, por exemplo. Outro problema ocorre quando os registros são documentos de identidade, Cadastro de Pessoa Física, Jurídica (CPF e CNPJs) ou outros identificadores que começam com 0, por exemplo. Quando esses registros estão no formato numérico, os editores de planilha podem eliminar os zeros à esquerda. Isso pode causar diversos problemas ao tentar cruzar bases de dados distintas ou mesmo ocasionar a perda dos valores originais da tabela, caso você seja sobrescreva o arquivo.</p>
<p>O contrário também pode acontecer. Há ocasiões em que os números - que realmente precisam ser números - estão em formato texto, impedindo que qualquer cálculo seja feito com eles. Por isso, antes de partir para a análise, verifique a formatação de cada coluna da sua planilha e, caso necessário, modifique-a.</p>
<h3 id="padrão-de-números-e-datas">Padrão de números e datas</h3>
<p>Outro ponto para se ter atenção é a localidade onde os dados foram produzidos. Nos Estados Unidos, na representação de números, os pontos separam os decimais e as vírgulas, os centésimos. Já no Brasil e na Europa, é o inverso: usamos o ponto para separar os centésimos e a vírgula para separar os números decimais. Isto pode ser um problema na hora dos softwares “entenderem” e realizarem operações com números.</p>
<p>As datas também costumam ser elementos complicadores e precisam de atenção. Dependendo da origem da sua planilha, elas podem chegar a você no formato dia/mês/ano (padrão brasileiro) ou no formato mês/dia/ano (padrão norte-americano). Por isso, é importante saber qual a origem dos dados e certificar-se de que eles não foram produzidos em localidades distintas. Alguns editores de planilha possuem configurações que permitem indicar qual é a localidade do arquivo e, a partir disso, deduz as configurações de separadores, datas e moedas. Caso seus dados adotem padrões distintos, será necessário padronizá-los para realizar análises.</p>
<h2 id="lidando-com-pdfs">Lidando com PDFs</h2>
<p>O primeiro passo para lidar com dados em PDF é identificar se há elementos de texto no documento ou se o arquivo é, na verdade, uma foto. No primeiro caso, o processo tende a ser mais tranquilo e menos suscetível a erro. No segundo, é preciso aplicar uma técnica especial chamada <strong>reconhecimento ótico de caracteres</strong> (OCR), que permite que o computador “veja” a imagem e “transcreva” os números e textos nela. Se você passa o mouse em cima da tabela e consegue selecionar os caracteres, então, trata-se do primeiro caso. Se não, então, você está vendo na verdade uma imagem.</p>
<p>Infelizmente, não existe uma solução única ou perfeita para libertar dados em PDF. No entanto, existem alguns fatores que ajudam a escolher a melhor ferramenta. Se você precisa realizar a conversão uma única vez e em um documento com poucas páginas, uma solução gratuita - inclusive com OCR - deve ser suficiente. Se você quiser automatizar esse procedimento, customizá-lo ou realizá-lo para um número maior de documentos e páginas, linguagens de programação como Python e R se apresentam como uma boa saída.</p>
<p>Para facilitar, fizemos um resumo das principais soluções para extração de dados em PDF.</p>
<h3 id="pdf-como-imagens-ocr">PDF como imagens (OCR)</h3>
<p>Caso você queira uma solução baseada em Python ou R, busque implementações do Tesseract:</p>
<ul>
<li><a href="https://pypi.org/project/pytesseract/">PyTesseract (Python)</a></li>
<li><a href="https://cran.r-project.org/web/packages/tesseract/index.html">Tesseract (R)</a></li>
<li><a href="https://pypi.org/project/pypdfocr/">PyPDFOCR (Python)</a></li>
</ul>
<p>Se preferir soluções que não requeiram conhecimento de programação, vale a pena conferir as seguintes alternativas:</p>
<ul>
<li><a href="https://www.abbyy.com/pt-br/finereader/">Abby</a></li>
<li><a href="https://www.zamzar.com/">Zamzar</a></li>
<li><a href="http://www.cometdocs.com/">Cometdocs</a></li>
<li><a href="https://sourceforge.net/projects/yagf-ocr/">Yagf</a> (open source)</li>
<li><a href="https://www.onlineocr.net/">OnlineOCR</a> (gratuito)</li>
</ul>
<h3 id="pdf-como-texto">PDF como texto</h3>
<p>Se você tiver um documento com elementos de texto, existe uma gama maior de opções. Usando linguagens de programação, destacamos os seguintes softwares:</p>
<ul>
<li><a href="https://pypi.org/project/rows/">Rows (Python)</a> (criada por Álvaro Justen, colaborador e membro da Escola de Dados)</li>
<li><a href="https://pypi.org/project/pdfminer/">PDFMiner (Python)</a></li>
<li><a href="https://ropensci.org/technotes/2018/12/14/pdftools-20/">PDFTools (R)</a></li>
<li><a href="https://pypi.org/project/tabula-py/">Tabula (Python)</a></li>
</ul>
<p>Já se quiser opções com interface gráfica, então, separamos esta lista de opções:</p>
<ul>
<li><a href="https://tabula.technology/">Tabula</a>: provavelmente será sua primeira opção nestes casos, é de código aberto e você pode rodar no seu próprio computador.</li>
<li><a href="https://pdftables.com/">PDFTables</a> (online)</li>
</ul>
<h2 id="raspagem-de-dados-e-apis">Raspagem de dados e APIs</h2>
<p>Quando as informações que você precisa não estão estruturadas como dados abertos, será necessário fazer uso de uma técnica conhecida como <strong>raspagem de dados ou web scraping</strong>, que envolve realizar cópias de informações de interesse disponibilizadas em páginas web, organizando-as como dados estruturados. Este processo é feito utilizando alguns programas específicos e, nesta seção, você verá algumas das principais ferramentas.</p>
<p>Para raspagens mais simples, você pode utilizar soluções com interface gráfica e resolver o que precisa com poucos cliques. Porém, a depender da complexidade da tarefa, talvez seja necessário que você desenvolva um programa ou script próprio, usando Python ou R, por exemplo.</p>
<p>Os detalhes sobre raspagens de dados variam imensamente de acordo com a fonte dos dados ou volume de requisições necessárias, já que alguns sites bloqueiam ou restringem o acesso quando identificam tentativas de raspagem dados. Outro problema comum é o uso de CAPTCHAS ou conteúdos carregados dinamicamente via JavaScript, que dificultam a raspagem.</p>
<p>Não iremos entrar no detalhe de cada situação. De modo geral, o que você precisa saber que é este método de coleta costuma envolver duas etapas fundamentais.</p>
<p>A primeira delas envolve descarregar as páginas e informações brutas. Independente de qual for a solução de raspagem adotada, ela precisará começar fazendo o download das páginas web ou arquivos que serão utilizados.</p>
<p>Em seguida, você precisará separar o joio do trigo. Como os dados não estão estruturados em sua origem, será preciso fazer isso. Esta etapa por vezes é chamada de <em>parsing</em>. Nela, você irá identificar quais elementos de uma página HTML que interessam na formação da sua tabela, por exemplo. Esta etapa já pode ser considerada também como parte do processo de limpeza de dados, que veremos adiante.</p>
<p>Todo processo de raspagem, <em>parsing</em> ou limpeza de dados envolve basicamente uma habilidade fundamental: reconhecimento de padrões. Seja na identificação dos elementos que precisam ser raspados, seja no processamento dos arquivos para “limpá-los” das informações desnecessários, será necessário identificar quais padrões irão permitir ao computador chegar aos dados tal como você deseja.</p>
<p>Para melhorar seus conhecimentos em raspagem de dados, você precisa conhecer pelo menos o básico de HTML. Também são úteis conhecimentos em CSS ou XPath. Abaixo, você encontra um resumo (não-exaustivo) de algumas das principais soluções para raspagens de dados.</p>
<h3 id="via-interface-gráfica">Via interface gráfica</h3>
<ul>
<li><p><a href="https://webscraper.io">WebScraper</a>: é uma extensão do navegador Chrome, que ativa uma nova aba na seção do navegador voltada para desenvolvedores web. Com ela, você poderá descrever os caminhos de um site para um raspador. Apesar da interface não ser tão intuitiva a princípio, é bastante poderoso e pode ser usado com sucesso em casos como o de raspagem em páginas numeradas ou quando é exigido algum tipo de navegação pelo site para obter os dados desejados.</p></li>
<li><p><a href="https://github.com/scrapinghub/portia">Portia</a>: é uma interface gráfica para o pacote em Python chamado Scrapy</p></li>
</ul>
<h3 id="com-python">Com Python</h3>
<ul>
<li><a href="https://scrapy.org/">Scrapy</a></li>
<li><a href="https://pypi.org/project/beautifulsoup4/">beautifulsoup4up4</a></li>
<li><a href="https://selenium-python.readthedocs.io/">Selenium</a></li>
</ul>
<h3 id="com-r">Com R</h3>
<ul>
<li><a href="https://github.com/tidyverse/rvest">rvest</a>: é parte do conjunto de bibliotecas conhecido como Tidyverse, bastante recomendado para quem deseja trabalhar com dados.</li>
</ul>
<h3 id="comunicação-com-apis">Comunicação com APIs</h3>
<p>APIs são interfaces que facilitam a comunicação de dados entre computadores. A sigla significa <strong>interface de programação de aplicações</strong> (Application Programming Interface, em inglês) e esta forma de acessar dados está presente nas principais plataformas e redes sociais, mas também em portais de dados governamentais.</p>
<p>Se a raspagem de dados, como o nome indica, evoca um método um tanto bruto de se obter os dados, a API seria o oposto. APIs são interfaces que foram criadas justamente para isso: facilitar o fornecimento de dados estruturados, para que possam ser consumidos por terceiros.</p>
<p>Existem alguns programas com interface gráfica que são capazes de se comunicar com estas APIs e carregaram dados. É o caso do Gephi, por exemplo, cujas extensões (plugins) podem torná-lo capaz de acessar dados da API do Twitter. O OpenRefine, que veremos a seguir no capítulo sobre limpeza de dados, também pode consultar APIs.</p>
<p>Na Escola de Dados, você encontra <a href="https://escoladedados.org/tutoriais/geocodificando-enderecos-transforme-tabelas-em-mapas/">um tutorial de como utilizá-lo para</a> <a href="https://escoladedados.org/tutoriais/geocodificando-enderecos-transforme-tabelas-em-mapas/">geolocalizar</a> as coordenadas de latitude e longitude de endereços em texto, utilizando a API do OpenStreetMaps, por exemplo. Porém, no geral, quando utilizamos a API, é mais comum que ela seja acessada usando algum script.</p>
<p>Agora que vimos alguns aspectos e ferramentas da obtenção de dados, passaremos no próximo capítulo à etapa de checagem das informações recebidas.</p>
<h1 id="cheque">Cheque</h1>
<p>Até agora, você aprendeu, em linhas gerais, o que são dados e como encontrá-los ou obtê-los. Para começar a fazer análises, é preciso mergulhar na etapa de <strong>verificação e limpeza</strong> dos dados.</p>
<p>Você pode estar com uma planilha (aparentemente) bem estruturada na sua frente e ansioso para analisá-la, mas se você seguir direto para essa etapa e pular este capítulo poderá se frustrar, ter que refazer a análise ou, pior, publicar informações erradas.</p>
<p>É comum que as bases de dados não cheguem prontas para análise e precisem passar por uma série de verificações e limpezas. É bastante frequente detectar inconsistências ou retirar colunas para reduzir o tamanho de uma base de dados e lidar com elas mais facilmente.</p>
<p>A <strong>verificação</strong> consiste na busca de elementos que comprovem que os dados coletados estão corretos, são consistentes e que não há falta de informação que comprometa o seu trabalho posterior. Esse processo envolve desde as checagens mais básicas e aparentemente banais, como verificações de formato (texto ou numérico, por exemplo) a outros pontos mais complexos, que envolvam comparar os dados com outras fontes.</p>
<p>A checagem é uma etapa fundamental do trabalho que dados. Na prática, ela deve ocorrer de forma transversal, desde a obtenção até a visualização. Ou seja, ao realizar uma raspagem de dados, é importante que durante esta coleta você já verifique se as informações estão sendo capturadas corretamente. Na análise e visualização, o mesmo acontece. Faça a checagem dos dados e, se possível, compare-os com os resultados obtidos por outras fontes.</p>
<p>Já falamos sobre a importância de observar a documentação que acompanha as bases de dados. Este é o primeiro passo para começar a verificação: procure pelo dicionário de dados. Em alguns casos, esse documento pode vir com diferentes nomes: leia-me, nota técnica, nota informativa, anexo etc. Esse arquivo, que funciona como uma espécie de bula, incluirá explicações sobre as variáveis adotadas na estruturação das informações.</p>
<p>Nesse documento, idealmente, haverá também informações detalhadas sobre as unidades de medidas utilizadas (gramas, quilos ou toneladas, por exemplo) e os formatos adotados (número absoluto, índice, taxa, percentual etc.).</p>
<p><strong>Dados, assim como humanos, são imperfeitos</strong></p>
<p>Até mesmo uma fonte que conhecemos bem e tem as melhores credenciais possíveis pode se enganar: um especialista pode cometer um erro de avaliação, a testemunha de um evento pode se confundir e alguém que tenta relembrar um acontecimento histórico que vivenciou pode ser traído pela própria memória.</p>
<p>O mesmo vale para bancos de dados. Até algumas das melhores bases possíveis, mantidas e atualizadas por instituições relevantes e confiáveis, podem trazer problemas como esses. No caso das planilhas, essas falhas podem se apresentar como erros de digitação, entradas duplicadas e outros problemas do gênero. O papel do repórter é verificar se a informação que recebe é legítima antes de publicar, não importa se ela venha da boca de um especialista renomado ou de um banco de dados do governo.</p>
<p>Tomemos como exemplo um caso ocorrido durante a pandemia de Covid-19 no Brasil. Ao final da tarde, como de costume, o Ministério da Saúde divulgou uma imagem com os números atualizados de casos e mortes pela doença em todas os estados do país. No dia 20 de abril de 2020, foi publicado um dado que indicava crescimento substancial da epidemia em São Paulo: a tabela mostrava que as mortes passaram, em 24 horas, de 1.015 para 1.307 - um surreal crescimento de 30%, muito acima do que havia sido observado nos dias anteriores.</p>
<p>O número recorde chegou a aparecer na manchete de portais de notícias, mas estava errado. Por sorte, o crescimento fora do padrão chamou a atenção dos jornalistas mais atentos, que começaram a cobrar explicações do Ministério.</p>
<p>Resposta: o que aconteceu não foi um crescimento sem precedentes, mas um erro de digitação. O total de mortes não havia pulado de 1.015 para 1.307, mas sim para 1.037. O dado foi retificado.</p>
<p>Esse exemplo é excessivamente dramático, já que trata de uma estatística que estava no centro da agenda de notícias nacional e dificilmente passaria despercebido. Ainda assim, é ilustrativo de como apenas as credenciais oficiais não são suficientes para garantir precisão.</p>
<p>Há casos em que esses erros são mais difíceis de detectar. O <a href="https://arte.estadao.com.br/politica/basometro/"><em>Basômetro</em></a>, ferramenta do Estadão, compreende dados de votos da Câmara dos Deputados para medir quanto apoio o Poder Executivo tem entre parlamentares. Em acesso às bases de dados das votações, desde 2003, foram percebidas algumas inconsistências: havia uma votação em que apareciam mais de 513 registros de deputados. Isso é impossível, já que a Câmara só tem esse número de membros. O que aconteceu, afinal? Alguns deputados, não se sabe o motivo, apareciam duplicados nos dados.</p>
<p>Pela lógica, cada sessão de votação precisava cumprir alguns requisitos para que os dados fossem válidos: não poderia ter registro de mais de 513 votos, não poderia ter mais de um voto registrado para um mesmo deputado e assim por diante. Apenas aplicando esses filtros à base de dados inteira, foi possível detectar e corrigir outras sessões com problemas semelhantes.</p>
<h2 id="biografando-dados">Biografando dados</h2>
<p>Uma parte fundamental após a obtenção das informações é realizar uma espécie de <strong>biografia dos dados</strong>. Basicamente, você precisa entender minimamente a origem, a captação, o recorte e as limitações dos dados nas suas mãos. Isso pode parecer fácil, mas é preciso atenção. Um deslize nesta etapa e toda seu trabalho futuro com os dados estará comprometido. Por isso, nesta seção, iremos explicar um pouco deste método de verificação e checagem de dados.</p>
<p>Por que é importante biografar os dados antes de entrevistá-los?</p>
<p>Para seguir com a metáfora, vamos pensar no processo de apuração de uma reportagem tradicional, que não usa muitos dados quantitativos: o repórter, quando se encontra com a fonte, faz uma série de perguntas e usa as respostas para produzir a matéria. Isso é uma entrevista, obviamente.</p>
<p>No trabalho com dados, o equivalente acontece quando o jornalista começa a mexer em filtros e classificações para descobrir qual foi o maior gasto de um departamento do governo no ano, por exemplo.</p>
<p>Entretanto, a entrevista não é o começo de uma apuração jornalística. Antes de falar com qualquer pessoa, o bom repórter precisa fazer a lição de casa. Além de estudar o tema da conversa e preparar perguntas, ele precisa também descobrir o máximo sobre as características da pessoa com quem vai falar.</p>
<p>Quem é o entrevistado? Quais são seus interesses? Quais são suas áreas de especialidade e atuação? Ele tem alguma conexão com pessoas ou grupos que podem gerar conflitos de interesse? Existe alguma controvérsia relevante a seu respeito? Ele costuma ser ouvido por outros jornalistas? Ele tem um histórico confiável como informante? Ele é respeitado pelos seus pares? É preciso saber a resposta para essas perguntas antes de buscar informações com uma fonte.</p>
<p>O mesmo vale para um banco de dados. Tentar entrevistar uma planilha sem saber detalhes sobre ela é uma receita infalível para erros. Biografar dados é fazer essa pesquisa prévia, etapa necessária antes de qualquer tentativa de análise quantitativa.</p>
<p>E o que devemos procurar saber sobre uma planilha antes de partir para a entrevista? A cientista de dados Heather Krause <a href="https://www.youtube.com/watch?v=yCuRQc4xuhA">dá um exemplo prático</a> com base em um de seus temas de pesquisa mais recorrentes: violência contra a mulher.</p>
<p>O entrevistado da vez era um relatório público pela ONU em 2015. Uma fonte de confiança, certo?</p>
<p>Bem, vamos ver o que ela descobriu sobre a coleta de dados durante o trabalho de biografia e pensar um pouco sobre como esses detalhes podem impactar os números.</p>
<p>O primeiro passo foi analisar com atenção o <strong>apêndice estatístico</strong> do relatório. Esses documentos complementares são, geralmente, bem chatos de ler, mas reúnem informações metodológicas importantes sobre a coleta de dados de qualquer fonte.</p>
<p>Como dissemos anteriormente, você pode acabar esbarrando nele com outro nome: dicionário de dados, metadados, anexo metodológico. Enfim, o que importa é que lá estão detalhes sobre os campos que aparecem na planilha, o que eles significam e como foram preenchidos. Exige força de vontade, mas é essencial superar a linguagem de bula de remédio desses documentos.</p>
<p>O que Krause descobriu nesse exercício de atenção e paciência? Que os métodos de coleta de informação variam de país para país e de ano para ano, o que dificulta comparações.</p>
<p>Exemplo: no Malawi, um país do sudeste africano, foi registrada uma variação inesperada nas taxas de violência de uma pesquisa para a outra, entre 2004 e 2005. O número subiu desproporcionalmente e, logo em seguida, voltou o cair.</p>
<p>O que aconteceu nesse intervalo? Será que houve um grande evento político, social e cultural que gerou esse pico? Parece uma boa história, não?</p>
<p>A explicação, porém, era bem menos empolgante. No ano do crescimento desproporcional, quem fez a coleta de dados foi uma instituição privada, com uma metodologia descrita apenas como “inovadora”, sem mais detalhes.</p>
<p>Nos outros anos, a coleta foi feita por agências financiadas com recursos governamentais, que usavam uma metodologia mais tradicional e transparente.</p>
<p>A variação, portanto, é provavelmente efeito desse percalço na continuidade histórica dos dados e não consequência de uma mudança no mundo real. E os problemas não paravam por aí!</p>
<p>Além do uso de fontes diferentes, a data de coleta dos dados variava radicalmente entre os diferentes países. O relatório inclui informações de 2003 e 2013 sob o rótulo de “números mais recentes disponíveis”, por exemplo.</p>
<p>O jornalista desavisado poderia, então, ao tentar contrastar dois países, acabar comparando uma realidade atual com outra que, provavelmente, não é mais relevante.</p>
<p>Essas limitações importantes estavam presentes em um relatório global da ONU, que é tida como uma fontes mais confiáveis para assuntos internacionais. Por sorte, os autores da pesquisa foram transparentes e incluíram essas possíveis falhas metodológicas no documento.</p>
<p>Entretanto, nem todo banco de dados é tão “honesto”. Muitos dados públicos não vêm acompanhados de um detalhamento tão minucioso das próprias limitações. Muita vezes sequer vêm acompanhados de uma descrição decente do que significa cada um dos campos da planilha.</p>
<p>Diante de um cenário como esse, o trabalho do repórter inclui entrar em contato com os autores do levantamento para tirar todas as dúvidas possíveis. Como dissemos brevemente antes, a dica é nunca presumir o que um rótulo de coluna significa ou de que forma os dados foram reunidos. Sempre é preciso fazer esse trabalho prévio.</p>
<p>Krause resume o processo de biografia de dados com uma lista de perguntas que precisam de resposta antes da apuração seguir em frente:</p>
<p><strong>Quem coletou os dados e por que os coletou?</strong> Fique de olho em possíveis conflitos de interesse e em outras formas que a autoria da pesquisa podem afetar os dados. Algumas são menos óbvias. Por exemplo, pesquisas sobre renda costumam ter resultados diferentes quando são feitas por instituições governamentais. Não é conspiração, mas sim desconfiança: as pessoas tendem a subestimar o quanto ganham, com medo de possíveis cobranças ou impostos.</p>
<p><strong>Como os dados foram coletados?</strong> Os dados vêm de um censo que fala com todas as pessoas do país, batendo de porta em porta? São feitos com base em um recorte amostral da população? São coletados por telefone? São inseridos em um programa de banco de dados por policiais ou médicos? São consolidados automaticamente por um sistema automático? Tudo isso afeta a representatividade, a qualidade e as conclusões que podemos tirar dos números.</p>
<p><strong>Quando os dados foram coletados ou atualizados?</strong> Uma pegadinha comum é que os dados divulgados em um ano mostram, na realidade, o cenário de outro momento. Um exemplo comum são os resultados de pesquisas eleitorais. Como, em época de eleição, a opinião pública costuma mudar rápido, a pesquisa representa o estado das coisas no dia de campo (ou seja, no dia em que os pesquisadores fizeram as entrevistas) e não na data de divulgação, que costuma ser até dois dias depois.</p>
<h2 id="tópicos-de-atenção">Tópicos de atenção</h2>
<p>Para analisar os dados de uma planilha, é importante que você entenda o que significa cada linha e cada coluna da sua tabela. Imagine uma base de dados sobre Covid-19 no Brasil. O primeiro passo é entender o que ela registra: cada linha na tabela é um paciente atendido ou o total de casos de uma cidade, por exemplo? Depois de entender o que as linhas significam na sua tabela, é importante compreender cada coluna.</p>
<p>Uma coluna ou variável chamada “localidade”, por exemplo, pode representar pelo menos duas coisas: o município de residência de um cidadão ou a localidade onde ele foi atendido. Não raro, pessoas recebem atendimento de saúde fora do município onde vivem. Por isso, é preciso ficar atento à documentação e à descrição do significado das variáveis de uma planilha.</p>
<p>Se sua base for muito grande para você fazer checagens de todos os registros, uma dica é separar uma amostra aleatória dos seus dados e verificar se está tudo certo. É importante que a seleção seja aleatória. Por exemplo, se você checa apenas as primeiras linhas de uma tabela com registros em ordem cronológica, problemas que tenham ocorrido mais próximos ao fim do período podem passar despercebidos.</p>
<p><strong>Completude e coerência</strong></p>
<p>A identificação da eventual falta de registros em um banco de dados deve ser imediatamente verificada junto à fonte original. Exemplo: você obteve os dados do Ministério da Saúde sobre os contaminados pela Covid-19 nas 27 unidades federativas do Brasil e, ao checar se todas elas estão presentes na base de dados, constata que um estado ou um município está ausente. Reflita: o que tal ausência significa? Significa que ninguém foi contaminado ou que os municípios ou estados não foram analisados?</p>
<p>Se você receber soma, dados agregados ou operações matemáticas já realizadas, mas também tiver acesso aos dados desagregados, a recomendação é refazer e checar os cálculos. Especialmente se a base de dados foi elaborada manualmente, erros neste sentido não são incomuns.</p>
<p>Para entender melhor a importância desse processo, aí vai uma história real. Em uma redação de jornal, dois profissionais estavam produzindo uma matéria sobre filiações partidárias e as migrações de pessoas entre partidos. Enquanto um jornalista de dados ficou responsável pela a obtenção dos dados na página do Tribunal Superior Eleitoral (TSE), via web scraping, outro tinha a missão de fazer as análises a partir dos dados coletados.</p>
<p>Quando as perguntas foram respondidas e o texto e a visualização estavam prontos, foi notada a ausência de dois partidos da análise. Consequentemente, as duas siglas estavam ausentes na reportagem e na infografia. O fato provocou estranheza: será que nenhuma pessoa dessas duas legendas políticas nunca trocaram de partido? Onde estão seus filiados?</p>
<p>Após uma conversa entre os profissionais, eles resolveram checar cada etapa do processo e concluíram que havia um erro no processo. Em função dos descuidos, a reportagem estava comprometida, uma vez que retratava as migrações de filiados de um partido ao outro utilizando tanto números absolutos quanto percentuais. Portanto, a ausência das duas legendas alterava, também, os cálculos realizados para os demais partido. Por sorte, porém, a matéria estava “pronta” com antecedência, o que permitiu refazê-la antes do envio do conteúdo para a gráfica responsável pela impressão do jornal.</p>
<p>Este caso permite refletir sobre o que poderia ser feito para evitar o erro e a consequente repetição de procedimentos. O desfecho seria diferente se houvesse uma verificação básica que mostrasse a presença de todos os 33 partidos na base de dados obtida via web scraping. O erro ocorreu duas vezes: na ausência de verificação da planilha recebida e, antes disso, na falta de detecção do problema na hora da captura dos dados, quando uma primeira verificação deveria ter sido feita.</p>
<p>A história se torna ainda mais complexa porque o código que havia sido desenvolvido para a raspagem e obtenção dos dados fora usado para uma reportagem anterior, que não apresentou erro em relação ao número de partidos.</p>
<p>O que mudou, então?</p>
<p>Os responsáveis pelo site do TSE alteraram a grafia das siglas desses partidos, fazendo com que o código, que já estava pronto, não conseguisse mais identificar as siglas. Por isso, <strong>muito cuidado se for reutilizar um código</strong>. Às vezes os responsáveis pelas páginas na web fazem pequenas alterações que podem comprometer a obtenção de dados recentes.</p>
<p>Este exemplo também mostra que a checagem das informações pode (e deve!) ser aplicada também na etapa de obtenção de dados, de modo a mitigar possíveis problemas posteriores. Ao fazer raspagens de dados, faça sempre uma checagem dos dados em todas as etapas para garantir que todas informações estão sendo capturadas adequadamente.</p>
<p>E mesmo dados estruturados em planilhas podem vir acompanhados de muitos problemas. O jornalista de dados precisa ser minucioso e desconfiado. O trabalho com as bases de dados não admitem fios soltos e, por isso, o trabalho de verificação e limpeza inclui identificar potenciais problemas para eliminá-los imediatamente.</p>
<p><strong>Valores anormais</strong></p>
<p>Uma das primeiras etapas na checagem de dados com números ou valores é a identificação dos chamados <strong>valores extremos ou outliers</strong>. Números que destoam muito dos demais podem ter dois significados: serem de fato casos especiais que merecem investigação ou serem frutos de erros.</p>
<p>Em uma análise sobre a despesa de parlamentares com diárias, por exemplo, é interessante observar se um deles se sobressai em termos de gastos públicos em relação aos seus colegas. Em uma prestação de contas de campanha ou declarações de bens de políticos, o mesmo pode acontecer.</p>
<p>Números extremos, seja para mais ou para menos, podem ser chamativos. Lembre-se, porém, de verificar as informações antes de seguir uma possível história: o que ocorre, às vezes, é o preenchimento incorreto de informações. Na declaração de patrimônio de candidatos a um cargo eletivo, por exemplo, a simples adição do número zero infla o valor dos bens declarados. Por isso, a checagem dos valores extremos ou anormais nas planilhas é uma etapa fundamental não só da análise mas também da checagem da integridade dos dados.</p>
<p><strong>Unidades de medida</strong></p>
<p>Fique atento quanto às unidades de medida (milhas, quilômetros, pés) ou moedas (real, dólar, peso, libra e outros) utilizadas em um banco de dados. Nem sempre essas informações são padronizadas. Para descobrir qual é o caso, leia cuidadosamente a documentação. Não presuma, por exemplo, que todas as planilhas criadas no Brasil estão estruturadas em reais.</p>
<p>Se estiver trabalhando com dados de diversas fontes, escolha a unidade de medida ou moeda com a qual pretende trabalhar e realize as conversões necessárias. Se possível, acrescente colunas e sinalize as alterações.</p>
<p>Verifique, sobretudo, em que formato estão os números da base de dados com a qual pretende trabalhar. Em alguns casos, não haverá casas decimais. É o que ocorre com o número de nascimentos, mortes e outros: não é possível que haja 3,2 óbitos ou 10,8 nascimentos, por exemplo. Se uma coluna reúne informações sobre <em>pageviews</em> (número de acessos), da mesma forma, não pode conter números decimais.</p>
<h1 id="limpe">Limpe</h1>
<p>A <strong>limpeza de dados</strong> é uma etapa fundamental de qualquer trabalho com dados. Em geral, ela não é muito empolgante, mas pode tomar um tempo considerável do seu trabalho. Aqui, você irá organizar os dados para que seja possível posteriormente realizar análises, operações matemáticas, filtros, ordenações, enfim, tudo que você precisa para responder às perguntas desejadas.</p>
<p>Ao limpar seus dados, você irá alterar as informações originais da planilha. Por isso, é importante tomar nota das alterações, bem com manter uma cópia da versão original. Em caso de problemas com seu trabalho de verificação e limpeza, você sempre poderá recomeçar do zero.</p>
<p>Caso você utilize linguagens de programação, o próprio código já serve como esta documentação. Além disso, há os chamados notebooks, que costumam ser ótimas ferramentas para documentar códigos e processos de limpeza e análise dos dados. Eles também permitem que você acrescente comentários e lembretes para si ou para seus colegas. Entre os notebooks mais conhecidos estão o Jupyter Notebook e o Colab do Google.</p>
<p>Antes de começarmos a listar os problemas mais comuns para limpeza de dados, é importante que você conheça o conceito de <strong>dados organizados</strong> (tidy data). Trata-se de um forma de organizar dados tabulares, proposto por <strong>Hadley Wickham</strong>, um dos desenvolvedores de maior destaque da comunidade de R.</p>
<p>Apesar do tempo que cientistas de dados passam limpando a matéria-prima do seu trabalho, ele notou que há pouca reflexão sobre este processo, ao contrário do que acontece com etapas como a análise e visualização de dados, onde há um largo acúmulo de reflexões teóricas e práticas. Por isso, ele concebeu a ideia de tidy data.</p>
<p>De acordo com esta noção, cada tabela registra um certo fenômeno (despesas de um órgão do governo, as notas de alunos, resultados de jogos de futebol ou da situação de pacientes de um hospital, por exemplo). Cada ocorrência será registrada em uma linha ou em uma observação. Cada característica deste fenômeno será uma variável ou coluna e, por fim, a descrição destas características serão chamadas de valores e ocuparão as células.</p>
<figure>
<img src="images/limpe/tidydata.png" alt="No modelo do “tidy data”, cada variável deve ter sua própria coluna, cada observação deve ter sua própria linha e cada valor deve ter sua própria célula." /><figcaption aria-hidden="true">No modelo do “tidy data”, cada variável deve ter sua própria coluna, cada observação deve ter sua própria linha e cada valor deve ter sua própria célula.</figcaption>
</figure>
<p>A seguir, um exemplo de uma tabela fora do formato tidy data.</p>
<table>
<thead>
<tr class="header">
<th><strong>Nome/Registro</strong></th>
<th><strong>Turma</strong></th>
<th><strong>Biologia</strong></th>
<th><strong>Química</strong></th>
<th><strong>Física</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Marcela Nunes - 20351</td>
<td>A</td>
<td>7</td>
<td>6</td>
<td>6</td>
</tr>
<tr class="even">
<td>Ricardo Fernandes - 20589</td>
<td>C</td>
<td>5</td>
<td>4</td>
<td>7</td>
</tr>
</tbody>
</table>
<p>Na tabela, o fenômeno capturado são notas de alunos. Mas repare que a variável “disciplina” ocupa diferentes colunas. No formato tidy data, essa planilha deveria ter uma coluna chamada “disciplina”, onde as matérias estivessem declaradas nas células abaixo dessa coluna.</p>
<p>Outro problema que pode ser visto na tabela são as linhas referentes à coluna Nome/RA. Nesse caso, há duas informações (valores) em uma mesma célula: o nome do estudante e o registro do aluno (um código identificador).</p>
<p>Porém, percebemos que os nomes dos alunos estão separados dos registros por um hífen. Deste modo, podemos usar esse padrão para separar estes valores em colunas ou variáveis distintas, utilizando editores de planilha ou linguagens de programação, por exemplo. Como dissemos, o reconhecimento de padrões que permitam a limpeza dos dados será o seu maior aliado nesta etapa.</p>
<p>Para Hadley Wickham, todas estas questões precisam ser corrigidas antes de qualquer trabalho de análise ou visualização de dados. Assim, a tabela deveria ficar assim para atender o formato do tidy data.</p>
<table>
<thead>
<tr class="header">
<th><strong>Nome</strong></th>
<th><strong>Registro</strong></th>
<th><strong>Turma</strong></th>
<th><strong>Disciplina</strong></th>
<th><strong>Nota</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Marcela Nunes</td>
<td>20351</td>
<td>A</td>
<td>Biologia</td>
<td>7</td>
</tr>
<tr class="even">
<td>Marcela Nunes</td>
<td>20351</td>
<td>A</td>
<td>Química</td>
<td>6</td>
</tr>
<tr class="odd">
<td>Marcela Nunes</td>
<td>20351</td>
<td>A</td>
<td>Física</td>
<td>6</td>
</tr>
<tr class="even">
<td>Ricardo Fernandes</td>
<td>20589</td>
<td>C</td>
<td>Biologia</td>
<td>5</td>
</tr>
<tr class="odd">
<td>Ricardo Fernandes</td>
<td>20589</td>
<td>C</td>
<td>Química</td>
<td>4</td>
</tr>
<tr class="even">
<td>Ricardo Fernandes</td>
<td>20589</td>
<td>C</td>
<td>Física</td>
<td>7</td>
</tr>
</tbody>
</table>
<p>Com a organização dos dados, as disciplinas se tornaram uma única coluna, com diferentes valores. Além disso, há uma linha para cada observação (ou seja, notas de aluno em disciplinas) e o nome e número de registro do aluno também foram separados.</p>
<h2 id="ferramentas-e-técnicas-de-limpeza">Ferramentas e técnicas de limpeza</h2>
<p>Na etapa de limpeza dos dados, mais uma vez, é possível usar tanto linguagens de programação ou softwares com interfaces gráficas. Para trabalhar com planilhas simples e constituídas por poucas linhas, softwares de editores de planilhas (Excel, Google Sheets ou LibreOffice, por exemplo) correspondem à principal solução para quem não domina linguagens de programação.</p>
<p>Mas há também programas úteis para a limpeza de dados, que são gratuitos e possuem interfaces gráficas. Eles irão ampliar em muito suas habilidades na padronização de dados. Nesta seção, falaremos mais sobre estas soluções e, a seguir, conheceremos uma linguagem para descrição de padrões, que podem ser aplicados em diferentes programas e plataformas: as expressões regulares.</p>
<p><strong>Expressões regulares</strong></p>
<p>Uma expressão regular, também conhecida como Regex, é uma forma comum e concisa de representar algum tipo de padrão em texto. Isso ocorre em uma variedade de aplicações e linguagens, seja pesquisando em um documento, seja fazendo operações de <em>Localizar e Substituir</em> ou limpando um conjunto de dados. Muitas linguagens de programação e editores de texto/planilha permitem o uso de expressões regulares. As sintaxes, por sua vez, podem diferir levemente de acordo com a linguagem ou o programa em uso.</p>
<p>As expressões regulares podem parecer enigmáticas e confusas à primeira vista, mas não se assuste. O importante é entender que as letras e caracteres podem ter significados especiais. Um exemplo bastante simples é:</p>
<pre><code>            [0-9]</code></pre>
<p>Esta é uma expressão regular bem simples, que seleciona todos os números entre 0 e 9 em uma sequência de caracteres. Poderia ser útil se você tem um campo com textos e números e precisa separá-los, por exemplo.</p>
<p>Se você precisa descrever padrões para obter informações específicas de sequência de texto, provavelmente é o caso de começar a aprender expressões regulares. Explorar a fundo esta sintaxe exigiria um guia por si só. Mas se você quiser ter uma introdução ao funcionamento de expressões regulares, vale conferir <a href="https://escoladedados.org/tutoriais/expressao-regular-pode-melhorar-sua-vida/">este tutorial da Escola de Dados</a> e utilizar sites como Regex ou Regex101 para testar as operações na prática. Eles podem ser úteis também para “traduzir” expressões regulares que você encontrar na internet, indicando o significado de cada caractere.</p>
<p><strong>Programas úteis</strong></p>
<p>A <strong>expressão regular</strong> é uma linguagem “universal”, que você poderá utilizar tanto em editores de planilha, quanto ao escrever códigos com Python e R. Ela também pode ser utilizada em outros tipos de programas, que possuem funções específicas para a limpeza de dados.</p>
<p>Nesta seção, iremos abordar duas destas ferramentas: o OpenRefine e o Workbench.</p>
<p>O <strong>OpenRefine</strong> é uma ferramenta voltada à limpeza de dados. Ele consegue carregar arquivos em diferentes formatos (inclusive JSON), transformar para tabelas e então aplicar diversas operações, como a remoção de duplicatas, criação ou remoção de linhas e colunas, normatizações, correção de ortografia entre outras funções.</p>
<p>Além disso, o OpenRefine mantém um “log” com todas as operações que foram feitas nos dados originais. Este registro é extremamente útil, caso você precise refazer uma operação ou reaplicar as transformações realizadas em outros dados que seguem os mesmos padrões.</p>
<p>O OpenRefine também conta funcionalidades muito práticas, que permitem padronizar textos com erros de digitação ou grafias distintas. Ele permite até mesmo a consulta a APIs mais simples, que você pode utilizar para preencher novas colunas a partir de dados existentes. O OpenRefineé uma ferramenta de código-aberto, que conta com versões para Windows, Mac e GNU/Linux. Para utilizá-lo, você irá precisar instalá-lo no seu computador.</p>
<p>Se você preferir utilizar uma solução online, pode utilizar o <strong>Workbench</strong>. Na realidade, esta plataforma é uma ferramenta útil para todas etapas do trabalho com dados, não só a limpeza.</p>
<p>Nela, você pode carregar dados em tabelas, realizar raspagens de dados ou carregar informações do Twitter, por exemplo, para em seguida realizar transformações de limpeza ou operações de análise e visualização dos dados. Na área de limpeza, atualmente, o Workbench oferece funções para remoção de colunas duplicadas, preenchimento de células nulas, geração automática de colunas com identificadores únicos, união e separação de colunas, extração de valores com expressão regular, entre outras funcionalidades.</p>
<h2 id="tópicos-de-atenção-1">Tópicos de atenção</h2>
<p>Nesta seção, veremos alguns tópicos que merecem atenção especial na hora de limpar dados, independente da ferramenta ou software que você irá utilizar. Para uma listagem mais completa sobre o tema, vale consultar o <a href="https://escoladedados.org/tutoriais/guia-quartz-para-limpeza-de-dados/">Guia Quartz para Limpeza de Dados</a>, que traduzimos para o português na Escola de Dados.</p>
<h3 id="ausência-de-valor">Ausência de valor</h3>
<p>Um problema comum nos conjuntos de dados são a ausência de valor, ou um valor vazio, que pode ser representado de diferentes formas. O nulo (null), a célula em branco, o NA (<em>not available</em>) e o número zero podem significar coisas completamente diferentes, dependendo de quem coletou esses dados. Ainda que na programação cada uma dessas representações tenha significados distintos, é preciso verificar.</p>
<p>Para o aprendizado introdutório, é importante entender que qualquer um desses valores em uma planilha pode significar 0. Em outra ocasião, porém, o 0 ou a ausência do valor representa que aquele dado não foi coletado ou que foi perdido. Busque mais informações contextuais junto à fonte original. Diante disso, será possível avaliar se a ausência de valor será mantida ou excluída da análise.</p>
<h3 id="entradas-duplicadas">Entradas duplicadas</h3>
<p>Um dos erros mais comuns em bases de dados é quando uma entrada aparece duas vezes por engano. Verifique se há duplicatas exatas no arquivo: em caso positivo, pode ser que você esteja diante de um erro. Porém, só é possível saber se um registro duplicado é um erro ou não conhecendo bem as “regras de negócio” por trás da base de dados.</p>
<p>Considerando um exemplo sobre a Covid-19, poderíamos pensar que determinado estado ou cidade apresenta duas linhas de informação, quando o correto é apenas uma. Se a linha aparecer duas vezes em um conjunto de dados, é preciso entender o motivo. É um erro ou uma atualização/complementação? Atente também às planilhas que envolvem dados financeiros e transações. Vale contatar a fonte primária dos dados e entender o que houve.</p>
<h3 id="cabeçalho-com-informações-inúteis">Cabeçalho com informações inúteis</h3>
<p>Alguns órgãos públicos oferecem, de praxe, informações técnicas no cabeçalho e no rodapé das planilhas (exemplo: nome do órgão responsável, data da coleta, explicações sobre a metodologia). Embora esse conteúdo auxilie a dar contexto ao material coletado, prejudica a análise (ao fazer uma simples ordenação, por exemplo) e precisa ser removido. Por isso, antes de começar a editar as informações, faça uma cópia do arquivo original - as informações extras podem servir para tirar dúvidas e complementar o material.</p>
<h3 id="grafia-distinta">Grafia distinta</h3>
<p>Ao comparar dados, certifique-se de que nomes de cidades estão registrados com a mesma grafia. Por exemplo, diferentes linhas podem conter a seguinte variação da cidade mais famosa do mundo: Nova Iorque, Nova York, New York, NY - ou, ainda, erros de digitação, como “Nova Yok” e tantas outras possibilidades. Para que possa fazer a análise, é preciso corrigir as grafias estabelecendo uma única versão (as expressões regulares podem ser particularmente úteis aqui). Do contrário, operações realizadas com esses registros podem ficar comprometidas. Não se esqueça de documentar as mudanças.</p>
<p>Atenção para nomes de pessoas: nunca faça correções em nomes de pessoas caso não tenha certeza absoluta de que se trata de um erro. Nomes podem ter variações de grafias que podem não acompanhar sua imaginação. Por isso, não altere se não estiver absolutamente seguro.</p>
<h1 id="analise">Analise</h1>
<p>Você já checou como os dados foram coletados e divulgados e não encontrou nenhum problema. Também já entrou em contato com os responsáveis pelo levantamento e os números parecem responder aos mais rigorosos critérios de qualidade. Além disso, você verificou se os arquivos tinham alguns erros comuns e tudo parece estar conforme o esperado. Agora é só sucesso, certo? Nem sempre.</p>
<p>O maior risco de erro vem de onde menos prestamos atenção: nós mesmos. Nossos próprios vieses e eventuais falhas nas premissas que adotamos na hora de analisar um banco de dados são um estoque inesgotável de cascas de banana.</p>
<p>Philip Meyer, criador do jornalismo de dados, propõe uma reflexão que ajuda a entender esse problema.</p>
<p>Em seu livro de 1973, “<em>Precision Journalism</em>”, ele discute a maneira como repórteres encaram a missão de reportar fatos com objetividade. De acordo com Meyer, jornalistas costumam perceber a si próprios como pessoas de mente aberta, capazes de embarcar em investigações como “tábulas rasas”, sem qualquer prejulgamento. O autor aponta, porém, que isso é impossível. Na prática, não dá para começar a pensar sobre qualquer problema sem partir de um enquadramento teórico ou de uma hipótese. Nós começamos a investigar um assunto porque achamos que pode existir algo de interesse ali, afinal.</p>
<p>Paul Bradshaw, professor da Birmingham City University, publicou recentemente <a href="https://onlinejournalismblog.com/2020/03/24/a-journalists-guide-to-cognitive-bias-and-how-to-avoid-it/">um artigo</a> relacionado ao tema. O texto explora como diversos vieses cognitivos afetam o trabalho jornalístico. Sem jargão, isso significa o seguinte: existem vários mecanismos programados na mente humana que fazem com que nossa avaliação da realidade não seja tão isenta e objetiva como gostaríamos que fosse.</p>
<p>Um dos vieses listados é tão importante que mereceu um <a href="https://onlinejournalismblog.com/2020/04/07/how-to-prevent-confirmation-bias-affecting-your-journalism/">texto só para ele</a>: o viés de confirmação. Em resumo, humanos tendem a prestar mais atenção em informações que reafirmam suas próprias opiniões sobre um tema, enquanto ignoram informações que possam colocar essas perspectivas em xeque. O viés de confirmação também é frequentemente acionado nas crenças de fatos duvidosos, como ocorre no circuito da desinformação.</p>
<p>Essa questão não surge exclusivamente no jornalismo de dados, mas também pode ser observada nas reportagens que não se utilizam de quantificações. Muitas vezes, na ânsia de ver uma investigação se confirmar, repórteres direcionam a atenção apenas para os elementos que corroboram o resultado que querem alcançar e ignoram evidências contrárias. Isso acontece porque o repórter tem estímulos positivos para confirmar as próprias suposições, desde a satisfação de ver seu faro estar certo até a pressão que envolve apurar, escrever e entregar uma matéria relevante dentro de um prazo apertado.</p>
<p>Assim como acontece com as pessoas do outro lado do balcão, que produzem dados para nosso consumo, jornalistas de dados também podem falhar: erros de digitação, fórmulas mal aplicadas, a mão que escorrega na hora de aplicar uma função na planilha… Tudo isso pode acontecer e passar despercebido.</p>
<p>Entretanto, o próprio Philip Meyer propõe uma saída para o problema que levantou - e ela funciona também para minimizar tanto os efeitos dos vieses cognitivos quanto os deslizes mundanos. Para ele, o <em>jornalismo de precisão</em> deveria adotar, na medida do possível, os ideais, os métodos e o conceito de objetividade dos cientistas.</p>
<p>O que isso significa, porém?</p>
<p>De saída, significa formalizar, enunciar e tomar consciência das hipóteses, teorias e premissas que assumimos na hora de apurar uma matéria - ou, no nosso caso, de fazer uma análise de dados. Só assim é possível fazer uma análise mais criteriosa dos pressupostos que envolvem nossa forma de pensar e as conclusões que derivam dela.</p>
<p>Além disso, é importante adotar o <strong>maior rigor metodológico possível.</strong> Antes de mergulhar nos números, vale listar quais são os elementos que você procura, que evidências seriam necessárias para comprovar a hipótese que você investiga e, em contraste, o que seria necessário para admitir que não há nada ali. A ciência estatística pode ser aliada nesse processo, como veremos adiante.</p>
<p>Por fim, Meyer também destaca a importância de assumir uma postura de <strong>transparência radical</strong> , semelhante àquela que os bons cientistas adotam ao divulgar seus estudos de forma que possam ser meticulosamente avaliados e até reproduzidos pelos pares.</p>
<p>Explico melhor: cientistas estão acostumados a registrar todos os seus passos de forma detalhada. Junto com a conclusão de seus experimentos, publicam também uma descrição detalhada do método utilizado, os dados relacionados e um passo a passo de como os resultados foram obtidos.</p>
<p>Assim, um trabalho científico é também uma espécie de “mapa” que serve para que colegas (na revisão entre pares, por exemplo) e o público em geral possam verificar se tudo está como deveria estar ou se há alguma falha no estudo.</p>
<p>O jornalismo investigativo tradicional faz isso em certa medida, quando reúne documentos e registros concretos que podem ser verificados: atas de reunião, contratos, editais… Uma reportagem de impacto geralmente cita e mostra elementos como esses, o que ajuda a conferir credibilidade ao relato.</p>
<p>A coisa fica mais complicada, porém, quando o trabalho envolve informações confidenciais, fontes anônimas ou eventos que o repórter testemunhou em primeira pessoa. Algumas reportagens, pela própria natureza, não podem vir acompanhadas da demonstração de evidências.</p>
<p>O jornalismo de dados, por sua vez, apresenta condições de oferecer <strong>transparência</strong> ao leitor. Como o trabalho costuma ser mais metódico e controlado, é possível documentar cada passo de uma apuração ou análise.</p>
<p>Quando o repórter sabe programar, ele pode divulgar o <strong>código-fonte</strong> de uma matéria, ou seja, as linhas de instruções que foram executadas pelo computador para chegar ao resultado. Assim, pessoas que também entendem de código podem revisar o processo de elaboração do material em busca de erros. Este processo já é adotado na redação de grandes jornais no Brasil e no mundo, como o Estadão ou o The New York Times.</p>
<p>Mesmo quando o trabalho não envolve programação, é possível fazer algo semelhante através do registro sistemático de todas as ações que foram tomadas no processo de produção.</p>
<p>Vale a pena anotar tudo o que você fizer, desde a origem dos arquivos que baixou até o passo a passo da limpeza de dados e das fórmulas e filtros que aplicou. Além de servir para organizar melhor o próprio fluxo de trabalho, esse tipo de material pode ser divulgado junto com a matéria.</p>
<p>Ao permitir que terceiros avaliem se seu métodos são sólidos, você também minimiza a chance de que um erro passe despercebido por todos. Mais do que isso, você demonstra que está trabalhando de boa fé e constrói uma relação de confiança com os leitores. Quanto mais gente prestar atenção e discutir os méritos e falhas do jornalismo, mais a qualidade dos conteúdos tende a crescer.</p>
<hr />
<p><strong>Dicas para começar uma análise</strong></p>
<p><strong>Desenvolva um método:</strong> em vez de mergulhar na base de dados de forma livre, olhando para todos os lados em busca de algo que possa ser interessante, é importante elaborar um plano de ação. Assim, nos obrigamos a tomar consciência das hipóteses e premissas que envolvem o trabalho. O que exatamente você espera encontrar? De que maneira vai sistematizar essa busca? Que evidências seriam suficientes para corroborar suas hipóteses?</p>
<p><strong>Reporte contra suas convicções:</strong> quando começamos uma análise de dados, é natural que o esforço de investigação enfatize elementos que corroborem a história que queremos contar. Entretanto, precisamos pensar também naquilo que pode derrubar a matéria. Que evidências fariam você desistir da reportagem? Procure por elas também.</p>
<p><strong>Seja transparente:</strong> desenvolver um método claro de trabalho não é útil apenas para guiar nossos próprios esforços de apuração. Quando a metodologia é publicada junto com uma reportagem, você ajuda o público a entender quais foram os passos da investigação, o que aumenta a credibilidade do material e permite que interessados verifiquem se os resultados são mesmo sólidos.</p>
<hr />
<h2 id="vieses-e-limitações">Vieses e limitações</h2>
<p>Agora, já sabemos que dados podem trazer erros e vieses e que esses problemas podem ter várias causas, desde falhas metodológicos até pequenos deslizes humanos.</p>
<p>Falta entender, entretanto, como esses dados ruins podem afetar a sociedade de forma negativa - e o que podemos fazer diante disso.</p>
<p>Em 2016, <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">o veículo americano <em>ProPublica</em></a> investigou como um programa de inteligência artificial usado pelo sistema de justiça americano discriminava pessoas negras.</p>
<p>Essa inteligência artificial supostamente era capaz de dizer qual era a chance de um prisioneiro reincidir no crime caso fosse solto e, assim, ajudar juízes a tomarem decisões melhores. O programa avalia dados sobre o réu e emite uma nota, em uma escala de 1 a 10, para mensurar o risco. O juiz, depois de consultar o valor, decide o que fazer: concede liberdade condicional ou mantém o sujeito na prisão?</p>
<p>A promessa de um sistema como esse é reduzir a influência do preconceito inerente aos humanos no processo de decisão. Entretanto, a reportagem mostrou que isso não aconteceu.</p>
<p>De acordo com a análise, o programa sistematicamente classifica americanos negros como mais propensos a reincidir do que americanos brancos, ainda que tenham cometidos crimes menos violentos.</p>
<p>Por que isso acontece? Porque uma inteligência artificial precisa de dados para operar. Um sistema como esse funciona ao analisar quantidades enormes de números, buscando padrões neles. É com base em registros e métodos elaborados por humanos que o computador cospe seu veredito.</p>
<p>Agora o problema fica mais aparente: de acordo com um dos procurados citados na matéria, a sociedade americana, e o sistema prisional em especial, tem um histórico grave de racismo.</p>
<p>O programa não era alimentado com dados sobre a raça dos réus, mas se debruçava sobre dados sócio-econômicos e comportamentais, como renda e desemprego. Esses problemas não afetam pessoas de diferentes raças igualmente: negros sofrem mais com eles. Assim, a máquina passou a enxergar uma relação indireta - e inexistente, como a reportagem demonstra - entre raça e risco de reincidência.</p>
<p><strong>Quando um sistema analisa automaticamente números produzidos por uma sociedade que discrimina, o resultado da análise vai trazer consigo o mesmo tipo de discriminação. Os dados são, em sua origem, essencialmente humanos</strong>.</p>
<p>A reportagem da ProPublica, além de revelar essa dinâmica que perpetua desigualdades, mostra como o jornalismo de dados pode agir diante de um contexto como esse.</p>
<p>O trabalho usou técnicas do jornalismo de dados não apenas para encontrar tendências em uma base, mas para entender melhor os efeitos que ela tem sobre o mundo. Aqui, o dado não é encarado como espelho da realidade, mas como uma construção que tanto reflete quanto afeta a sociedade.</p>
<p>Além disso, as melhores práticas foram seguidas e o resultado foi publicado junto com uma <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">descrição detalhada da metodologia</a>. A matéria serve para ilustrar como é possível tratar os dados não apenas como uma fonte de informação, mas como um tema que merece ser investigado por si só.</p>
<p>Outro exemplo dessa postura vem do trabalho da Folha de São Paulo na cobertura da epidemia de Covid-19: a equipe do núcleo de dados do jornal (Delta Folha), ao analisar dados sobre mortalidade publicado pelos cartórios do Brasil, percebeu uma série de erros que impediam fazer uma análise sólida.</p>
<p>Em vez de simplesmente desistir da reportagem e começar outra matéria, o jornal <a href="https://www1.folha.uol.com.br/equilibrioesaude/2020/05/base-de-dados-de-cartorios-traz-falhas-que-impedem-calcular-efeito-real-do-coronavirus-no-brasil.shtml">publicou um texto</a> em que expôs os diversos problemas daquelas estatísticas, que vinham sendo usadas cada vez mais por outros participantes do debate público.</p>
<p>O The New York Times também tem se destacado nesse aspecto, com <a href="https://www.nytimes.com/series/new-york-times-privacy-project">uma cobertura</a> dedicada aos efeitos que a coleta em massa de dados pode ter para a privacidade dos cidadãos e suas consequências para a democracia.</p>
<p>Essa atitude inquisitiva é especialmente importante porque, cada vez mais, dados e programas de computador têm efeitos na vida das pessoas. O tema tem se tornado mais caro ao jornalismo, tanto que alguns repórteres já se propõem a fazer a <strong>cobertura de algoritmos</strong>. Em vez de se especializar em reportar sobre política, cultura ou saúde, eles se dedicam a entender melhor e discutir de forma crítica como esses mecanismos atuam. O tema não cabe no escopo do livro, mas vale registrar que técnicas do jornalismo de dados podem ser úteis para quem quer se aventurar por esse campo.</p>
<p>Agora que já dedicamos uma boa atenção às preocupações que precisamos ter durante a análise de uma base dados, vamos começar a parte mais prática deste capítulo. <strong>Como, afinal, fazemos para descobrir quais são as histórias que se escondem em uma série de números? Quais são as técnicas e saberes que eu preciso mobilizar para produzir uma boa reportagem guiada por dados?</strong></p>
<p>A primeira recomendação é não esquecer daquilo que importa para todos os repórteres do universo: seu trabalho é encontrar e comunicar o que há de mais novo, relevante e interessante no mundo. O que muda é que um bom jornalista de dados precisa desenvolver habilidades para encontrar informações em um novo ambiente social.</p>
<p>Uma das melhores explicações sobre o que isso significa veio de Tim Berners Lee, pesquisador e criador da internet moderna (World Wide Web).</p>
<p>Em uma <a href="https://www.theguardian.com/technology/organgrinder/2010/nov/19/berners-lee-journalism-data">entrevista</a> de 2010 para o jornal britânico The Guardian, Lee resumiu a questão: segundo ele, jornalistas estão acostumados a encontrar histórias conversando com pessoas, e vão continuar fazendo isso. Entretanto, em mundo cada vez mais digitalizado, eles também vão encontrar histórias em bancos de dados, e portanto precisam estar equipados para analisá-los.</p>
<p>Esse pensamento se materializa quando percebemos que, hoje, praticamente todas as ações humanas acabam se tornado um registro numérico, no final das contas. Quando um parlamentar compra uma refeição, o registro vai parar em uma planilha em algum canto do site da Câmara. Quando o Presidente da República publica um tweet, um banco de dados é atualizado. Quando alguém faz uma busca no Google, um algoritmo é posto para funcionar.</p>
<p>E qual é o equipamento que um jornalista de dados precisa ter em mãos para compreender e usar esses dados, afinal? <strong>O mais essencial é desenvolver uma maneira quantitativa de pensar. Em vez de enxergar anedotas e histórias individuais, um repórter treinado para trabalhar com informação quantitativa busca ver padrões, tendências, repetições</strong>.</p>
<p>Para deixar mais claro como essa mentalidade funciona, vamos pensar em um acontecimento frequente: um roubo de celular que aconteceu em uma rua movimentada de uma grande capital.</p>
<p>Um único roubo, por si só, provavelmente não seria noticiado por um jornal da cidade. É corriqueiro demais, comum demais. Entretanto, o bom repórter de dados não para em um roubo só. Ele percebe que esse fato singular está inserido dentro de vários outros. Quantos celulares são roubados por dia em São Paulo, por exemplo?</p>
<p>Além disso, ele percebe que o roubo é um fenômeno quantificável: a ação aconteceu em determinado dia da semana e em determinado horário, em um local que pode ser representado como coordenadas geográficas. A vítima tem uma idade, uma raça, uma profissão. O ladrão também. Tudo isso cabe muito bem em uma planilha, não acha?</p>
<p>Quando jornalistas e editores percebem essa possibilidade, a história sobre roubo de celular fica interessante. Vira até <a href="https://sao-paulo.estadao.com.br/noticias/geral,roubos-de-celular-atingem-metade-das-ruas-de-sao-paulo,70002022457">capa de jornal</a>: o exemplo é real, e resultou em uma matéria que foi publicada pelo Estadão em setembro de 2017. A planilha com todas essas informações sobre os roubos existe, de fato: é o registro dos boletins de ocorrência publicado pela Secretaria de Segurança Pública de São Paulo.</p>
<p>A matéria ecoa o <a href="http://www.holovaty.com/writing/fundamental-change/">texto clássico sobre jornalismo de dados</a>, publicado em 2006 por Adrian Holovaty e sobre o qual falamos na introdução deste livro.</p>
<p>Depois que você aprende a enxergar números em todos os lugares, precisa aprender também a entender o que eles revelam. E é aí que entra no jogo algo que parece assustador: a matemática.</p>
<p>Dificilmente um jornalista ou comunicador entrou na profissão porque gosta de fazer contas. Na verdade, o que acontece com frequência é o contrário: muita gente escolhe virar repórter porque quer evitar os números, geralmente depois de passar anos sofrendo para superar provas de matemática.</p>
<p>O resultado dessa aversão generalizada à matemática é perceptível no ambiente de trabalho, visto que algumas pessoas entram em desespero ao precisar fazer uma simples conta de regra de três.</p>
<p>O fenômeno da ansiedade causada pela matemáticajá foi descrito em <a href="https://journals.sagepub.com/doi/full/10.1177/1326365X18780418">pesquisas acadêmicas</a> e a conclusão assusta: muitos estudantes deixam de cursar disciplinas de jornalismo de dados porque acham que não gostam ou não sabem o suficiente de matemática.</p>
<p>Esse medo, contudo, não faz muito sentido: quase tudo que um jornalista de dados faz envolve matemática básica. Além disso, ao contrário da escola, podemos usar calculadoras ou, como é mais frequente, programas como o Google Sheets e o Microsoft Excel.</p>
<p>Antes de aprender como mexer com essas ferramentas, porém, precisamos relembram algumas tarefas simples dos tempos de escola, como taxas, porcentagem, estatística básica e afins.</p>
<h2 id="operações-matemáticas-básicas">Operações matemáticas básicas</h2>
<p>Nesta seção, aprenderemos um pouco sobre como calcular porcentagem e taxas, além de ter algumas dicas relacionadas à correção de valores pela inflação e análise de séries temporais. Para uma descrição mais detalhada das operações matemáticas básicas importantes para o trabalho com dados vale conferir o livro de Sarah Cohen, <em>“Numbers In The Newsroom”</em>. Trata-se de um manual clássico escrito por uma ex-editora de jornalismo de dados do New York Times, que apresenta os conceitos da matemática que mais são usados nas redações de forma didática.</p>
<h3 id="porcentagem">Porcentagem</h3>
<p>Calcular a porcentagem é, provavelmente, a tarefa mais comum de um jornalista. Manchetes como “65% dos entrevistados se preocupam com o desemprego” são extremamente comuns e não costumamos pensar muito no que elas significam. É óbvio, certo?</p>
<p>Pode até ser, mas vale a pena esmiuçar o conceito. Quando alguém menciona 65% dos entrevistados, na prática está dizendo que 65 de cada 100 deles demonstrou preocupação com o desemprego.</p>
<p>Entretanto, a descrição metodológica dessa pesquisa diz que foram entrevistados, na verdade, 6.734 brasileiros e não 100. Desses, 4.377 disseram que estavam preocupados, em vez de 65. Nesse contexto, por que estamos falando de “65 de cada 100” em vez de “4.377 de cada 6.734”?</p>
<p>A explicação é simples: é mais fácil entender o que significa “65 de 100” do que “4.377 de 6.734”. No primeiro caso, fica bem mais fácil entender que estamos falando de mais da metade do total. Ao falar em “65%”, a proporção dos preocupados fica mais clara.</p>
<p>É para isso que serve a porcentagem: o cálculo parte de um valor arbitrário e difícil de compreender e o transforma em algo mais palatável. O passo a passo é o seguinte:</p>
<figure>
<img src="images/analise/figura2.png" alt="Para calcular o percentual neste exemplo, primeiro, efetuamos esta divisão" /><figcaption aria-hidden="true">Para calcular o percentual neste exemplo, primeiro, efetuamos esta divisão</figcaption>
</figure>
<figure>
<img src="images/analise/figura3.png" alt="Em seguida, multiplicamos a taxa obtida por cem, afinal, queremos o percentual" /><figcaption aria-hidden="true">Em seguida, multiplicamos a taxa obtida por cem, afinal, queremos o percentual</figcaption>
</figure>
<p>Então, chegamos ao resultado de 64,9% (na prática, os 65% mencionados)</p>
<p>Agora que já entendemos o que é uma porcentagem, podemos dar um passo adiante e falar de variação percentual. Veja este exemplo real de título: “<a href="https://noticias.uol.com.br/meio-ambiente/ultimas-noticias/redacao/2019/05/17/com-bolsonaro-liberacao-de-agrotoxicos-cresceu-42-diz-estudo.htm">Com Bolsonaro, liberação de agrotóxicos cresceu 42%, diz estudo</a>”.</p>
<p>Vamos aos números: de acordo com a reportagem, até abril de 2019, o governo de Jair Bolsonaro havia aprovado o uso de 166 novos agrotóxicos. No mesmo período de 2018, sob outro presidente, haviam sido 117. Como fazemos para chegar nessa variação de 42%, então?</p>
<p>Primeiro, precisamos calcular a <strong>diferença</strong> entre a aprovação de agrotóxicos em 2019 e 2018. Depois, queremos saber quanto essa diferença representa do <strong>valor original</strong>. Na prática, é muito parecido com o cálculo simples de porcentagem, mas com um passo a mais.</p>
<p><img src="images/analise/figura5.png" /> <img src="images/analise/figura6.png" /> <img src="images/analise/figura7.png" /> <img src="images/analise/figura8.png" alt="Estabelecer a variação percentual requer mais uma etapa no cálculo" /></p>
<p>O que todas essas contas fazem, em sua essência, é descobrir <strong>o quanto a mudança nos números brutos</strong> representa do valor inicial. <strong>Discernir isso é importante para não cair em um erro comum: confundir variação percentual e diferença em pontos percentuais</strong>.</p>
<p>Esse último é mais fácil de entender: ele não envolve as transformações de números em percentuais que acabamos de fazer, mas sim a comparação já entre duas porcentagens.</p>
<p>O exemplo desta vez é a pesquisa Datafolha de 28 de maio de 2020, que mostrou que a reprovação do presidente Jair Bolsonaro cresceu de 38% para 43% desde o mês anterior.</p>
<p>Alguém desavisado poderia dizer que a variação foi de 5%, já que 43 menos 38 é igual a cinco. Entretanto, calcular a variação em porcentagem envolve os passos que acabamos de mostrar. Quando a conta é simples assim, comparando a diferença entre duas porcentagens com uma simples subtração, o correto é dizer que a queda foi de cinco pontos percentuais.</p>
<p>Calcular a <strong>variação percentual</strong>, por outro lado, envolveria pegar essa diferença de 5 pontos percentuais e dividir pelos 38 originais. O resultado seria uma queda de aproximadamente 13%.</p>
<h3 id="taxas">Taxas</h3>
<p>Ao entender como funciona o cálculo de uma porcentagem, você automaticamente aprende também a usar outra ferramenta importante no cinto de utilidades de um jornalista de dados: o cálculo de <strong>taxas</strong>.</p>
<p>Como vimos, uma porcentagem consiste em transformar um número absoluto, muitas vezes difícil de colocar em perspectiva, em algo mais palatável. Assim, é mais fácil entender o que aquele valor representa.</p>
<p>Calcular uma porcentagem nada mais é que calcular uma taxa. Lembre-se do passo final da operação, quando o resultado da divisão da parte pelo todo é multiplicado por 100. A multiplicação, na prática, está colocando o resultado em uma <strong>base</strong> diferente.</p>
<p>Isso significa que, em vez de pensarmos em um número arbitrário, podemos usar uma quantidade que é mais fácil de compreender, mas representa a mesma proporção de casos.</p>
<p>A novidade é que essa base <strong>não precisa ser 100</strong>, necessariamente. Um caso frequente é a taxa de homicídios, que geralmente é calculada na base de <strong>100 mil</strong>.</p>
<p>Além de tornar mais fácil entender o que um número representa de fato, o cálculo da taxa serve, principalmente, para comparar fenômenos que acontecem em populações de tamanho diferente.</p>
<p>Veremos como isso funciona na prática, ainda com os dados de assassinatos de 2016. Em Trinidad e Tobago, 420 pessoas foram vítimas de homicídio naquele ano. No Brasil, no mesmo ano, foram aproximadamente 61 mil. <strong>Qual país é mais violento?</strong></p>
<p>A resposta simples é que mais gente é assassinada no Brasil do que no país caribenho. Entretanto, a população do Brasil é cerca de 200 vezes maior. É natural que a quantidade total de mortes seja maior aqui.</p>
<p>Como podemos responder a essa pergunta de forma justa? <strong>Usando uma taxa que coloque esses números na mesma base.</strong> Assim, conseguimos saber o quão comuns são as ocorrências de assassinato dentro de uma população. Veja abaixo o passo a passo e repare como o processo se assemelha ao da porcentagem:</p>
<p><img src="images/analise/figura9.png" /> <img src="images/analise/figura10.png" /> <img src="images/analise/figura11.png" alt="As figuras mostram a comparação entre os países com o uso de taxas" /></p>
<p>Os assassinatos, ainda que por pouco, são <strong>menos comuns</strong> no Brasil que em Trinidad e Tobago, mesmo que a contagem de mortes seja maior.</p>
<p>É uma boa prática calcular taxas sempre que formos comparar a realidade de universos de tamanhos diferentes. Mesmo assim, é bom nunca perder os números absolutos de vista, também.</p>
<p>De acordo com as circunstâncias, controlar os valores por população pode induzir leituras erradas. Precisamos prestar atenção especial na hora de comparar universos de escalas muito diferentes. Quando a população total é muito pequena, poucas ocorrências podem inflar uma taxa artificialmente.</p>
<p>Para entender melhor, vale olhar para os números de mortes por Covid-19 para cada milhão de habitantes em dois países. Na Islândia, essa taxa era de 27 ao final de maio de 2020. Na China, era de 3. A situação do país asiático parece muito melhor sob essa métrica, mas sabemos que a realidade é diferente.</p>
<p>Uma cidade chinesa foi o epicentro do primeiro surto da doença, com milhares de mortes que levaram a medidas compulsórias de isolamento social. No país nórdico, morreram apenas 10 pessoas.</p>
<p>As taxas de ambas as nações são puxadas para extremos opostos porque eles estão em extremos opostos: a China tem bilhões de habitantes, enquanto a Islândia tem menos de 500 mil.</p>
<p>Um único caso da doença teria grande impacto na taxa islandesa, enquanto mesmo uma quantidade de mortes capaz de colocar um sistema de saúde em colapso pouco alteraria a taxa chinesa.</p>
<h3 id="inflação">Inflação</h3>
<p>A análise de dados que envolve valores monetários deve, necessariamente, considerar a inflação do período. Antes de utilizar números de uma série histórica, por exemplo, é preciso verificar se os valores foram corrigidos. Depois de verificar esse detalhe na documentação do banco de dados que pretende utilizar, é hora de fazer a conversão. Para tanto, existem ferramentas gratuitas que automatizam esse processo, como a calculadora do <a href="https://www3.bcb.gov.br/CALCIDADAO/publico/exibirFormCorrecaoValores.do?method=exibirFormCorrecaoValores">Banco Central</a> e do <a href="https://www.ibge.gov.br/explica/inflacao.php">IBGE</a>.</p>
<p>Tomemos como ponto de partida o poder de compra de um cidadão que, em janeiro de 2005, recebeu R$ 1 mil pelo seu trabalho. Em valores corrigidos pelo Índice Nacional de Preços ao Consumidor Amplo (IPCA), esses R$ 1 mil tornaram-se R$ 2,13 mil em janeiro de 2019. Em outras palavras, este cidadão não teria o mesmo poder de compra caso continuasse recebendo R$ 1 mil em 2019. Por isso, a inflação do período precisa ser observada. Como afirma a jornalista Mariana Segala <a href="https://sigaosnumeros.com/sumario/descomplicando-os-dados/como-encontrar-pautas-nos-dados/as-tres-operacoes-fundamentais-da-matematica-para-jornalistas/">neste trecho do livro Siga os Números</a>, atualizar valores de acordo com a inflação ou com os juros do período é uma das habilidades demandadas especialmente dos jornalistas que cobrem economia e finanças. A ausência de correção de valores provocaria uma análise equivocada.</p>
<h3 id="séries-históricas">Séries históricas</h3>
<p>A análise temporal de um fenômeno exige dados de série histórica, isto é, informações correspondentes a um grande período de tempo. Podemos pensar, por exemplo, sobre dados de emprego e desemprego, distribuição de renda entre a população, produção agrícola e números de importação e exportação em determinado país.</p>
<p>Se você obtiver acesso apenas às informações referentes a um curto espaço de tempo (poucos meses ou poucos anos), é preciso redobrar os cuidados quanto aos resultados e afirmações contundentes e que remetem ao “melhor” ou “pior” desempenho de um setor. Também é importante observar se a coleta de dados foi feita pela mesma instituição ao longo dos anos e/ou se a metodologia de coleta e apresentação de dados passou por mudanças.</p>
<p>Outro ponto que exige atenção é a sazonalidade, muito importante na comparação entre períodos. Em períodos regulares do ano, por exemplo, o trânsito das cidades costuma ser bastante movimentado. Assim, não é possível comparar a circulação de veículos em períodos “normais” com os meses de janeiro e fevereiro. É natural que a circulação de veículos na cidade caia nos meses de férias escolares.</p>
<p>Produção agrícola e até mesmo criminalidade são outras áreas que bem exemplificam a necessidade de escolher períodos comparáveis entre eles, visto que há oscilação dos dados de acordo com os meses. Por isso, é fundamental que qualquer análise seja feita a partir do mesmo período correspondente no ano ou nos anos anteriores. Na dúvida, consulte um especialista.</p>
<p>Daqui a alguns anos, pense bem antes de comparar qualquer tempo com períodos de 2020: a Covid-19 marcou o ano e precisa ser vista como um fenômeno à parte, que deve ser levado em conta nas análises futuras sobre este ano.</p>
<h2 id="estatística-para-leigos">Estatística para leigos</h2>
<p>Depois de entrar em alguns conceitos de matemática básica, precisamos discutir as principais noções de estatística. Na linguagem do dia a dia, costumamos chamar de estatística tudo aquilo que é número. Quando um repórter fala de “trazer estatísticas” para uma matéria, geralmente está falando de rechear o texto com exemplos, contagens, porcentagens e afins.</p>
<p>Estatística é, na verdade, uma ciência que se dedica a analisar e interpretar bancos de dados. Geralmente, o jornalista ou comunicador trabalha com um campo específico da área: <strong>a estatística descritiva</strong> , que se preocupa em resumir de forma significativa as características de um conjunto de informações.</p>
<p>O conceito pode parecer estranho quando descrito dessa forma, mas é algo que está muito presente em nossa cotidiano. Os valores de média, moda, e mediana, por exemplo, fazem parte desse campo, assim como os conceitos de desvio padrão, outliers e padrões de distribuição. Vamos entender para o que serve cada um deles.</p>
<h3 id="moda-média-e-mediana">Moda, média e mediana</h3>
<p>Você provavelmente já calculou a <strong>média</strong> de alguma coisa, nem que seja a média das notas do seu boletim escolar. O procedimento é simples: somar todos os números de uma série e dividir pela quantidade total de elementos. Você já parou para pensar qual é o objetivo desse cálculo?</p>
<p>Na prática, o cálculo da média tenta encontrar um número que seja capaz de representar todas as entradas de uma série de dados de forma simplificada. Quando calculamos a média das notas de todas as provas que um aluno fez em um ano, esperamos que o resultado seja um número que resuma todas as avaliações em uma só.</p>
<p>Não é algo tão simples e justo quanto parece, como qualquer estudante que tenha ficado insatisfeito com sua nota final já percebeu. Existem casos em que usar a média é ainda mais complicado.</p>
<p>Veja, na tabela, a distribuição dos salários de uma empresa:</p>
<table>
<thead>
<tr class="header">
<th><strong>Empregado</strong></th>
<th><strong>Salários (em mil R$)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jéssica</td>
<td>1.5</td>
</tr>
<tr class="even">
<td>Miguel</td>
<td>2.5</td>
</tr>
<tr class="odd">
<td>Bernardo</td>
<td>2.5</td>
</tr>
<tr class="even">
<td>Juliana</td>
<td>2.5</td>
</tr>
<tr class="odd">
<td>Adriana</td>
<td>2.5</td>
</tr>
<tr class="even">
<td>Carlos</td>
<td>3.5</td>
</tr>
<tr class="odd">
<td>Antônia</td>
<td>3.5</td>
</tr>
<tr class="even">
<td>Gabriel</td>
<td>3.5</td>
</tr>
<tr class="odd">
<td>Letícia</td>
<td>4.0</td>
</tr>
<tr class="even">
<td>Sandra</td>
<td>4.5</td>
</tr>
<tr class="odd">
<td>José</td>
<td>5.0</td>
</tr>
<tr class="even">
<td>Bianca</td>
<td>5.5</td>
</tr>
<tr class="odd">
<td>João</td>
<td>6.5</td>
</tr>
<tr class="even">
<td>Camila</td>
<td>28.0</td>
</tr>
<tr class="odd">
<td>Amanda</td>
<td>150.0</td>
</tr>
</tbody>
</table>
<p>Ao calcular a média salarial dos funcionários, chegamos a um número de R$ 15 mil por mês. Entretanto, <strong>não há uma única pessoa que receba esse valor</strong>. Nesse caso, a média não oferece um bom resumo da realidade.</p>
<p>Isso acontece porque os salários de Camila e Amanda são muito maiores que os demais. Como o cálculo da média simples dá um mesmo peso para todos os elementos, o resultado acaba sendo muito sensível a extremos como esses.</p>
<p>Por sorte, existem outras medidas que podemos usar em situações com essa.</p>
<p>A <strong>mediana</strong>, por exemplo, usa uma tática diferente para encontrar um número representativo do banco de dados: ela divide a série em duas metades e pega o valor que está <strong>exatamente no meio</strong>.</p>
<p>Consideremos esta série hipotética:</p>
<blockquote>
<p>[1, 2, <strong>3</strong> , 4, 8]</p>
</blockquote>
<p>Neste caso, o valor seria o <strong>3</strong>, já que há uma mesma quantidade de valores maiores e menores do que ele.</p>
<p>No caso dos salários que mostramos acima, a mediana é um dos salários de R$ 3,5 mil.</p>
<blockquote>
<p>[1.5, 2.5, 2.5, 2.5, 2.5, 3.5, 3.5, <strong>3.5</strong> , 4.0, 4.5, 5.0, 5.5, 6.5, 28.0, 150.0]</p>
</blockquote>
<p>Note como há exatamente sete itens acima e sete itens abaixo do valor selecionado. O valor não é sensível a valores exagerados e oferece um dado mais real.</p>
<p>A <strong>moda</strong>, outra métrica de centralidade, usa uma estratégia mais simples: selecionar, simplesmente, o número que mais se repete. No exemplo acima, é o salário de R$ 2,5 mil, que ocorre com quatro dos 15 funcionários.</p>
<p>Para escolher qual é a melhor métrica para o banco de dados que você tem em mãos, é preciso entender um pouco mais sobre outro conceito de estatística: <strong>a distribuição</strong>.</p>
<h3 id="distribuição-dispersão-desvio-padrão-e-outliers">Distribuição: dispersão, desvio padrão e outliers</h3>
<p>Ainda seguindo com o exemplo dos salários, vamos prestar mais atenção na característica dos dados que tornou o cálculo da média pouco representativo: havia elementos extremos na série, ou seja, salários muito distantes dos demais e que distorciam o cálculo.</p>
<p>Esse tipo de característica pode ser medida usando estatísticas descritivas de <strong>dispersão</strong>. Para entender melhor quais são as informações de um banco de dados - se ele tem muitos extremos ou é mais uniforme, por exemplo - é muito útil usar um tipo de gráfico chamado histograma. Em resumo, esse gráfico permite observar a distribuição dos dados e identificar pontos fora da curva. Falaremos mais sobre ele no capítulo sobre visualização de dados.</p>
<p>Agora, vamos falar de medidas que, assim como as estatísticas de centralidade que vimos anteriormente, tentam resumir as características de um banco de dados em um número único.</p>
<p>Já vimos como esse tipo de abordagem pode ser perigoso mas, ainda assim, servem para ter uma ideia rápida do tipo de dados com os quais estamos lidando.</p>
<p>O <strong>desvio padrão</strong> , por exemplo, é útil para saber se estamos diante de um banco de dados com muitos valores extremos. Esse número é, na prática, <strong>uma média da distância de cada ponto da média de todos os bancos de dados.</strong></p>
<p>Confuso? Nem tanto. Vamos voltar aos dados de salários com que trabalhamos, cuja média é R$ 15 mil.</p>
<p>Para calcular o desvio padrão, precisamos calcular a diferença do salário de cada funcionário da média salarial: Jéssica, por exemplo, ganha R$ 1,5 mil, ou seja, está R$ 14,5 mil distante da média. Amanda ganha R$ 150 mil, então está R$ 135 mil distante da média.</p>
<p>Ao somar todas essas diferenças e dividir pelo total de funcionários, temos o desvio padrão, que tenta resumir o quão uniforme é um banco de dados. Um desvio padrão maior indica dados mais díspares, com a presença de um ou mais extremos.</p>
<p>Nesse caso, o valor é de R$ 37,9 mil. Para saber se ele é significativo, vale comparar com as outras estatísticas que vimos: trata-se de mais do que o dobro da média e é mais de dez vezes maior do que a moda e a mediana.</p>
<p>Também é possível usar o desvio padrão para descobrir o quão extremo é um ponto de dados. Para isso, é preciso dividir o valor pelo desvio padrão.</p>
<p>Por exemplo, vamos analisar novamente o salário de Amanda: R$ 150 mil, divididos pelo desvio padrão de R$ 37,9 mil, resultam em aproximadamente 4 desvios padrão acima da média.</p>
<p>Usualmente, dados que estejam a três desvios padrão ou mais da média, em um banco de dados que segue uma distribuição normal, podem ser considerados extremos - ou seja, são outliers.</p>
<p>Ainda que um outlier possa ser de interesse jornalístico, esse tipo de dado pode prejudicar a análise dos demais. Sempre verifique se esse não é o caso antes de interpretar estatísticas descritivas simples.</p>
<h3 id="correlação">Correlação</h3>
<p>Outra técnica estatística útil para o jornalismo é o cálculo da taxa de correlação. Essa medida, que é bastante complexa e quase sempre é calculada com o uso de programas de planilha ou tecnologias equivalentes, estima como o comportamento de duas variáveis está interligado.</p>
<p>Vamos, de novo, deixar o jargão de lado e tentar entender o conceito com um exemplo mais próximo da realidade: temos um banco de dados que mostra a nota que cada estudante tirou no Exame Nacional do Ensino Médio (Enem) e a renda média de sua família.</p>
<p>Com um cálculo de correlação, podemos verificar que, quanto maior é a renda da família, melhor a nota tende a ser. Trata-se de uma correlação positiva: quando um dos valores cresce, o outro provavelmente vai crescer também.</p>
<p>Existem as correlações negativas, em que ocorre algo oposto: quando uma das variáveis aumenta, a outra diminui. Um exemplo possível é a relação entre renda média e taxa de analfabetismo. Quanto maior for a renda média entre os moradores de uma cidade, por exemplo, menor tende a ser a prevalência de analfabetismo entre a população.</p>
<p>E o quão forte são essas ligações, afinal? Para mensurar exatamente o quanto duas variáveis estão conectadas, é possível calcular um valor chamado <strong>coeficiente de correlação.</strong></p>
<p>Existem vários tipos, mas o de uso mais frequente no jornalismo é coeficiente de <strong>correlação de Pearson</strong>. Ela mede justamente o tipo de relação aqui apresentado e classifica a intensidade do fenômeno de -1 até 1.</p>
<p>Uma correlação de 1 é perfeitamente positiva, em que cada unidade a mais em uma variável gera uma unidade a mais na outra. Uma correlação de -1 é perfeitamente negativa, e uma unidade a mais em uma variável gera uma unidade a menos na outra. Quando o valor é 0, não há correlação alguma e as variáveis não se influenciam.</p>
<p>Entretanto, na prática, é raríssimo encontrar correlações perfeitas ou a total ausência de correlação. O coeficiente se apresenta, na vida real, em frações: 0,8 indica uma correlação forte, por exemplo, enquanto 0,2 indica uma correlação fraca.</p>
<p>Esse tipo de cálculo é útil para fortalecer estatisticamente matérias que mostram como dois fatores estão relacionados. É possível calcular a correlação entre pobreza e acesso à educação ou pobreza e violência, por exemplo.</p>
<p>Contudo, mesmo diante de um coeficiente de correlação alto, é preciso tomar alguns cuidados.</p>
<p>Vamos voltar para o exemplo de notas no Enem. Agora, em vez de comparar a nota de cada estudante com a renda de sua família, você resolveu medir o efeito da arborização na performance escolar. E existe uma correlação clara entre conseguir notas melhores e viver em um bairro cheio de árvores.</p>
<p>Hora de escrever uma matéria espetacular sobre isso, certo? Errado. É hora de pensar um pouquinho mais a fundo.</p>
<p>É muito provável que a variável de renda influencie tanto a quantidade de árvores no bairro de cada estudante como a sua nota na prova. Gente com mais dinheiro mora em locais com melhor estrutura urbana e também tende a ter resultados melhores no Enem.</p>
<p>Não é o excesso de árvores que influencia o desempenho na prova. É a renda que influencia tanto a arborização quanto a nota no exame. Quando não nos atentamos para essa relação escondida, na verdade, estamos medindo uma terceira variável sem nos darmos conta.</p>
<p>Além disso, é possível encontrar dados que se correlacionam de forma perfeita, mas que não tem nenhuma conexão entre si. Existe <a href="https://www.amazon.com/gp/product/0316339431/ref=as_li_tl?ie=UTF8&amp;camp=211189&amp;creative=373489&amp;creativeASIN=0316339431&amp;link_code=as3&amp;tag=tylervicom-20&amp;linkId=UO6I3ENRRQUF255J">até um livro</a> apenas sobre isso. Entre os exemplos, está até uma correlação de 0.95 (portanto, super forte) entre o consumo de queijo muçarela e a quantidade de pessoas formadas em um curso superior de Engenharia Civil.</p>
<p>É por motivos como esses que existe um mantra entre quem trabalha com análise de dados: <strong>correlação não é causalidade.</strong> Só porque dois fenômenos ocorrem de forma paralela, não podemos afirmar que um <strong>causa</strong> o outro, mesmo que o coeficiente de correlação seja absurdamente alto.</p>
<p>Para afirmar que um fenômeno causou outro, é preciso fazer testes estatísticos mais específicos e poderosos, que não conseguiremos cobrir nesse livro.</p>
<p>Na dúvida, é melhor não avançar o sinal: você não quer ser o cara que disse que viver perto de árvores faz alunos irem melhor na prova, não é mesmo?</p>
<h3 id="margem-de-erro">Margem de erro</h3>
<p>Imagine que você queira compreender os hábitos de consumo dos brasileiros ou mesmo quais são suas preferências de voto em uma eleição iminente. É improvável que alguém tenha tempo ou recursos suficientes para ouvir cada um dos 210 milhões de brasileiros. Por isso, trabalha-se com a ideia de amostra, ou seja, um conjunto de pessoas cujas características sociais e demográficas sejam capazes de representar a população como um todo. Dessa forma, as respostas obtidas em uma amostra de pesquisa podem ser atribuídos a um universo (neste caso, a população inteira).</p>
<p>Ao trabalhar com dados amostrais, portanto, fique atento à margem de erro, que corresponde a quantos percentuais (para mais ou para menos) as informações podem variar. Se 90% dos respondentes de uma pesquisa concordaram com uma afirmação, por exemplo, e a margem de erro for de cinco pontos percentuais, estima-se, então, que entre 85% e 95% pessoas responderam afirmativamente a esta questão.</p>
<p><strong>Pesquisas com margens de erro muito altas (a partir de 10 pontos percentuais) dificilmente trazem dados que representam de forma qualificada uma determinada realidade</strong>, e por vezes indicam problemas na metodologia. A margem de erro em pontos percentuais é uma característica importante a ser levada em conta, e deve, inclusive, ser comunicada claramente na reportagem. Em geral, as pesquisas amostrais também divulgam o intervalo de confiança, normalmente de 95%. Isso significa que, se a pesquisa for repetida com amostras aleatórias 100 vezes, em 95 delas o resultado será mesmo.</p>
<h2 id="operações-de-análise-de-dados">Operações de análise de dados</h2>
<p>Existem algumas operações básicas que podem ajudar a encontrar padrões e tendências nos dados. De acordo com o software que você usa para trabalhar, os procedimentos podem ter algumas diferenças, mas o raciocínio segue o mesmo.</p>
<p>De início, tente <strong>ordenar os dados</strong> do maior para o menor ou do menor para o maior. Se você está mexendo com dados de gastos governamentais, faz sentido ver qual foi a maior compra de todas, por exemplo.</p>
<p><strong>Filtrar</strong> a planilha é interessante para ver se o padrão de comportamento dos dados é o mesmo quando olhamos apenas para um segmento deles. Ainda usando a mesma metáfora, pode ser que o gasto médio de um ministério específico seja muito diferente do gasto médio do governo como um todo.</p>
<p>Da mesma forma, <strong>agregar</strong> os dados pode revelar padrões que não seriam vistos de outra forma: em vez de olhar apenas para cada uma das compras governamentais, individualmente, é possível reuni-las em categorias. Quantas foram feitas por cada departamento? Quanto gastou cada ministério? Você conseguirá fazer esta operação usando operadores de linguagens de programação, como o GROUP BY, ou através das tabelas dinâmicas nos editores de planilha.</p>
<p>Com as tabelas dinâmicas, você conseguirá de fato utilizar os editores de planilha para entrevistar seus dados. Imagine que você tenha uma tabela onde cada linha representa repasses de financiamento de campanha e você gostaria de responder a seguinte pergunta: quais doadores financiaram a maior soma de recursos?</p>
<p>Existem várias operações de análise dos dados que são necessárias para respondê-la: primeiro, você precisa agrupar os doadores de acordo com uma coluna. Ao realizar agrupamentos, sempre dê preferência a usar campos identificadores como CPF ou CNPJ ao invés de campos de texto, como o nome, que são mais suscetíveis a erros de digitação.</p>
<p>Ao agrupá-los, será necessário, então, fazer uma soma na coluna com os valores financiados para, em seguida, ordenar os resultados de forma decrescente e, assim, descobrir os 10 principais financiadores.</p>
<p>Na tabela dinâmica, você conseguirá realizar todas estas operações. Basicamente, a ideia por trás deste recurso é que você deve criar uma nova tabela, que irá “moldar” os dados da planilha original para que eles assumam a forma que você deseja.</p>
<p>Em geral, as linhas dessa nova tabela representam uma entidade, como um doador, nesse exemplo. Nas colunas, geralmente, aparecem os valores agregados por categoria. No exemplo, revelariam a soma total de doações feitas por cada pessoa <strong>.</strong></p>
<p>Assim, independente do software utilizado, o importante ao entrevistar dados com tabelas dinâmicas é saber identificar qual é a forma que essa nova tabela precisa assumir.</p>
<figure>
<img src="images/analise/figura24.png" alt="Exemplo de tabela com as informações originais." /><figcaption aria-hidden="true">Exemplo de tabela com as informações originais.</figcaption>
</figure>
<figure>
<img src="images/analise/figura25.png" alt="Tabela dinâmica gerada automaticamente com os valores da tabela anterior." /><figcaption aria-hidden="true">Tabela dinâmica gerada automaticamente com os valores da tabela anterior.</figcaption>
</figure>
<p>As duas imagens acima mostram como funciona uma tabela dinâmica: o valor pago por cado doador, em diferentes datas, foi agregado em uma única soma.</p>
<p>Por fim, <strong>cruzar</strong> dados também pode ser interessante: o termo significa trazer uma segunda base de dados que possa enriquecer o trabalho de análise. Um exemplo clássico é reunir dados de resultados eleitorais por município com os indicadores de desenvolvimento de cada cidade, por exemplo.</p>
<p>Existem diferentes formas de cruzar tabelas diferentes. Nos editores de planilha, há funções como a procura vertical (PROCV ou, em inglês, VLOOKUP, vertical lookup), que podem resolver cruzamentos mais simples. Porém, à medida que você avançar no trabalho com dados, vai perceber que realizar cruzamentos com editores de planilha não é o ideal. Nestes casos, o recomendável é utilizar linguagens de consulta ou programação, que contam com a poderosa função <strong>join</strong>, responsável por unir tabelas diferentes.</p>
<p>Seja qual for a ferramenta que você adote, o princípio permanece: <strong>para fazer um cruzamento, você precisa de um campo que sirva como identificador, ou seja, uma coluna ou variável que esteja presente nas tabelas que serão cruzadas</strong>. A existência de campo identificador serve como uma “ponte” para conectar bases diferentes e é fundamental para realizar cruzamento.</p>
<p>Além disso, também vale atentar para padrões temporais (os gastos do governo crescem em algum momento do ano?), para outliers suspeitos (por que essa compra específica é muito mais cara que as demais?) e para tendências de crescimento (por que os gastos desse ministério subiram tanto a partir do ano passado?).</p>
<p>No final das contas, a chave para uma boa matéria é a curiosidade e a capacidade de fazer boas perguntas para a planilha. Como vimos, é possível fazer muitas coisas com editores de planilha, mas se você quer realmente progredir na análise de dados é altamente recomendável aprender uma linguagem de programação. Assim, você conseguirá documentar e checar melhor suas análises, além de não ficar limitado às funcionalidades dos editores de planilha.</p>
<p>Como visto no primeiro capítulo, a linguagem SQL pode ser um bom começo. Ao contrário das planilhas, trabalhar com bases de dados em SQL permitirá lidar com volumes grandes de informações. Com ele, você conseguirá fazer operações de análise, mas tenha em mente que esta é antes de tudo uma linguagem de consulta, como o seu nome indica.</p>
<p>Se você quer entrar a fundo na análise de dados, vá para o <strong>Python ou R</strong>. Na linguagem R, a dica para quem quer trabalhar com análise é a biblioteca Tidyverse, uma biblioteca que reúne diversos recursos que facilitam e muito a lida com os dados. Ele é relativamente simples de ser compreendido e guarda muitas semelhanças com o SQL, de modo que pode ser uma opção interessante para quem quer começar com aquela linguagem para depois alçar voos maiores. O Tidyverse também já conta com o ggplot2, uma poderosa ferramenta visualização de dados.</p>
<p>Já em Python, um componente fundamental para manuseio de dados é o <strong>pandas</strong>. Trata-se de um pacote bastante robusto, considerado a principal referência para análise de dados nesta linguagem. Em vez de lidar com loops e condicionais, como é comum no mundo da programação, o pandas implementa uma estrutura de dados chamada <em>dataframe</em>, de modo semelhante ao Tidyverse. Assim, na prática, a análise de dados se assemelha bastante ao trabalho com planilhas, com uma estrutura de colunas e linhas.Ele pode ainda ser combinado com outras bibliotecas, como o <em>matplotlib</em>, parar criar gráficos simples de maneira rápida. Além disso, ele se destaca pela performance ao lidar com grandes volumes de dados ou realizar operações complexas.</p>
<h1 id="visualize">Visualize</h1>
<p>Ainda que a visualização de dados se insira no fluxo de trabalho com dados, esta área se trata de um campo do conhecimento que merece atenção por si só. É impossível falar de forma exaustiva sobre o tema em um capítulo de livro. Assim, nas próximas páginas, a abordagem será pragmática e bastante resumida.</p>
<p>Antes de mais nada, vamos definir o que é visualização de dados: como reconhecer uma visualização de dados na página de uma publicação? Como não confundir com outras formas de representação visual comuns na imprensa?</p>
<p>Na introdução de “<em>The Functional Art</em>”, livro publicado em 2013, o pesquisador <strong>Alberto Cairo</strong> descreve uma cena que testemunhou várias vezes quando trabalhava em redações: quando editores precisavam de um gráfico para acompanhar uma reportagem, dirigiam-se para a equipe de infografia do veículo para encomendar “uma arte”.</p>
<p>O termo, na rotina de trabalho, faz algum sentido. Na hierarquia da maioria dos jornais, a equipe responsável por produzir gráficos está, de algum modo, subordinado à <strong>editoria de Arte</strong>. Nessas editorias, muitas vezes, a maior parte da força de trabalho não tem formação em jornalismo: são designers e artistas visuais, não repórteres e redatores.</p>
<p>Segundo Cairo, porém, o uso desse termo gera um problema. É frequente que, na hora de produzir um jornal, as peças visuais que acompanham o conteúdo da reportagem sejam vistas como mero complemento ou ilustração. Sob essa perspectiva, o conteúdo realmente importante de uma matéria ficaria no texto, enquanto o gráfico serve para resumir o assunto para um leitor pouco interessado ou, simplesmente, para preencher o espaço em branco ou tornar uma página mais agradável esteticamente.</p>
<p>Entretanto, a função de um gráfico não é decorativa. A função primordial de um gráfico é informar - tanto quanto um bloco de texto. Uma visualização de dados impactante concentra tanta informação quanto o <em>lead</em> (o que, quem, quando, onde, como e por que) de uma reportagem.</p>
<p>Para Cairo, a relação entre visualizações e arte é como a relação entre jornalismo e literatura. Segundo ele, um jornalista pode se inspirar nas técnicas e no estilo de um grande ficcionista. Entretanto, seu trabalho nunca deve virar literatura, porque é de outra natureza.</p>
<p>O mesmo vale para a produção de gráficos. Ainda que um bom profissional de visualização tenha apreço pela beleza e elegância de uma peça artística, essa é uma aspiração secundária. O foco é transmitir informação da forma mais precisa possível.</p>
<p>Há uma confusão comum entre visualização de dados e infografia. Existe todo um debate a respeito das definições exatas de cada termo e às vezes os termos são usados de forma intercambiável. Porém, de modo geral, podemos destacar algumas características que distinguem um conceito do outro.</p>
<p>De acordo com a definição proposta por Tatiana Teixeira, pesquisadora da UFSC (Universidade Federal de Santa Catarina), por infográfico, compreendemos uma peça visual com um objetivo narrativo, que explica algo a quem está lendo. São trabalhos que mostram como ocorreu um acidente de avião ou uma operação da polícia, por exemplo. O importante aqui é que os fatos se sucedem de forma mais ou menos contínua no tempo.</p>
<p>Por outro lado, uma visualização de dados estrutura ou tenta traduzir dados quantitativos, codificando visualmente algumas de suas características em dimensões, como cor, forma, tamanho, posição e etc. Como nós humanos somos melhores observando padrões visuais do que numéricos, a visualização de dados nos ajuda a reconhecer padrões e identificar características importantes das bases, que seriam impossíveis de serem enxergadas em tabelas. É o caso dos gráficos de barra, pizza, dispersão entre outros.</p>
<p>Assim, de acordo com esta divisão, um infográfico poderia compreender uma visualização de dados, mas não o inverso. Como dito, a definição explorada neste tópico não é consensual, mas serve para delimitar o escopo desta seção. Neste guia, não iremos abordar as práticas de infografia, mas sim de visualização de dados.</p>
<h3 id="visualização-como-expansão-cognitiva">Visualização como expansão cognitiva</h3>
<p>Alberto Cairo oferece uma definição bastante útil de visualização de dados em “<em>The Truthful Art</em>”, seu livro de 2016. Ele afirma que uma visualização de dados é uma forma de exibir informação quantitativa que é <strong>“desenhada para permitir análises, explorações e descobertas”.</strong></p>
<p>Cairo destaca também que uma visualização de dados não tem como objetivo principal enviar uma mensagem pronta e hermética para o leitor. A ideia desse tipo de gráfico, na verdade, é servir para que as pessoas tirem suas próprias conclusões a partir dos números exibidos.</p>
<p>Assim, visualizações de dados são formas de <strong>aumentar a capacidade de compreensão</strong> humana. A prática funciona porque valores quantitativos, com sua natureza abstrata, são difíceis de analisar e interpretar.</p>
<p>Quando a informação é representada de forma visual, nossa mente é capaz de realizar tarefas como comparação e ordenação de forma mais eficiente.</p>
<p>Um exemplo ajuda a deixar essa realidade mais palpável. O que é mais fácil: fazer uma conta de divisão de cabeça ou comparar o tamanho de uma série de barras em um gráfico?</p>
<p>A segunda opção certamente é menos cansativa que a primeira, a não ser que você seja alguém com uma aptidão fora do comum para a matemática. Entretanto, na prática, ambas as atividades são a realização de uma mesma tarefa: estimar quantas vezes um valor é maior que outro.</p>
<p>Fazer essa operação com um gráfico de barras é mais fácil porque essa visualização de dados foi elaborada para tirar proveito de algumas características da cognição humana - nesse caso, a facilidade em perceber e comparar o tamanho de objetos.</p>
<p>O exemplo do gráfico de barras é o mais simples possível, mas mesmo as visualizações de dados mais complexas partem de um princípio semelhante.</p>
<p>Ainda que seja desejável produzir algo bonito, memorável e divertido, o principal objetivo do bom criador de gráficos é permitir que o seu leitor obtenha uma percepção mais aguçada de fenômenos complexos.</p>
<p>Conforme as formas de mensurar a realidade se tornam mais sofisticadas, as representações visuais também precisam se transformar. Os fundamentos, porém, são relativamente constantes há alguns séculos.</p>
<h2 id="breve-histórico-da-visualização-de-dados">Breve histórico da visualização de dados</h2>
<p>Uma retrospectiva histórica ajuda a demonstrar como o desenvolvimento de formas de representação visual está intimamente ligada à necessidade de realizar tarefas intelectuais e analisar valores quantitativos de forma sistemática. Um dos <a href="http://datavis.ca/">trabalhos mais detalhados sobre o passado do campo</a> foi feito por <strong>Michael Friendly</strong>, professor de psicologia da Universidade de York, em Toronto, no Canadá.</p>
<p>Ele elaborou uma lista de marcos na história da visualização de dados que começa mais de 6 mil anos antes de Cristo, com mapas primitivos. A compilação passa pelo surgimento de tabelas que tentavam representar a posição dos planetas, diagramas trigonométricos e afins, mas vê um ponto de inflexão a partir do século XVII.</p>
<p>É nesse momento que se consolidam áreas do saber que preocupavam-se em mensurar e analisar fenômenos físicos, como a astronomia e a cartografia. Além disso, nasciam os rudimentos das teorias da probabilidade e os primeiros censos demográficos.</p>
<p>Existia, assim, um conjunto de dados relevante e o interesse coletivo por novos métodos de análise. Entretanto, uma quantidade maior de números exigia novas ferramentas para compreendê-los.</p>
<p>É nesse momento histórico que surgem os primeiros gráficos estatísticos modernos, como o gráfico de pizza, de barras e de linha. Boa parte deles foi inventada ou popularizada por <strong>William Playfair</strong>, um engenheiro escocês.</p>
<p>Em 1786, ele publicou uma obra chamada “<em>The Commercial and Political Atlas</em>”, que foi pioneira em usar elementos visuais para representar tendências políticas e econômicas de forma sistemática.</p>
<p>Nos séculos seguintes, o campo da visualização de dados viu desenvolvimentos significativos, com impactos efetivos no discurso público.</p>
<p>Apenas neste livro, já foram citados dois exemplos de trabalhos de visualização de dados que mudaram consensos sociais nessa época: o mapa de cólera de John Snow e os gráficos feitos por Florence Nightingale sobre as causas de morte durante a Guerra da Crimeia.</p>
<p>Tanto Snow como Nightingale não se esforçaram apenas para reunir informações quantitativas. O que fez com que seus levantamentos tivessem efeitos significativos sobre a sociedade foi a apresentação visual.</p>
<p>O mapa de Snow mostra casos de cólera se distribuindo ao redor de um poço de aǵua contaminada, revelando uma relação espacial que não seria fácil de notar a partir de uma simples tabela de endereços. Já os gráficos circulares de NIghtingale revelam que a maior parte das mortes no front do confronto eram causadas por doenças infecciosas e preveníveis, sem que o leitor precise fazer contas e calcular percentuais.</p>
<p>Na prática, os dois se esforçaram para mostrar de forma mais palpável fenômenos que seriam difíceis de perceber e avaliar a olho nu - o que, segundo Cairo, é justamente o que a visualização de dados faz de melhor até hoje, algumas centenas de anos depois.</p>
<h2 id="princípios-práticos">Princípios práticos</h2>
<p>Agora, já temos uma definição mais precisa do que significa o termo <strong>visualização de dados</strong>. Já vimos também que um gráfico serve como ferramenta que ajuda a mente humana a interpretar valores quantitativos abstratos. Além disso, vimos com exemplos históricos como essa prática é antiga e pode ter impactos significativos na sociedade. Resta, agora, aprender conceitos práticos. Nas próximas páginas, vamos ver algumas das ideias básicas que estão por trás de visualizações de dados efetivas.</p>
<p><strong>Um bom gráfico tem uma missão principal: possibilitar uma comunicação efetiva</strong>. De pouco vale uma ideia criativa, uma apresentação bonita e uma boa pauta se a visualização de dados é confusa ou poluída, falhando nessa tarefa básica.</p>
<p>Para garantir que um gráfico seja compreensível, é preciso pensar mais a fundo na <strong>tarefa perceptiva</strong> que ele ajuda a fazer - ou seja, no tipo de análise que o leitor vai tentar realizar.</p>
<p>Seguindo com a metáfora de que a visualização de dados é uma ferramenta, precisamos escolher a peça ideal para o propósito do trabalho.</p>
<p>Assim como não faz sentido algum usar um martelo para apertar um parafuso ou um alicate para prender um prego, há tipos de gráficos específicos para vários tipos de operações mentais.</p>
<p>No final deste capítulo, vamos ver um inventário de formatos que pode ser útil como ferramenta de consulta na hora de escolher a forma de representação adequada para uma reportagem.</p>
<p>Antes disso, porém, precisamos entender <strong>por que</strong> há gráficos que são melhores para algumas coisas do que outros. A resposta tem tudo a ver com a capacidade da mente humana de visualizar e comparar formas.</p>
<h3 id="hierarquia-da-percepção">Hierarquia da percepção</h3>
<p>Em 1984, dois pesquisadores decidiram testar quais tipos de gráficos são mais <strong>precisos</strong> para transmitir informações quantitativas.</p>
<p><strong>William S. Cleveland e Robert McGill</strong> organizaram um experimento em que mostraram para dezenas de colaboradores uma série de visualizações de dados em diferentes formatos: gráficos de barras, de dispersão, de pizza, de bolhas e mapas de cor.</p>
<p>Além disso, eles definiram que tipo de elemento visual era usado em cada um dos gráficos. Em um gráfico de barras, por exemplo, o <strong>comprimento</strong> de cada item é usado para representar um número. Em um gráfico de pizza, os valores são representados pelo <strong>ângulo</strong> de cada fatia.</p>
<p>Os gráficos também foram mostrados com ou sem o auxílio de um <strong>eixo</strong> - ou seja, de uma escala que mostrasse os números representados.</p>
<p>O objetivo do teste era descobrir quais formas gráficas permitiam uma estimativa mais adequada da diferença entre os valores exibidos. O resultado mostrou que alguns formatos de gráfico foram lidos consistentemente de forma mais precisa.</p>
<p>Ao analisar os resultados, os estudiosos propuseram um ranking de formatos, do mais preciso para o menos.</p>
<ol type="1">
<li>Posição sobre um eixo comum</li>
<li>Posição sobre eixos não alinhados</li>
<li>Comprimento</li>
<li>Direção</li>
<li>Ângulo</li>
<li>Área</li>
<li>Volume</li>
<li>Curvatura</li>
<li>Tom de cor</li>
<li>Saturação de cor</li>
</ol>
<p>A imagem a seguir, <a href="https://blogs.elpais.com/periodismo-con-futuro/2012/02/elegirgrafico.html">preparada por Alberto Cairo para o blog Periodismo con futuro</a>, do El País, mostra de que tipo de gráfico falamos em cada item.</p>
<figure>
<img src="images/visualize/figura12.jpg" alt="A hierarquia da percepção segundo experimento de Cleveland e McGill. Fonte: Alberto Cairo." /><figcaption aria-hidden="true">A hierarquia da percepção segundo experimento de Cleveland e McGill. Fonte: Alberto Cairo.</figcaption>
</figure>
<p>Quanto mais alto na escala está a forma de representação, mais fácil é usá-la para fazer comparações precisas. Quanto mais para baixo, mas difícil.</p>
<p>Esta outra imagem, também elaborada por Cairo para o mesmo blog, mostra como isso acontece na prática.</p>
<figure>
<img src="images/visualize/figura13.jpg" alt="Qual destes gráficos permite uma leitura mais precisa? - Fonte: Alberto Cairo (2012)" /><figcaption aria-hidden="true">Qual destes gráficos permite uma leitura mais precisa? - Fonte: Alberto Cairo (2012)</figcaption>
</figure>
<p>Todos os gráficos representam os mesmos valores, mas de diferentes formas. Todavia, os gráficos de barras permitem uma leitura mais precisa e rápida.</p>
<p>É evidente que a segunda barra, por exemplo, é mais alta que a quinta. Contudo, é bem mais difícil dizer qual dos círculos é o maior ou qual das cores é a mais escura.</p>
<p>Assim, é possível afirmar, objetivamente, que os gráficos na parte de cima do espectro permitem comparações mais <strong>precisas</strong>.</p>
<p>Nem sempre a forma gráfica mais precisa é a mais adequada. De vez em quando, não queremos que os leitores façam comparações muito específicas, mas sim que sejam capazes de ver <strong>tendências gerais e padrões</strong>.</p>
<p>Nesses casos, formas próximas da parte inferior da escala passam a ser mais úteis, especialmente quando são usadas em conjunto com outras dimensões, como, por exemplo, em um mapa.</p>
<p>Veja este gráfico sobre o resultado das eleições presidenciais no Brasil em 2018:</p>
<figure>
<img src="images/visualize/figura14.png" alt="Mapa do resultado das eleições presidenciais de 2018 no Brasil, produzido pelo Estadão" /><figcaption aria-hidden="true">Mapa do resultado das eleições presidenciais de 2018 no Brasil, produzido pelo Estadão</figcaption>
</figure>
<p>O objetivo dessa visualização não é fazer com que o leitor descubra qual é a cidade onde Bolsonaro teve mais votos ou comparar precisamente a quantidade de votos recebidos por Haddad em dois municípios distantes. <strong>A ideia é mostrar a distribuição geográfica do voto</strong>, que tende a ser PT na região Nordeste e PSL no Sul. Um gráfico de barras não seria efetivo nesse caso.</p>
<p>De novo, cabe ao autor da visualização determinar qual é a tarefa que seu gráfico vai ajudar a cumprir e transformá-lo na ferramenta mais adequada possível para tal. Vamos ver, agora, um princípio básico das boas visualizações de dados: <strong>ater-se ao que é essencial</strong>.</p>
<h2 id="clareza-vs-emoção">Clareza vs emoção</h2>
<p>Outro pesquisador fundamental do campo da visualização de dados é <strong>Edward Tufte</strong>. Seu livro <em>“The Visual Display of Quantitative Information”</em>, publicado em 1983, é uma das obras mais influentes da área.</p>
<p>Talvez o conceito mais marcante do trabalho de Tufte seja a ideia de <strong>data-ink ratio</strong>, ou a <strong>razão dados-tinta</strong>.</p>
<p>Em resumo, a ideia é que um <strong>gráfico é mais efetivo quando usa a menor quantidade de elementos visuais para comunicar um valor</strong> - ou seja, quando a razão entre os dados comunicados e a quantidade de “tinta” usada para tal for a menor possível.</p>
<p>Na prática, isso significa que Tufte defende a produção de gráficos minimalistas, em que a presença de cada elemento no papel tem uma clara função informativa. Assim, a “densidade de dados” do gráfico aumenta.</p>
<p>Como consequência, surge o conceito de “<em>chart junk</em>”, que pode ser compreendido como a poluição de elementos em um gráfico. São justamente os elementos desnecessários, redundantes, e que não agregam densidade informativa ou que não representam dado algum. Servem apenas como decoração, para efeitos estéticos - e mesmo assim, na maioria das vezes, deixam a apresentação do conteúdo mais feia em vez de interessante.</p>
<p>Veja o gráfico a seguir, gerado a partir de dados ficcionais, sem muito esforço nem ou atenção ao design no Google Sheets.</p>
<figure>
<img src="images/visualize/figura15.png" alt="Exemplo de gráfico de barras com elementos visuais desnecessários." /><figcaption aria-hidden="true">Exemplo de gráfico de barras com elementos visuais desnecessários.</figcaption>
</figure>
<p>Vamos analisá-lo a partir dos princípios de Tufte que acabamos de conhecer.</p>
<p>Primeiro, percebemos que há uma série de elementos redundantes nessa visualização: o eixo, na esquerda, exibe os mesmos valores que os rótulos em cima de cada uma das barras.</p>
<p>O título do gráfico, “gastos mensais”, aparece também no eixo esquerdo. E uma legenda completamente descartável revela que as barras de cor vermelha representam “gastos”.</p>
<p>Além disso, existem elementos que não agregam dado algum. Qual é a razão das barras estarem em 3D, quando a única dimensão que importa é a altura, e não a profundidade ou a largura? Por que tantas linhas no fundo, por que tantos marcadores no eixo vertical, por que aplicar uma sombra cinza na base das barras?</p>
<p>Removendo todos estes elementos, ficamos com um gráfico mais próximo daquilo que Tufte considera o ideal. A visualização a seguir foi feita em ainda menos tempo no <a href="https://app.datawrapper.de/">Datawrapper</a>, uma ferramenta gratuita disponível online.</p>
<figure>
<img src="images/visualize/figura16.png" alt="O mesmo gráfico, porém com uma apresentação mais minimalista" /><figcaption aria-hidden="true">O mesmo gráfico, porém com uma apresentação mais minimalista</figcaption>
</figure>
<p>Perceba como o gráfico fica mais fácil de ler. O motivo é que não há mais elementos redundantes ou pouco informativos disputando atenção. Assim, nossos olhos e cérebro conseguem se concentrar apenas naquilo que importa.</p>
<p>Agora, faça o mesmo exercício com o próximo gráfico.</p>
<figure>
<img src="images/visualize/figura17.png" alt="Gráfico publicada na Glamour Magazine na década de 1980, feito por Nigel Holmes." /><figcaption aria-hidden="true">Gráfico publicada na Glamour Magazine na década de 1980, feito por Nigel Holmes.</figcaption>
</figure>
<p>Segundo as regras dispostas por Tufte, o que pensar deste trabalho pouco convencional?</p>
<h3 id="conectando-se-com-o-público">Conectando-se com o público</h3>
<p>O gráfico anterior foi produzido por <strong>Nigel Holmes</strong>, um designer gráfico que ficou conhecido por ter feito carreira na revista Time. Praticamente toda a sua produção é marcada por uma mistura entre ilustração e visualização de dados, praticamente a antítese de todos os conceitos que expusemos até aqui.</p>
<p>O trabalho de Holmes foi alvo de críticas ferozes por parte de Tufte, que destacou um gráfico em especial, mostrado a seguir, para um achincalhamento público.</p>
<figure>
<img src="images/visualize/figura18.jpg" alt="Gráfico publicado na revista Time em agosto de 1982, feito por Nigel Holmes." /><figcaption aria-hidden="true">Gráfico publicado na revista Time em agosto de 1982, feito por Nigel Holmes.</figcaption>
</figure>
<p>Para Tufte, as peças apresentadas anteriormente são ultrajantes.</p>
<p>Em <em>Envisioning Information (1990)</em>, outro de seus livros, o pesquisador usa esse gráfico como exemplo de “chartjunk” que menospreza a audiência, que é tratada com obtusa e desinteressada.</p>
<p>Além disso, Tufte afirma que quem faz esse tipo de gráfico promove a ideia de que informação é algo chato, que precisa de decoração para ficar interessante.</p>
<p>Diante de uma crítica tão pesada de um nome tão relevante para o campo, o trabalho de Holmes se transformou em um exemplo do que <strong>não fazer</strong> na hora de desenhar gráficos.</p>
<p>Entretanto, apesar das críticas acadêmicas, Nigel Holmes seguiu fazendo sucesso, tornou-se diretor de arte da revista em que trabalhava e, posteriormente, um consultor independente. Alguns de seus gráficos, por bem ou por mal, estão entre os mais memoráveis da história da imprensa e do design.</p>
<p>Assim, vale a pena olhar também para essa perspectiva sobre a visualização de dados, diametralmente oposta aos pontos que elucidamos até aqui.</p>
<p>O que Holmes tem a dizer sobre as críticas que recebeu? Como justifica suas decisões criativas? O que pesquisas revelam sobre esse tipo de linguagem hoje, 30 anos depois da crítica violenta de Tufte?</p>
<p>O pesquisador Ricardo Cunha Lima, professor da Universidade Federal de Pernambuco (UFPE), analisou em <a href="http://pdf.blucher.com.br.s3-sa-east-1.amazonaws.com/designproceedings/9cidi/1.0222.pdf">um artigo</a> de 2019 quais era os elementos típicos da linguagem de Holmes. Segundo ele, Holmes adotou o uso de metáforas visuais marcantes porque acreditava que esse tipo de conteúdo tornaria mais palatáveis temas complexos, com os quais os leitores provavelmente nunca tiveram contato algum antes.</p>
<p>Em uma <a href="https://www.youtube.com/watch?time_continue=931&amp;v=WB7DCEayj3w&amp;feature=emb_logo">palestra de 2015</a> na conferência OpenVis, em Boston, o próprio Holmes defende o uso de humor como forma de <strong>conectar-se com a audiência</strong> e explicar assuntos complexos de forma quase conversacional.</p>
<p>Desta forma, percebe-se que o objetivo do designer era comunicar informação relativamente complexa de forma mais aprazível para um público leigo.</p>
<p>O argumento central dessa posição, portanto, é que os elementos redundantes e decorativos não são descartáveis, mas sim formas de facilitar a compreensão sobre os temas tratados usando uma linguagem figurativa, explicativa e amigável.</p>
<p>Uma <a href="http://hci.usask.ca/uploads/173-pap0297-bateman.pdf">pesquisa</a> feita por Scott Bateman e mais cinco acadêmicos da Universidade de Saskatchewan, no Canadá, colocou o conceito a prova.</p>
<p>Os estudiosos pediram para que voluntários avaliassem gráficos que representavam os mesmos dados, mas em duas versões diferentes: uma no estilo decorado de Holmes e outro em um formato minimalista que se aproximava mais das convicções de Tufte.</p>
<figure>
<img src="images/visualize/figura19.png" alt="Exemplo de um gráfico com chart junk e um gráfico minimalista com os mesmos dados" /><figcaption aria-hidden="true">Exemplo de um gráfico com <em>chart junk</em> e um gráfico minimalista com os mesmos dados</figcaption>
</figure>
<p>Os leitores eram questionados, logo depois de ler o gráfico, sobre os números que viram e outras questões de ordem mais técnica, como a tendência demonstrada pelos dados.</p>
<p>Além disso, os participantes responderam a perguntas sobre o tipo de gráfico que preferiam e se avaliavam que a imagem mostrava apenas dados objetivos ou se exibia também alguma forma de interpretação ou opinião.</p>
<p>Por fim, depois de um intervalo de cerca de duas semanas, os voluntários foram questionados sobre o que <strong>lembravam</strong> sobre cada um dos gráficos.</p>
<p>O estudo descobriu que não havia diferenças significativas na precisão da leitura dos gráficos no estilo de Holmes e no estilo minimalista - ou seja, os voluntários conseguiram ler os gráficos da mesma maneira, interpretando tanto gráficos decorados quanto gráfico sem “chartjunk” de forma correta na mesma proporção.</p>
<p>Entretanto, os gráficos no estilo cartum foram mais <strong>lembrados</strong> depois do intervalo longo, o que sugere que eles são mais <strong>memoráveis</strong> - ou seja, que a informação comunicada por visualizações nesse formato são mais marcantes para o público.</p>
<p>Além disso, os participantes disseram gostar mais dos gráficos com elementos decorativos. Por fim, eles também notaram mais elementos interpretativos e opinativos nos trabalhos de Holmes - o que, pode-se argumentar, torna essas visualizações menos úteis como ferramentas que aumentam as capacidades de percepção do leitor.</p>
<p>Essa pesquisa, claro, não resolve debate algum. O texto, inclusive, recebeu <a href="https://perceptualedge.com/articles/visual_business_intelligence/the_chartjunk_debate.pdf">pesadas críticas metodológicas</a> de pesquisadores contemporâneos, como Stephen Few. Os achados servem, sobretudo, para mostrar que há espaço para discussão em torno do tema.</p>
<h2 id="tarefas-perceptivas-e-gráficos">Tarefas perceptivas e gráficos</h2>
<p>Depois de visitar essa quantidade monumental de conceitos, podemos finalmente listar alguns dos formatos mais comuns de gráficos.</p>
<p>Neste momento, vamos inverter o processo. Em vez de começar com uma lista de visualizações, vamos elencar algumas das <strong>tarefas perceptivas</strong> mais comuns na leitura de uma visualização de dados.</p>
<p>A apresentação segue essa ordem porque, para elaborar uma boa visualização de dados, é preciso ao menos ter alguma ideia prévia de sua <strong>função</strong> - ou seja, de que tipo de ferramenta mental o gráfico pretende ser.</p>
<p>Depois dessa reflexão, é necessário escolher um formato de representação funcional. Assim, <strong>vamos descobrir quais são os formatos de gráficos que funcionam melhor para fazer comparações precisas ou ver a evolução de fenômenos ao longo, entre outras possibilidades</strong>.</p>
<p>Vamos começar por formatos mais comuns, que costumam aparecer com frequência na televisão e nos jornais, em programas e notícias generalistas. Conforme a lista avança, porém, surgirão alguns formatos que não são tão usuais fora da análise de dados e da estatística.</p>
<h3 id="comparar-valores-de-forma-precisa">Comparar valores de forma precisa</h3>
<p>Essa, talvez, seja a tarefa perceptiva mais simples que uma visualização de dados pode ajudar a executar. Aqui, <strong>o objetivo é fazer com que o leitor consiga contrastar de forma precisa o tamanho de poucas grandezas</strong>.</p>
<p>Assim, faz sentido escolher formas visuais que tenham maior precisão na escala elaborada por Cleveland e McGill. Entre as formas de representação mais perto do topo, como vimos, estão aquelas que posicionam os dados em um eixo fixo.</p>
<p>Dessa forma, os formatos mais indicados para essa tarefa são <strong>gráficos de barra</strong> ou alguma de suas variantes. Veja a seguir uma visualização que compara a quantidade de imposto pago em relação a renda em alguns países.</p>
<figure>
<img src="images/visualize/figura20.png" alt="Gráfico de barras publicado na The Economist. Note que aqui a barra é composta por dois valores, cada um representado por uma cor. Na prática, eles se somam para representar uma barra única." /><figcaption aria-hidden="true">Gráfico de barras publicado na The Economist. Note que aqui a barra é composta por dois valores, cada um representado por uma cor. Na prática, eles se somam para representar uma barra única.</figcaption>
</figure>
<p>Para decodificá-la, o leitor precisa localizar o ponto final da barra e comparar a posição dela com a das demais, que estão na mesma escala. É fácil perceber, por exemplo, que Hong Kong tem uma carga tributária de perto de 12% e que a Suíça se aproxima dos 18%.</p>
<p>O exemplo é particularmente interessante porque funciona para fazer uma <strong>comparação entre os diferentes países</strong>, mas também permite enxergar a distribuição do imposto <strong>dentro</strong> de cada um deles. Vamos falar mais sobre essa segunda tarefa a seguir.</p>
<p><strong>Comparar partes do todo</strong></p>
<p>Aqui, a tarefa é parecida com a anterior, mas não estamos mais comparando valores independentes. Em vez disso, queremos saber como se distribuem, por exemplo, opiniões dentro de um grupo de pessoas.</p>
<p>Talvez a forma mais usual de representar dados como estes seja um gráfico de pizza. Entretanto, ao consultar o ranking da percepção visual, vemos que representações com base em ângulos não são boas para nem para comparações precisas nem para enxergar tendências gerais.</p>
<p>Esse tipo de gráfico fica bem no meio da escala, o que indica que não é muito bom para nenhum tipo de tarefa. Assim, não faz sentido usá-lo.</p>
<p>Por sorte, existem alternativas melhores. Vamos voltar para o gráfico de barras que mostramos acima, mas agora olhando para uma linha de cada vez.</p>
<p>Recapitulando: estamos vendo qual é a composição da carga tributária de um país. A parte <strong>azul clara</strong> mostra o <strong>percentual referente ao imposto de renda</strong>. A parte <strong>azul escura</strong> , o <strong>percentual referente à seguridade social</strong>.</p>
<p><img src="images/visualize/figura21.png" /></p>
<p>Agora, para descobrir qual parte é maior, em vez de comparar ângulos, estamos comparando <strong>comprimento</strong>.</p>
<p>Ainda que os dois segmentos da barra não estejam alinhados verticalmente, é relativamente fácil perceber que a parte escura é cerca de três vezes menor que a parte clara.</p>
<p>Caso você tenha ficado curioso, o nome desse tipo de gráfico é <strong>barra empilhada</strong>, ou <strong>stacked bar</strong>.</p>
<p>A ideia é que as diferentes partes de um mesmo item sejam representadas por pedaços de reta colocados um em cima do outro. Assim, a barra pode ser lida a partir de cada segmento individual e também como a soma de todos eles.</p>
<p>Esse formato traz a vantagem, como vimos, de permitir a comparação da distribuição interna de diferentes grupos.</p>
<p>Se essa não for uma preocupação, porém, talvez o melhor a se fazer seja usar um gráfico de barras simples, separadas e alinhadas. Assim, ganha-se mais precisão.</p>
<p>Nesse caso, o formato não sugeriria que todos os itens fazem parte de um mesmo grupo, mas esse é um problema que pode ser superado facilmente com informações de contexto, com em um título ou legenda.</p>
<h3 id="enxergar-tendências-temporais">Enxergar tendências temporais</h3>
<p>Na prática, quando queremos ver a evolução de um valor ao longo do tempo, poderíamos usar gráficos de barra, com uma barra para cada data. No final das contas, a tarefa executada é uma <strong>comparação entre valores</strong>.</p>
<p>Geralmente, ao analisar uma série temporal, não queremos que o foco de leitor seja na diferença <strong>exata</strong> entre uma data e outra. Usualmente, queremos que ele perceba <strong>se o movimento dos dados é de subida ou de queda</strong>.</p>
<p>Assim, faz sentido usar um formato de visualização que realça a tendência e, de quebra, mostra que os pontos de dados estão conectados de forma linear: gráficos de linha.</p>
<p>Vamos analisar o gráfico abaixo, <a href="https://archive.nytimes.com/www.nytimes.com/imagepages/2006/08/26/weekinreview/27leon_graph2.html?ref=patrick.net">publicado pelo The New York Times</a> em 2006.</p>
<figure>
<img src="images/visualize/figura22.png" alt="Gráfico de linhas apresenta tendências de ascensão e queda" /><figcaption aria-hidden="true">Gráfico de linhas apresenta tendências de ascensão e queda</figcaption>
</figure>
<p>Na prática, poderíamos substituir essa linha por uma série de barras ou pontos: o valor de cada ano é representado, afinal, pela posição do ponto mais alta da linha.</p>
<p>Ao conectar esses pontos, porém, o <strong>tracejado sugere conexão e movimento</strong>. Além disso, a inclinação gerada pelas ligações enfatiza a ideia de <strong>queda e subida</strong>, ainda que seja mais difícil perceber a variação exata de valor entre um ano e outro.</p>
<p>Perceba que aqui começamos a passar para a outra ponta da hierarquia da percepção, onde a preocupação passa a ser a percepção de tendências mais amplas e não a comparação exata entre valores.</p>
<p>No próximo item, vamos falar de forma mais genérica sobre a utilidade de representações desse tipo.</p>
<h3 id="enxergar-tendências-gerais">Enxergar tendências gerais</h3>
<p>Parece um contrassenso escolher formas menos precisas quando temos à disposição gráficos que permitem fazer comparações precisas.</p>
<p>Quando, afinal, faz sentido usar as representações visuais que ocupam a parte de baixo do ranking elaborado por Cleveland e McGill?</p>
<p>Geralmente, isso acontece quando um olhar mais distante <strong>revela padrões que não podem ser detectados comparando poucos pontos de dados</strong>.</p>
<p>De vez em quando, é melhor perder precisão e ganhar escopo, permitindo assim que a <strong>visualização de dados revele uma realidade mais ampla</strong>.</p>
<p>Vamos olhar para um exemplos prático e marcante que mostra como uma abordagem menos precisa pode ser útil. A visualização de dados usa cores, tidas como a mais imprecisa das formas de representação, para oferecer um olhar original sobre um tema já muito explorado.</p>
<figure>
<img src="images/visualize/figura23.png" alt="Warming stripes, listras do aquecimento, publicadas pelo climatologista Ed Hawkins em 2018." /><figcaption aria-hidden="true"><em>Warming stripes</em>, listras do aquecimento, publicadas pelo climatologista Ed Hawkins em 2018.</figcaption>
</figure>
<p>O gráfico acima representa a evolução da temperatura média do planeta entre 1850 e 2018. Quando a temperatura de um ano está acima do valor médio registrado entre 1970 e 2000, ele é pintado em um tom de vermelho. Quando está abaixo, em um tom de azul. Quanto maior for a diferença, mais escura é a cor.</p>
<p>Como esperado, é muito difícil dizer <strong>quantas vezes</strong> a temperatura de um ano específico é maior do que a de qualquer outro. Contudo, o gráfico revela como a tendência de aquecimento é evidente.</p>
<p>Essa visualização funciona não apenas porque é esteticamente agradável, mas porque o autor reconheceu que o mais central em sua mensagem era realçar as <strong>linhas gerais</strong> do fenômeno.</p>
<p>Pouco importa quantos graus a mais o ano de 2008 teve em comparação ao ano de 1987, afinal. O que importa, em resumo, é que a década de 1980 foi mais fria que a década de 2000.</p>
<p>Logicamente, seria possível produzir vários outros gráfico que passe a mesma mensagem de forma mais precisa, mas é difícil imaginar um formato que tenha o mesmo efeito intuitivo. Ao ver essa imagem, o leitor de imediato entende o que está representado.</p>
<h3 id="enxergar-a-distribuição">Enxergar a distribuição</h3>
<p>Por fim, vamos apresentar um formato muito parecido com o gráfico de barras, mas que não é exatamente a mesma coisa: o <strong>histograma.</strong></p>
<p>Trata-se de um tipo de visualização que mostra qual é a <strong>distribuição</strong> dos dados, o que é essencial para entender melhor as características do fenômeno que estamos analisando.</p>
<figure>
<img src="images/visualize/figura26.png" alt="Histograma com distribuição das notas no Enem" /><figcaption aria-hidden="true">Histograma com distribuição das notas no Enem</figcaption>
</figure>
<p>O gráfico anterior mostra a distribuição das notas no Enem 2018: muitos alunos tiraram entre 400 e 600. Poucos tiraram um valor perto de 800. No exemplo, o eixo horizontal representa a variedade possível de notas no Enem, de 0 a 800. O eixo vertical mostra quantos alunos tiraram cada nota nesse intervalo.</p>
<p>A barra mais alta, por exemplo, mostra que cerca de 200 mil estudantes tiraram uma nota próxima de 500. Essa é a <strong>moda</strong> , o valor mais comum do banco de dados.</p>
<p>O gráfico realça essa diferença e mostra, ainda, que uma quantidade muito pequena de alunos conseguiu notas próximas de 800 – ou seja, que essas altas pontuações são eventos raros que distorcem o cálculo das estatísticas descritivas.</p>
<p>Isso é evidenciado pelo valor da <strong>média</strong> , que está representada pela <strong>linha preta pontilhada</strong> , com um valor um pouco superior ao da moda.</p>
<p>Depois de ver um gráfico como esse, o leitor consegue uma percepção mais detalhada <strong>de todo o banco de dados</strong> e pode entender melhor quais são as tendências e quantidades envolvidas.</p>
<p>De teor um pouco mais técnico, esse tipo de gráfico não costuma aparecer muito em reportagens, apesar de ser muito útil na hora de analisar dados.</p>
<p>Com cuidado e atenção especial para as explicações, ele pode ser uma ferramenta útil para explicar fenômenos complexos para o leitor, como no exemplo abaixo, retirado de <a href="https://www.estadao.com.br/infograficos/educacao,no-enem-1-a-cada-4-alunos-de-classe-media-triunfa-pobres-sao-1-a-cada-600,953041">uma reportagem do Estadão</a> sobre o impacto da desigualdade socioeconômica nos resultados do Enem.</p>
<figure>
<img src="images/visualize/figura27.png" alt="Histogramas sobrepostos para a comparação de distribuições" /><figcaption aria-hidden="true">Histogramas sobrepostos para a comparação de distribuições</figcaption>
</figure>
<p>A sobreposição de três histogramas, no caso, revela que a distribuição de notas dos alunos mais ricos tende muito mais para a direita – e para as notas mais altas – do que a dos alunos mais pobres.</p>
<h2 id="ferramentas-para-visualização-de-dados">Ferramentas para visualização de dados</h2>
<p>Depois da exposição teórica, é hora de criar os próprios gráficos. Existem inúmeros <em>softwares</em> para fazer visualizações de forma fácil e rápida.</p>
<p>Todavia, é importante dizer que esse tipo de ferramenta importa menos do que os princípios básicos expostos anteriormente. O crucial é entender como gráficos funcionam e quais são os formas mais efetivas de usá-los.</p>
<p>Para isso, não há aprendizado melhor que <strong>desenhar</strong> com lápis e papel. Não é necessário riscar gráficos perfeitos e precisos, mas é útil tentar esboçar o que você espera construir antes de começar a clicar nos botões de algum aplicativo.</p>
<p>Ao fazer isso, é inevitável pensar nas tarefas perceptivas que a sua visualização de dados pretende auxiliar. Além disso, esse processo analógico ajuda a entender melhor as características de sua base de dados.</p>
<p>Sobre este último ponto, vale destacar algo que, de tão óbvio, muitas vezes acaba ignorado. Visualizações de dados são ferramentas que ajudam pessoas a entender melhor valores quantitativos, como vimos ao longo das páginas anteriores.</p>
<p>Separamos uma seleção de 10 ferramentas para visualização de dados, que são úteis tanto para quem está começando quanto para pessoas com mais conhecimento.</p>
<ul>
<li><p><strong>Flourish</strong> (web): tem uma interface amigável e permite a criação de gráficos interativos, que podem ser unidos em histórias;</p></li>
<li><p><strong>Datawrapper</strong> (web): produz gráficos elegantes facilmente, com atualização em tempo real e edição colaborativa;</p></li>
<li><p><strong>Raw Graphs</strong> (web): bom para gráficos pouco usuais, é baseado em D3 (JavaScript) e tem código aberto;</p></li>
<li><p><strong>GGplot2</strong> (R): tem uma “gramática” para visualização de dados que é considerada referência, permitindo produzir gráficos muito elegantes em poucas linhas;</p></li>
<li><p><strong>Tableau</strong> (Windows/MacOS): fácil de usar, bom para análises exploratórias;</p></li>
<li><p><strong>Matplotlib</strong> (Python): bom para gráficos simples e análises exploratórias;</p></li>
<li><p><strong>Seaborn</strong> (Python): permite a criação de gráficos mais complexos;</p></li>
<li><p><strong>Google Charts</strong> (JavaScript): conta com diversos modelos/templates, além de gráficos responsivos;</p></li>
<li><p><strong>D3</strong> (JavaScript): permite a criação de isualizações complexas na web, conta com ampla documentação e exemplos;</p></li>
<li><p><strong>C3</strong> (JavaScript): baseado em D3, porém, mais simples, permite gerar visualizações interativas e responsivas.</p></li>
</ul>
<p>No jornalismo, é comum tratar um gráfico como ponto final do processo de apuração, etapa em que aquilo que foi descoberto durante a análise de dados é comunicado para o leitor.</p>
<p>Pensar dessa maneira, porém, é ignorar um dos maiores potenciais da visualização de dados. Ainda durante a fase da análise de dados, vale a pena elaborar gráficos para entender melhor os números com os quais você está trabalhando. Com paciência, tentativa e erro, é bem possível que tendências até então ignoradas aparecem, revelando novos ângulos para uma reportagem.</p>
<h1 id="conclusão">Conclusão</h1>
<p>Ainda que este livro possa te dar um pontapé para começar a trabalhar com dados, nem de longe iremos esgotar todo o universo sobre o tema. Tanto por conta de sua complexidade própria quanto pelo ritmo incessante de novidades na área, a utilização de de dados na comunicação hoje é um campo em constante crescimento. E, como em muitas outras áreas, o melhor aprendizado se dá na prática.</p>
<p>Por isso, para terminar este guia, iremos compartilhar algumas dicas de como você pode continuar aprendendo. Na Escola de Dados, acreditamos que este processo de aprendizagem é impulsionado por experiências coletivas e comunitárias. Por isso, estimulamos encontros (como o <a href="https://escoladedados.org/2018/02/que-tal-organizar-um-cerveja-com-dados-em-sua-cidade/">Cerveja com Dados</a> e a Conferência de Jornalismo de Dados e Métodos Digitais, o <a href="http://coda.escoladedados.org/">Coda.Br</a>) e, em parceria com a Associação Brasileira de Jornalismo Investigativo (ABRAJI), mantemos o <a href="http://jornalismodedados.org/">jornalismodedados.org</a>.</p>
<p>Além de reconhecer trabalhos de excelência que podem servir de inspiração para outras pessoas com o Prêmio Cláudio Weber Abramo de Jornalismo de Dados, esta plataforma mantém um fórum aberto e gratuito para a resolução de dúvidas, discussões sobre tópicos de interesse e divulgação de oportunidades.</p>
<p>No Brasil, há uma comunidade de jornalistas de dados bastante colaborativa e disposta a ajudar na disseminação do conhecimento. Espaços como o Fórum de Jornalismo de Dados reúnem profissionais experientes e iniciantes em um mesmo espaço de troca de conhecimento. Há outros canais, como <a href="https://t.me/joinchat/APE1P0zjg2w1mLdAlp9MUg">grupos abertos no Telegram</a> ou no <a href="https://www.facebook.com/groups/jornalismodedados">Facebook</a>.</p>
<p>E o mesmo vale para linguagens de programação como o R e o Python, que possuem comunidades bastante ativas, como os grupos no Telegram <a href="https://t.me/rbrasiloficial">R Brasil</a> ou <a href="https://t.me/datasciencepython">Pt-BR Data Science &amp; Python</a>. Há também canais como o <a href="https://stackoverflow.com/">Stack Overflow</a>, um lugar que provavelmente terá a resposta para a sua dúvida com linguagens de programação e, caso não tenha, você pode postar sua questão para que outras pessoas possam te ajudar. Há um Stack Overflow em português, porém, assim como toda documentação da área de ciência de dados, a quantidade de conteúdos em inglês é infinitamente maior.</p>
<p>As comunidades das linguagens R e Python também realizam encontros no Brasil e no mundo. Esses encontros locais são uma excelente porta de entrada para você se aventurar no mundo da programação. Conhecendo e compartilhando experiências com as pessoas localmente, você irá se sentir muito mais motivado a aprender do que lutando contra as dificuldades sozinho com seu computador. Procure os encontros (meetups), grupos e ações das comunidades na sua cidade ou no seu estado.</p>
<p>Além dos grupos regionais, há também diversas comunidades voltadas a grupos específicos, com recorte de gênero ou raça, por exemplo. Infelizmente, apesar da contribuição decisiva de mulheres para o desenvolvimento da computação, a área tecnológica ao longo do século XX se tornou um campo predominantemente masculino, o que gera dificuldades na inserção de mulheres ainda hoje. Para superar esse desafio, foram criadas redes como <strong>PyLadies</strong> e <strong>R-Ladies</strong>.</p>
<p>Ambas atuam hoje internacionalmente para fomentar comunidades de tecnologia mais plurais. E nos dois casos o Brasil ocupa um lugar de destaque. Em 2019, o país tinha o maior número de capítulos regionais da PyLadies no mundo e a R-Ladies foi fundada por uma brasileira nos idos de 2012, a estatística Gabriela de Queiroz, que atualmente trabalha na IBM. Também no Brasil surgiram experiências que buscam fomentar uma maior diversidade racial na área, como <strong>AfroPython</strong>.</p>
<p>Essas comunidades servem como canais para a troca de experiência e colaboração entre as pessoas. Além de estudar e praticar, participar delas sem dúvida vai ter ajudar a quebrar barreiras e superar dificuldades. Esses espaços servem para tirar dúvidas e tomar conhecimento sobre eventos e atividades da área, mas também existem diversos cursos que podem te dar um empurrão inicial. Em Python, há opções em português como o <a href="https://www.pycursos.com/python-para-zumbis/">Python para Zumbis</a> e, no R, as formações do <a href="https://www.curso-r.com/">Curso-R</a>.</p>
<p>A <a href="http://escoladedados.org/">Escola de Dados</a> também oferece cursos e conta com diversos tutoriais gratuitos. Outras referências interessante são os cursos da <a href="https://www.abraji.org.br/">Abraji</a> e do <a href="https://knightcenter.utexas.edu/">Knight Center for Journalism in the Americas</a>, que frequentemente abordam temas relacionados ao jornalismo de dados.</p>
<p>Por fim, se você gostou deste guia e quer apoiar o trabalho da Escola de Dados, fica aqui nosso convite para o nosso programa de membresia. Nele, você terá acesso a uma newsletter exclusiva para ficar por dentro das principais atualizações da área, além de receber descontos nos cursos e participar de canais exclusivos com nossa equipe.</p>
<h1 id="referências">Referências</h1>
<ul>
<li><a href="https://5stardata.info/en/">5-star Open Data - Tim Berners-Lee</a></li>
<li><a href="https://www.nexojornal.com.br/grafico/2018/10/05/30-anos-o-quanto-a-Constitui%C3%A7%C3%A3o-preserva-de-seu-texto-original">30 anos: o quanto a Constituição preserva de seu texto original - Nexo</a></li>
<li><a href="http://www.holovaty.com/writing/fundamental-change/">A fundamental way newspaper sites need to change - Adrian Holovaty</a></li>
<li><a href="https://onlinejournalismblog.com/2020/03/24/a-journalists-guide-to-cognitive-bias-and-how-to-avoid-it/">A journalist’s guide to cognitive bias (and how to avoid it) - Paul Bradshaw</a></li>
<li><a href="https://www.oreilly.com/library/view/bad-data-handbook/9781449324957/">Bad Data Handbook - Q. Ethan McCallum</a></li>
<li><a href="https://www1.folha.uol.com.br/equilibrioesaude/2020/05/base-de-dados-de-cartorios-traz-falhas-que-impedem-calcular-efeito-real-do-coronavirus-no-brasil.shtml">Base de dados de cartórios traz falhas que impedem calcular efeito real do coronavírus no Brasill - Folha de S.Paulo</a></li>
<li><a href="https://arte.estadao.com.br/politica/basometro/">Basômetro - Estadão</a></li>
<li><a href="https://docs.google.com/document/d/1BfLPJpRtyq4RFtHJoNpvWQjmGnyVkfE2HYoICKOGguA/edit#">Bellingcat’s Online Investigation Toolkit - Bellingcat</a></li>
<li><a href="http://buscaprecedentes.cgu.gov.br/busca/SitePages/principal.aspx">Busca Precedentes - Controladoria Geral da União</a></li>
<li><a href="https://www3.bcb.gov.br/CALCIDADAO/publico/exibirFormCorrecaoValores.do?method=exibirFormCorrecaoValores">Calculadora de correção de valores - Banco Central</a></li>
<li><a href="http://dados.gov.br/pagina/cartilha-publicacao-dados-abertos">Cartilha Técnica para Publicação de Dados Abertos no Brasil - Governo Federal</a></li>
<li><a href="https://noticias.uol.com.br/meio-ambiente/ultimas-noticias/redacao/2019/05/17/com-bolsonaro-liberacao-de-agrotoxicos-cresceu-42-diz-estudo.htm">Com Bolsonaro, liberação de agrotóxicos cresceu 42%, diz estudo - Uol</a></li>
<li><a href="http://www.consultaesic.cgu.gov.br/busca/SitePages/principal.aspx">Consulta E-sic - Controladoria Geral da União</a></li>
<li><a href="http://tede2.pucrs.br/tede2/bitstream/tede/4590/1/461784.pdf">Entrevistando planilhas: estudo das crenças e do ethos de um grupo de profissionais de jornalismo guiado por dados no Brasil - Marcelo Träsel</a></li>
<li><a href="https://escoladedados.org/tutoriais/expressao-regular-pode-melhorar-sua-vida/">Expressão regular pode melhorar sua vida - Escola de Dados</a></li>
<li>Envisioning Information - Edward Tufte</li>
<li><a href="https://escoladedados.org/tutoriais/guia-quartz-para-limpeza-de-dados/#planilha-tem-65536-linhas">Guia para Quartz para Limpeza de Dados</a></li>
<li><a href="https://onlinejournalismblog.com/2020/04/07/how-to-prevent-confirmation-bias-affecting-your-journalism/">How to prevent confirmation bias affecting your journalism - Paul Bradshaw</a></li>
<li><a href="https://qz.ai/how-youre-feeling-when-machine-learning-might-help/">How you’re feeling when machine learning might help - Jeremy Merrill</a></li>
<li><a href="https://journals.sagepub.com/doi/full/10.1177/1326365X18780418">‘I Don’t Like Maths, That’s Why I am in Journalism’: Journalism Student Perceptions and Myths about Data Journalism - Amy Schmitz Weiss e Jéssica Retis</a></li>
<li><a href="https://www.ibge.gov.br/explica/inflacao.php">Inflação - IBGE</a></li>
<li><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine bias risk assessments in criminal sentencing - ProPublica</a></li>
<li><a href="http://pdf.blucher.com.br.s3-sa-east-1.amazonaws.com/designproceedings/9cidi/1.0222.pdf">Metáforas e gráficos pictórico-esquemáticos de Nigel Holmes - Ricardo Cunha Lima</a></li>
<li><a href="https://g1.globo.com/monitor-da-violencia/noticia/monitor-da-violencia-do-g1-vence-o-data-journalism-awards-na-categoria-escolha-do-publico.ghtml">Monitor da Violência - G1</a></li>
<li><a href="https://www.estadao.com.br/infograficos/educacao,no-enem-1-a-cada-4-alunos-de-classe-media-triunfa-pobres-sao-1-a-cada-600,953041">No Enem, 1 a cada 4 alunos de classe média triunfa. Pobres são 1 a cada 600 - Estadão</a></li>
<li>Numbers in the newsroom - Sarah Cohen</li>
<li><a href="https://escoladedados.org/tutoriais/operadores-de-busca-avancada/">Operadores de busca avançada - Escola de Dados</a></li>
<li><a href="https://www.estadao.com.br/infograficos/politica,o-que-revela-uma-analise-das-emocoes-dos-candidatos-durante-o-debate,923037">O que revela uma análise das emoções dos candidatos durante o debate - Estadão</a></li>
<li><a href="https://lume.ufrgs.br/bitstream/handle/10183/172614/001060430.pdf?sequence=1">O uso de fontes documentais no jornalismo guiado por dados - Marília Gehrke</a></li>
<li><a href="https://www.icij.org/investigations/panama-papers">Panama Papers - ICIJ</a></li>
<li><a href="https://pudding.cool/2018/08/pockets/">Pockets - The Pudding</a></li>
<li>Precision Journalism: a reporter’s introduction to social science methods - Philip Meyer</li>
<li><a href="https://interaktiv.tagesspiegel.de/radmesser/">Radmesser - Tagesspiegel</a></li>
<li><a href="https://sao-paulo.estadao.com.br/noticias/geral,roubos-de-celular-atingem-metade-das-ruas-de-sao-paulo,70002022457">Roubos de celular atingem metade das ruas de São Paulo - Estadão</a></li>
<li><a href="https://sigaosnumeros.com/sumario/descomplicando-os-dados/como-encontrar-pautas-nos-dados/as-tres-operacoes-fundamentais-da-matematica-para-jornalistas/">Siga os Números - Mariana Segala</a></li>
<li>Spurious Correlations - Tyler Vigen</li>
<li><a href="https://perceptualedge.com/articles/visual_business_intelligence/the_chartjunk_debate.pdf">The chartjunk debate: a close examination of recent findings - Stephen Few</a></li>
<li>The Commercial and Political Atlas - William Playfair</li>
<li><a href="">The Functional Art - Alberto Cairo</a></li>
<li>The Truthful Art - Alberto Cairo</li>
<li><a href="https://pudding.cool/projects/vocabulary/">The Largest Vocabulary In Hip Hop - The Pudding</a></li>
<li><a href="https://medium.com/@paulbradshaw/the-next-wave-of-data-journalism-7e2e10087bb3">The next wave of data journalism? - Paul Bradshaw</a></li>
<li><a href="https://www.nytimes.com/series/new-york-times-privacy-project">The New York Times Privacy Project</a></li>
<li>The Visual Display of Quantitative Information - Edward Tufte</li>
<li><a href="https://escoladedados.org/tutoriais/guia-quartz-para-limpeza-de-dados/#planilha-tem-65536-linhas">Tutoriais da Escola de Dados</a></li>
<li><a href="http://produtos.ne10.uol.com.br/umaporuma/index.php">Uma Por Uma - Uol</a></li>
<li><a href="https://escoladedados.org/2019/08/sou-uma-cientista-de-dados-cetica-quanto-aos-dados/">Sou uma cientista de dados cética quanto aos dados - Andrea Jones-Rooy</a></li>
<li><a href="http://opendatahandbook.org/guide/en/what-is-open-data/">What is open data? - Open Knowledge</a></li>
</ul>
<h1 id="apoiadores">Apoiadores</h1>
<p>Esta publicação foi realizada graças ao apoio de 282 pessoas, que colaboraram com a primeira campanha de financiamento colaborativo da Escola de Dados em 2019.</p>
<p>Adriana Farias</p>
<p>Adriana Ramos Guarani Kaiowá</p>
<p>Ailma Teixeira</p>
<p>Aisten Baldan</p>
<p>Alberto Oliveira</p>
<p>Alessandra Ferreira</p>
<p>Alessandra Midori</p>
<p>Amanda Carvalho</p>
<p>Amanda Lemos</p>
<p>Amanda Moura</p>
<p>Amanda Rossi</p>
<p>Ana Beatriz Assam</p>
<p>Ana Carolina Castro</p>
<p>Ana Freitas</p>
<p>Ana Laura Azevedo</p>
<p>Ana Paula de Oliveira</p>
<p>Ana Paula Ferreira</p>
<p>Andre Spritzer</p>
<p>André Tamura</p>
<p>Andre Mota</p>
<p>Ângela Prestes</p>
<p>Angélica Martins</p>
<p>Anna Livia Arida</p>
<p>Anne Clinio</p>
<p>Anselmo Dias</p>
<p>Antonio Junior</p>
<p>Antônio Prestes</p>
<p>Augusto Conconi</p>
<p>Augusto Fadel</p>
<p>Barbara Blum</p>
<p>Barbara Castro</p>
<p>Barbara Jambwisch</p>
<p>Bárbara Libório</p>
<p>Bianca Berti</p>
<p>Bruno Luiz</p>
<p>Bruno Teixeira</p>
<p>Bruno Lemos</p>
<p>Bruno Evangelista</p>
<p>Bruno Silva</p>
<p>Bruno De Barros</p>
<p>Bruno Nunes</p>
<p>Café.art.br</p>
<p>Caio do Nascimento</p>
<p>Carol Moreno</p>
<p>Carol Pacobahyba</p>
<p>Carol Queiroz</p>
<p>Carolina Assunção</p>
<p>Carolina Ribeiro</p>
<p>Caroline Franco</p>
<p>Cecília Do Lago</p>
<p>Celia Beatriz Rosemblum</p>
<p>Cesar de Oliveira</p>
<p>Christian Moryah</p>
<p>Christina Brentano</p>
<p>Clara Sacco</p>
<p>Clarissa Mendes</p>
<p>Colaboradados</p>
<p>Cristian Weiss</p>
<p>Cristiane Paião</p>
<p>Cristiano Pavini</p>
<p>Daniel Silveira</p>
<p>Daniel Mariani</p>
<p>Daniel Bramatti</p>
<p>Daniel de Augustinis</p>
<p>Daniel Dieb</p>
<p>Daniel Fireman</p>
<p>Daniel Portugal</p>
<p>Daniel Schwabe</p>
<p>Daniel Torquato</p>
<p>Danilo Torini</p>
<p>Dênis Tavares</p>
<p>Denise Businaro</p>
<p>Denise Neumann</p>
<p>Diana Yukari</p>
<p>Diego Oliveira</p>
<p>Diogo do Carmo</p>
<p>Diogo Mafra</p>
<p>Diogo Pires</p>
<p>Edna Simao de Souza</p>
<p>Edson Alves Jr</p>
<p>Eduardo Belo</p>
<p>Eduardo Almeida</p>
<p>Elisângela Mendonça</p>
<p>Emanuele dos Santos</p>
<p>Eric Daher</p>
<p>Érico Lima</p>
<p>Everton Alvarenga</p>
<p>Fabiana Cambricoli</p>
<p>Fabiana Pulcineli</p>
<p>Fabiano Silos</p>
<p>Fábio de Araujo</p>
<p>Fabio Takahashi</p>
<p>Felipe Grandin</p>
<p>Felippe Mercurio</p>
<p>Fernanda Campagnucci</p>
<p>Fernanda Távora</p>
<p>Fernando Barbalho</p>
<p>Filipe da Silva</p>
<p>Filipe Augusto</p>
<p>Filipe José Quintans</p>
<p>Filipe Menezes</p>
<p>Flavia Alemi</p>
<p>Flavio Dal Pozzo</p>
<p>Flávio Passos</p>
<p>Flavio Shirahige</p>
<p>Francisco de Oliveira Júnior</p>
<p>Francisco de Lima Moacyr Filho</p>
<p>Gabriel Santo</p>
<p>Gabriel Cortilio</p>
<p>Gabriela Caesar</p>
<p>Géssica Gonçalves</p>
<p>Gilberto Vieira</p>
<p>Gisele Barros</p>
<p>Giulia Afiune</p>
<p>Glaucia Campregher</p>
<p>Guilherme Duarte</p>
<p>Guilherme Mendes</p>
<p>Guilherme Storck</p>
<p>Gustavo Macedo</p>
<p>Gustavo Tosello</p>
<p>Guto Schultz</p>
<p>Haruan Mossato</p>
<p>Helder da Rocha</p>
<p>Helio Miguel</p>
<p>Henrique Dentzien</p>
<p>Henrique França</p>
<p>Henrique Parra</p>
<p>Iago Bolívar</p>
<p>Ígor Passarini</p>
<p>Ilito Torquato</p>
<p>Isabella Sander</p>
<p>Isis Reis</p>
<p>Ivan Lemos</p>
<p>Ivana Bentes</p>
<p>Jamile Santana</p>
<p>Jardel Duque</p>
<p>Jean Prado</p>
<p>João Vitor Freitas</p>
<p>João Vitor Rodrigues</p>
<p>Josir Cardoso Gomes</p>
<p>Joyce Heurich</p>
<p>Juan Torres</p>
<p>Juciano</p>
<p>Julia Mente</p>
<p>Juliana Marques</p>
<p>Juliana Lopes</p>
<p>Juliana Almeida</p>
<p>Juliana Vitor</p>
<p>Júlio Boaro</p>
<p>Júlio Oliveira</p>
<p>Karina Barcellos</p>
<p>Karla Mendes</p>
<p>Katia Brembatti</p>
<p>Keila Guimarães</p>
<p>Larissa Brainer</p>
<p>Leandro Filippi</p>
<p>Leonardo Germani</p>
<p>Leonardo Mendes Júnior</p>
<p>Ligia Guimarães</p>
<p>Liraucio Girardi Júnior</p>
<p>Lucas Gelape</p>
<p>Lucas Palma</p>
<p>Lucas Rizzi</p>
<p>Luciana Junqueira</p>
<p>Lui Pillmann</p>
<p>Luís Guilherme Julião</p>
<p>Luiz Claudio Reis</p>
<p>Luiz Fernando Teixeira</p>
<p>Luiz Fernando Toledo</p>
<p>Luiz Farias</p>
<p>Luiza Bodenmüller</p>
<p>Manoel Galdino</p>
<p>Marcela Miller</p>
<p>Marcelo da Fontoura</p>
<p>Marcelo Dias</p>
<p>Marcelo Granja</p>
<p>Marcelo Lima</p>
<p>Marcelo Oliveira</p>
<p>Marcelo Soares</p>
<p>Marcelo Träsel</p>
<p>Márcio Viana</p>
<p>Marco Antonio Konopacki</p>
<p>Marco Túlio Pires</p>
<p>Marcos André</p>
<p>Marcos Côrtes</p>
<p>Marcos de Salles</p>
<p>Maria Rosa</p>
<p>Mariah Queiroz</p>
<p>Mariana Tiemi</p>
<p>Marianna Araujo</p>
<p>Marilene Oliveira</p>
<p>Marília Gehrke</p>
<p>Marina Merlo</p>
<p>Mário Sérgio</p>
<p>Marlise</p>
<p>Marlos Pereira</p>
<p>Mateus Sousa</p>
<p>Matheus de Araújo</p>
<p>Max Stabile</p>
<p>Melissa Lüdeman</p>
<p>Michele Vieira</p>
<p>Moisés de Melo</p>
<p>Nitai da Silva</p>
<p>Patricia Bado</p>
<p>Patrícia da Silva</p>
<p>Pedro Burgos</p>
<p>Pedro Capetti</p>
<p>Pedro Maia</p>
<p>Pedro Hazan</p>
<p>Pedro Markun</p>
<p>Pedro Renaux Wanderley</p>
<p>Pedro Franco</p>
<p>Pedro Sarvat</p>
<p>Pedro dos Reis</p>
<p>Philippe Watanabe</p>
<p>Priscila Santos</p>
<p>Rachel Domingues</p>
<p>Rafael Vazquez</p>
<p>Rafael Moreira</p>
<p>Rafael Kenski</p>
<p>Rayan Alves</p>
<p>Reinaldo Silva</p>
<p>Renata Hirota</p>
<p>Renata Montechiare</p>
<p>Renato Rebelo</p>
<p>Revista AzMina</p>
<p>Ricardo Rossetto</p>
<p>Robson da Rosa</p>
<p>Rodolfo Almeida</p>
<p>Rodrigo Cunha</p>
<p>Rodrigo Guedes</p>
<p>Rodrigo Coelho</p>
<p>Rodrigo Schuinski</p>
<p>Rodrigo Takenouchi</p>
<p>Rosangela Lotfi</p>
<p>Rose do Nascimento</p>
<p>Rosental Alves</p>
<p>Rui Barros</p>
<p>Rute Pina</p>
<p>Sérgio Lüdtke</p>
<p>Sérgio Seabra</p>
<p>Sérgio Spagnuolo</p>
<p>Silvana Fernandes</p>
<p>Silvia Follador</p>
<p>Stefano Wrobleski</p>
<p>Stephanie de Paula</p>
<p>Suzana Barbosa</p>
<p>Tadeu Junior</p>
<p>Tadeu Teixeira</p>
<p>Taís Seibt</p>
<p>Talita Duvanel</p>
<p>Tatiana Balachova</p>
<p>Tatiana Coelho</p>
<p>testecolab</p>
<p>Thays Lavor</p>
<p>Thiago de Moraes</p>
<p>Thiago Corte</p>
<p>Thomaz Barbosa</p>
<p>Thomaz Rezende</p>
<p>Tiago Pereira</p>
<p>Tiago Rogero</p>
<p>Tomas Martinez</p>
<p>Verónica Goyzueta</p>
<p>Victor Grinberg</p>
<p>Vinícius Valle</p>
<p>Vitor Mafra</p>
<p>Vitor Paulos Bellini</p>
<p>Vívian Vieira</p>
<p>Viviane Machado</p>
<p>Yan Dutra Hill</p>
<p>Yuri Almeida</p>
<hr />
</body>
</html>
